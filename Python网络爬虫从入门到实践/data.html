<!DOCTYPE HTML>
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Arxiv Sanity Preserver</title>

<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML">
</script>

<!-- CSS -->
<link rel="stylesheet" type="text/css" href="/static/style.css">

<!-- Favicon -->
<link rel="shortcut icon" type="image/png" href="/static/favicon.png" />

<!-- JS -->
<script src="/static/jquery-1.8.3.min.js"></script>
<script src="/static/d3.min.js"></script>
<script src="/static/as-common.js"></script>

<!-- Google Analytics JS -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-3698471-25', 'auto');
  ga('send', 'pageview');

</script>

<script>

// passed in from flask as json
var tweets = [];
var papers = [{"abstract": "While Generative Adversarial Networks (GANs) have empirically produced\nimpressive results on learning complex real-world distributions, recent work\nhas shown that they suffer from lack of diversity or mode collapse. The\ntheoretical work of Arora et al.~\\cite{AroraGeLiMaZh17} suggests a dilemma\nabout GANs\u0027 statistical properties: powerful discriminators cause overfitting,\nwhereas weak discriminators cannot detect mode collapse.\n  In contrast, we show in this paper that GANs can in principle learn\ndistributions in Wasserstein distance (or KL-divergence in many cases) with\npolynomial sample complexity, if the discriminator class has strong\ndistinguishing power against the particular generator class (instead of against\nall possible generators). For various generator classes such as mixture of\nGaussians, exponential families, and invertible neural networks generators, we\ndesign corresponding discriminators (which are often neural nets of specific\narchitectures) such that the Integral Probability Metric (IPM) induced by the\ndiscriminators can provably approximate the Wasserstein distance and/or\nKL-divergence. This implies that if the training is successful, then the\nlearned distribution is close to the true distribution in Wasserstein distance\nor KL divergence, and thus cannot drop modes. Our preliminary experiments show\nthat on synthetic datasets the test IPM is well correlated with KL divergence,\nindicating that the lack of diversity may be caused by the sub-optimality in\noptimization instead of statistical inefficiency.", "authors": ["Yu Bai", "Tengyu Ma", "Andrej Risteski"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10586v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10586v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10586v1", "published_time": "6/27/2018", "rawpid": "1806.10586", "tags": ["cs.LG", "cs.DS", "stat.ML"], "title": "Approximability of Discriminators Implies Diversity in GANs"}, {"abstract": "This paper presents a new multi-objective deep reinforcement learning (MODRL)\nframework based on deep Q-networks. We propose the use of linear and non-linear\nmethods to develop the MODRL framework that includes both single-policy and\nmulti-policy strategies. The experimental results on two benchmark problems\nincluding the two-objective deep sea treasure environment and the\nthree-objective mountain car problem indicate that the proposed framework is\nable to converge to the optimal Pareto solutions effectively. The proposed\nframework is generic, which allows implementation of different deep\nreinforcement learning algorithms in different complex environments. This\ntherefore overcomes many difficulties involved with standard multi-objective\nreinforcement learning (MORL) methods existing in the current literature. The\nframework creates a platform as a testbed environment to develop methods for\nsolving various problems associated with the current MORL. Details of the\nframework implementation can be referred to\nhttp://www.deakin.edu.au/~thanhthi/drl.htm.", "authors": ["Thanh Thi Nguyen"], "category": "cs.LG", "comment": "17 pages", "img": "/static/thumbs/1803.02965v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.02965v2", "num_discussion": 0, "originally_published_time": "3/8/2018", "pid": "1803.02965v2", "published_time": "6/27/2018", "rawpid": "1803.02965", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "A Multi-Objective Deep Reinforcement Learning Framework"}, {"abstract": "When we are faced with challenging image classification tasks, we often\nexplain our reasoning by dissecting the image, and pointing out prototypical\naspects of one class or another. The mounting evidence for each of the classes\nhelps us make our final decision. In this work, we introduce a deep network\narchitecture that reasons in a similar way: the network dissects the image by\nfinding prototypical parts, and combines evidence from the prototypes to make a\nfinal classification. The algorithm thus reasons in a way that is qualitatively\nsimilar to the way ornithologists, physicians, geologists, architects, and\nothers would explain to people on how to solve challenging image classification\ntasks. The network uses only image-level labels for training, meaning that\nthere are no labels for parts of images. We demonstrate the method on the\nCIFAR-10 dataset and 10 classes from the CUB-200-2011 dataset.", "authors": ["Chaofan Chen", "Oscar Li", "Alina Barnett", "Jonathan Su", "Cynthia Rudin"], "category": "cs.LG", "comment": "14 pages, including the supplementary material", "img": "/static/thumbs/1806.10574v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10574v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10574v1", "published_time": "6/27/2018", "rawpid": "1806.10574", "tags": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "title": "This looks like that: deep learning for interpretable image recognition"}, {"abstract": "Studying the invertibility of deep neural networks (DNNs) provides a\nprincipled approach to better understand the behavior of these powerful models.\nDespite being a promising diagnostic tool, a consistent theory on their\ninvertibility is still lacking. We derive a theoretically motivated approach to\nexplore the preimages of ReLU-layers and mechanisms affecting the stability of\nthe inverse. Using the developed theory, we numerically show how this approach\nuncovers characteristic properties of the network.", "authors": ["Jens Behrmann", "S\u00f6ren Dittmer", "Pascal Fernsel", "Peter Maa\u00df"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09730v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09730v2", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.09730v2", "published_time": "6/27/2018", "rawpid": "1806.09730", "tags": ["cs.LG", "stat.ML"], "title": "Analysis of Invariance and Robustness via Invertibility of ReLU-Networks"}, {"abstract": "Epistemic logics are a primary formalism for multi-agent systems but major\nreasoning tasks in such epistemic logics are intractable, which impedes\napplications of multi-agent epistemic logics in automatic planning. Knowledge\ncompilation provides a promising way of resolving the intractability by\nidentifying expressive fragments of epistemic logics that are tractable for\nimportant reasoning tasks such as satisfiability and forgetting. The property\nof logical separability allows to decompose a formula into some of its\nsubformulas and thus modular algorithms for various reasoning tasks can be\ndeveloped. In this paper, by employing logical separability, we propose an\napproach to knowledge compilation for the logic Kn by defining a normal form\nSDNF. Among several novel results, we show that every epistemic formula can be\nequivalently compiled into a formula in SDNF, major reasoning tasks in SDNF are\ntractable, and formulas in SDNF enjoy the logical separability. Our results\nshed some lights on modular approaches to knowledge compilation. Furthermore,\nwe apply our results in the multi-agent epistemic planning. Finally, we extend\nthe above result to the logic K45n that is Kn extended by introspection axioms\n4 and 5.", "authors": ["Liangda Fang", "Kewen Wang", "Zhe Wang", "Ximing Wen"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10561v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10561v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10561v1", "published_time": "6/27/2018", "rawpid": "1806.10561", "tags": ["cs.AI"], "title": "Knowledge Compilation in Multi-Agent Epistemic Logics"}, {"abstract": "We study the problem of learning personalized decision policies from\nobservational data while accounting for possible unobserved confounding in the\ndata-generating process. Previous approaches, which assume unconfoundedness,\ni.e., that no unobserved confounders affect both the treatment assignment as\nwell as outcome, can lead to policies that actually introduce significant harm\nrather then benefit due to overeager intervention when some unobserved\nconfounding is present, as is actually the case in most applications dealing\nwith observational data. Instead, we calibrate policy learning for realistic\nviolations of this unverifiable assumption with uncertainty sets motivated by\nsensitivity analysis in causal inference. Our framework for confounding-robust\npolicy improvement optimizes the minimax regret of a candidate policy against a\nbaseline standard-of-care policy over an uncertainty set for propensity\nweights. We prove that if the uncertainty set is well-specified, our robust\npolicy, when applied in practice, will do no worse than the baseline and\nimprove upon it if possible. We characterize the adversarial optimization\nsubproblem and use efficient algorithmic solutions to optimize over\nparametrized spaces of decision policies such as logistic treatment assignment\nand decision trees. We assess our methods on synthetic data and on a large\nclinical trial of acute ischaemic stroke treatment, demonstrating that hidden\nconfounding can hinder existing policy learning approaches and lead to\nunwarranted harm, while our robust approach guarantees safety and focuses on\nwell-evidenced improvement, a necessity for making personalized treatment\npolicies learned from observational data reliable in practice.", "authors": ["Nathan Kallus", "Angela Zhou"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1805.08593v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.08593v2", "num_discussion": 0, "originally_published_time": "5/22/2018", "pid": "1805.08593v2", "published_time": "6/27/2018", "rawpid": "1805.08593", "tags": ["cs.LG", "stat.ML"], "title": "Confounding-Robust Policy Improvement"}, {"abstract": "Language identification of social media text still remains a challenging task\ndue to properties like code-mixing and inconsistent phonetic transliterations.\nIn this paper, we present a supervised learning approach for language\nidentification at the word level of low resource Bengali-English code-mixed\ndata taken from social media. We employ two methods of word encoding, namely\ncharacter based and root phone based to train our deep LSTM models. Utilizing\nthese two models we created two ensemble models using stacking and threshold\ntechnique which gave 91.78% and 92.35% accuracies respectively on our testing\ndata.", "authors": ["Soumil Mandal", "Sourya Dipta Das", "Dipankar Das"], "category": "cs.CL", "comment": "6 pages, 5 figures, 5 tables", "img": "/static/thumbs/1803.03859v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.03859v2", "num_discussion": 0, "originally_published_time": "3/10/2018", "pid": "1803.03859v2", "published_time": "6/27/2018", "rawpid": "1803.03859", "tags": ["cs.CL"], "title": "Language Identification of Bengali-English Code-Mixed data using\n  Character \u0026 Phonetic based LSTM Models"}, {"abstract": "Learning to estimate 3D geometry in a single image by watching unlabeled\nvideos via deep convolutional network has made significant process recently.\nCurrent state-of-the-art (SOTA) methods, are based on the learning framework of\nrigid structure-from-motion, where only 3D camera ego motion is modeled for\ngeometry estimation.However, moving objects also exist in many videos, e.g.\nmoving cars in a street scene. In this paper, we tackle such motion by\nadditionally incorporating per-pixel 3D object motion into the learning\nframework, which provides holistic 3D scene flow understanding and helps single\nimage geometry estimation. Specifically, given two consecutive frames from a\nvideo, we adopt a motion network to predict their relative 3D camera pose and a\nsegmentation mask distinguishing moving objects and rigid background. An\noptical flow network is used to estimate dense 2D per-pixel correspondence. A\nsingle image depth network predicts depth maps for both images. The four types\nof information, i.e. 2D flow, camera pose, segment mask and depth maps, are\nintegrated into a differentiable holistic 3D motion parser (HMP), where\nper-pixel 3D motion for rigid background and moving objects are recovered. We\ndesign various losses w.r.t. the two types of 3D motions for training the depth\nand motion networks, yielding further error reduction for estimated geometry.\nFinally, in order to solve the 3D motion confusion from monocular videos, we\ncombine stereo images into joint training. Experiments on KITTI 2015 dataset\nshow that our estimated geometry, 3D motion and moving object masks, not only\nare constrained to be consistent, but also significantly outperforms other SOTA\nalgorithms, demonstrating the benefits of our approach.", "authors": ["Zhenheng Yang", "Peng Wang", "Yang Wang", "Wei Xu", "Ram Nevatia"], "category": "cs.CV", "comment": "ECCV18\u0027 submission", "img": "/static/thumbs/1806.10556v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10556v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10556v1", "published_time": "6/27/2018", "rawpid": "1806.10556", "tags": ["cs.CV"], "title": "Every Pixel Counts: Unsupervised Geometry Learning with Holistic 3D\n  Motion Understanding"}, {"abstract": "Task offloading is an emerging technology in fog-enabled networks. It allows\nusers transmit tasks to neighbor fog nodes so as to utilize the computing\nresource of the networks. In this paper, we investigate a stochastic task\noffloading model and propose a multi-armed bandit framework to formulate this\nmodel. We consider different helper nodes prefer different kinds of tasks and\nfeedback one-bit information to task node named happiness of nodes. The key\nchallenge of this problem is an exploration-exploitation tradeoff. Thus we\nimplement a UCB-type algorithm to maximize the long-term happiness metric.\nFurther more, we prove that this UCB-type algorithm is asymptotically optimal.\nNumerical simulations are given in the end of the paper to corroborate our\nstrategy.", "authors": ["Shangshu Zhao", "Zhaowei Zhu", "Fuqian Yang", "Xiliang Luo"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10547v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10547v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10547v1", "published_time": "6/27/2018", "rawpid": "1806.10547", "tags": ["cs.LG", "stat.ML"], "title": "Online optimal task offloading with one-bit feedback"}, {"abstract": "In this paper we propose a new iterative method to hierarchically compute a\nrelatively large number of leftmost eigenpairs of a sparse symmetric positive\nmatrix under the multiresolution operator compression framework. We exploit the\nwell-conditioned property of every decomposition components by integrating the\nmultiresolution framework into the Implicitly restarted Lanczos method. We\nachieve this combination by proposing an extension-refinement iterative scheme,\nin which the intrinsic idea is to decompose the target spectrum into several\nsegments such that the corresponding eigenproblem in each segment is\nwell-conditioned. Theoretical analysis and numerical illustration are also\nreported to illustrate the efficiency and effectiveness of this algorithm.", "authors": ["Thomas Y. Hou", "De Huang", "Ka Chun Lam", "Ziyun Zhang"], "category": "math.NA", "comment": "46 pages, 11 figures, 10 tables", "img": "/static/thumbs/1804.03415v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.03415v2", "num_discussion": 0, "originally_published_time": "4/10/2018", "pid": "1804.03415v2", "published_time": "6/27/2018", "rawpid": "1804.03415", "tags": ["math.NA", "cs.CV"], "title": "A Fast Hierarchically Preconditioned Eigensolver Based On\n  Multiresolution Matrix Decomposition"}, {"abstract": "This paper discusses technology challenges and opportunities to embrace\nartificial intelligence (AI) era in the design of wireless networks. We aim to\nprovide readers with motivation and general methodology for adoption of AI in\nthe context of next-generation networks. First, we discuss the rise of network\nintelligence and then, we introduce a brief overview of AI with machine\nlearning (ML) and their relationship to self-organization designs. Finally, we\ndiscuss design of intelligent agent and it\u0027s functions to enable\nknowledge-driven wireless networks with AI.", "authors": ["Haris Gacanin"], "category": "cs.NI", "comment": "", "img": "/static/thumbs/1806.10518v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10518v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10518v1", "published_time": "6/27/2018", "rawpid": "1806.10518", "tags": ["cs.NI", "cs.AI"], "title": "Knowledge-Driven Wireless Networks with Artificial Intelligence: Design,\n  Challenges and Opportunities"}, {"abstract": "Human professionals are often required to make decisions based on complex\nmultivariate time series measurements in an online setting, e.g. in health\ncare. Since human cognition is not optimized to work well in high-dimensional\nspaces, these decisions benefit from interpretable low-dimensional\nrepresentations. However, many representation learning algorithms for time\nseries data are difficult to interpret. This is due to non-intuitive mappings\nfrom data features to salient properties of the representation and\nnon-smoothness over time. To address this problem, we propose to couple a\nvariational autoencoder to a discrete latent space and introduce a topological\nstructure through the use of self-organizing maps. This allows us to learn\ndiscrete representations of time series, which give rise to smooth and\ninterpretable embeddings with superior clustering performance. Furthermore, to\nallow for a probabilistic interpretation of our method, we integrate a Markov\nmodel in the latent space. This model uncovers the temporal transition\nstructure, improves clustering performance even further and provides additional\nexplanatory insights as well as a natural representation of uncertainty. We\nevaluate our model on static (Fashion-)MNIST data, a time series of linearly\ninterpolated (Fashion-)MNIST images, a chaotic Lorenz attractor system with two\nmacro states, as well as on a challenging real world medical time series\napplication. In the latter experiment, our representation uncovers meaningful\nstructure in the acute physiological state of a patient.", "authors": ["Vincent Fortuin", "Matthias H\u00fcser", "Francesco Locatello", "Heiko Strathmann", "Gunnar R\u00e4tsch"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.02199v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.02199v4", "num_discussion": 0, "originally_published_time": "6/6/2018", "pid": "1806.02199v4", "published_time": "6/27/2018", "rawpid": "1806.02199", "tags": ["cs.LG", "stat.ML"], "title": "Deep Self-Organization: Interpretable Discrete Representation Learning\n  on Time Series"}, {"abstract": "Adversarial examples are intentionally crafted data with the purpose of\ndeceiving neural networks into misclassification. When we talk about strategies\nto create such examples, we usually refer to perturbation-based methods that\nfabricate adversarial examples by applying invisible perturbations onto normal\ndata. The resulting data reserve their visual appearance to human observers,\nyet can be totally unrecognizable to DNN models, which in turn leads to\ncompletely misleading predictions. In this paper, however, we consider crafting\nadversarial examples from existing data as a limitation to example diversity.\nWe propose a non-perturbation-based framework that generates native adversarial\nexamples from class-conditional generative adversarial networks.As such, the\ngenerated data will not resemble any existing data and thus expand example\ndiversity, raising the difficulty in adversarial defense. We then extend this\nframework to pre-trained conditional GANs, in which we turn an existing\ngenerator into an \"adversarial-example generator\". We conduct experiments on\nour approach for MNIST and CIFAR10 datasets and have satisfactory results,\nshowing that this approach can be a potential alternative to previous attack\nstrategies.", "authors": ["Shih-hong Tsai"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10496v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10496v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10496v1", "published_time": "6/27/2018", "rawpid": "1806.10496", "tags": ["cs.CV", "cs.CR"], "title": "Customizing an Adversarial Example Generator with Class-Conditional GANs"}, {"abstract": "This paper demonstrates the effectiveness of our customized deep learning\nbased video analytics system in various applications focused on security,\nsafety, customer analytics and process compliance. We describe our video\nanalytics system comprising of Search, Summarize, Statistics and real-time\nalerting, and outline its building blocks. These building blocks include object\ndetection, tracking, face detection and recognition, human and face\nsub-attribute analytics. In each case, we demonstrate how custom models trained\nusing data from the deployment scenarios provide considerably superior\naccuracies than off-the-shelf models. Towards this end, we describe our data\nprocessing and model training pipeline, which can train and fine-tune models\nfrom videos with a quick turnaround time. Finally, since most of these models\nare deployed on-site, it is important to have resource constrained models which\ndo not require GPUs. We demonstrate how we custom train resource constrained\nmodels and deploy them on embedded devices without significant loss in\naccuracy. To our knowledge, this is the first work which provides a\ncomprehensive evaluation of different deep learning models on various\nreal-world customer deployment scenarios of surveillance video analytics. By\nsharing our implementation details and the experiences learned from deploying\ncustomized deep learning models for various customers, we hope that customized\ndeep learning based video analytics is widely incorporated in commercial\nproducts around the world.", "authors": ["Pratik Dubal", "Rohan Mahadev", "Suraj Kothawade", "Kunal Dargan", "Rishabh Iyer"], "category": "cs.CV", "comment": "Added Equal Contribution footnote", "img": "/static/thumbs/1805.10604v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.10604v2", "num_discussion": 0, "originally_published_time": "5/27/2018", "pid": "1805.10604v2", "published_time": "6/27/2018", "rawpid": "1805.10604", "tags": ["cs.CV", "cs.DM"], "title": "Deployment of Customized Deep Learning based Video Analytics On\n  Surveillance Cameras"}, {"abstract": "Face recognition (FR) systems for video surveillance (VS) applications\nattempt to accurately detect the presence of target individuals over a\ndistributed network of cameras. In video-based FR systems, facial models of\ntarget individuals are designed a priori during enrollment using a limited\nnumber of reference still images or video data. These facial models are not\ntypically representative of faces being observed during operations due to large\nvariations in illumination, pose, scale, occlusion, blur, and to camera\ninter-operability. Specifically, in still-to-video FR application, a single\nhigh-quality reference still image captured with still camera under controlled\nconditions is employed to generate a facial model to be matched later against\nlower-quality faces captured with video cameras under uncontrolled conditions.\nCurrent video-based FR systems can perform well on controlled scenarios, while\ntheir performance is not satisfactory in uncontrolled scenarios mainly because\nof the differences between the source (enrollment) and the target (operational)\ndomains. Most of the efforts in this area have been toward the design of robust\nvideo-based FR systems in unconstrained surveillance environments. This chapter\npresents an overview of recent advances in still-to-video FR scenario through\ndeep convolutional neural networks (CNNs). In particular, deep learning\narchitectures proposed in the literature based on triplet-loss function (e.g.,\ncross-correlation matching CNN, trunk-branch ensemble CNN and HaarNet) and\nsupervised autoencoders (e.g., canonical face representation CNN) are reviewed\nand compared in terms of accuracy and computational complexity.", "authors": ["Saman Bashbaghi", "Eric Granger", "Robert Sabourin", "Mostafa Parchami"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1802.09990v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.09990v2", "num_discussion": 0, "originally_published_time": "2/27/2018", "pid": "1802.09990v2", "published_time": "6/27/2018", "rawpid": "1802.09990", "tags": ["cs.CV"], "title": "Deep Learning Architectures for Face Recognition in Video Surveillance"}, {"abstract": "We present a variational renormalization group (RG) approach using a deep\ngenerative model based on normalizing flows. The model performs hierarchical\nchange-of-variables transformations from the physical space to a latent space\nwith reduced mutual information. Conversely, the neural net directly maps\nindependent Gaussian noises to physical configurations following the inverse RG\nflow. The model has an exact and tractable likelihood, which allows unbiased\ntraining and direct access to the renormalized energy function of the latent\nvariables. To train the model, we employ probability density distillation for\nthe bare energy function of the physical problem, in which the training loss\nprovides a variational upper bound of the physical free energy. We demonstrate\npractical usage of the approach by identifying mutually independent collective\nvariables of the Ising model and performing accelerated hybrid Monte Carlo\nsampling in the latent space. Lastly, we comment on the connection of the\npresent approach to the wavelet formulation of RG and the modern pursuit of\ninformation preserving RG.", "authors": ["Shuo-Hui Li", "Lei Wang"], "category": "cond-mat.stat-mech", "comment": "Main text: 4.5 pages, 4 figures. Supplement: 2 pages. Github link:\n  https://github.com/li012589/Neu...", "img": "/static/thumbs/1802.02840v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.02840v3", "num_discussion": 0, "originally_published_time": "2/8/2018", "pid": "1802.02840v3", "published_time": "6/27/2018", "rawpid": "1802.02840", "tags": ["cond-mat.stat-mech", "cs.LG", "stat.ML"], "title": "Neural Network Renormalization Group"}, {"abstract": "Research on question answering with knowledge base has recently seen an\nincreasing use of deep architectures. In this extended abstract, we study the\napplication of the neural machine translation paradigm for question parsing. We\nemploy a sequence-to-sequence model to learn graph patterns in the SPARQL graph\nquery language and their compositions. Instead of inducing the programs through\nquestion-answer pairs, we expect a semi-supervised approach, where alignments\nbetween questions and queries are built through templates. We argue that the\ncoverage of language utterances can be expanded using late notable works in\nnatural language generation.", "authors": ["Tommaso Soru", "Edgard Marx", "Andr\u00e9 Valdestilhas", "Diego Esteves", "Diego Moussallem", "Gustavo Publio"], "category": "cs.CL", "comment": "Extended abstract, selected for the NAMPI 2.0 Workshop at ICML 2018", "img": "/static/thumbs/1806.10478v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10478v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10478v1", "published_time": "6/27/2018", "rawpid": "1806.10478", "tags": ["cs.CL", "cs.AI", "cs.DB", "68T99", "I.2.6; I.2.7"], "title": "Neural Machine Translation for Query Construction and Composition"}, {"abstract": "We present a new method for estimating vector space representations of words:\nembedding learning by concept induction. We test this method on a highly\nparallel corpus and learn semantic representations of words in 1259 different\nlanguages in a single common space. An extensive experimental evaluation on\ncrosslingual word similarity and sentiment analysis indicates that\nconcept-based multilingual embedding learning performs better than previous\napproaches.", "authors": ["Philipp Dufter", "Mengjie Zhao", "Martin Schmitt", "Alexander Fraser", "Hinrich Sch\u00fctze"], "category": "cs.CL", "comment": "ACL 2018", "img": "/static/thumbs/1801.06807v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1801.06807v3", "num_discussion": 0, "originally_published_time": "1/21/2018", "pid": "1801.06807v3", "published_time": "6/27/2018", "rawpid": "1801.06807", "tags": ["cs.CL"], "title": "Embedding Learning Through Multilingual Concept Induction"}, {"abstract": "The current paper deals with the role played by Logarithmic Image Processing\n(LIP) operators for evaluating the homogeneity of a region. Two new criteria of\nheterogeneity are introduced, one based on the LIP addition and the other based\non the LIP scalar multiplication. Such tools are able to manage Region Growing\nalgorithms following the Revol\u0027s technique: starting from an initial seed, they\nconsist of applying specific dilations to the growing region while its\ninhomogeneity level does not exceed a certain level. The new approaches we\nintroduce are significantly improving Revol\u0027s existing technique by making it\nrobust to contrast variations in images. Such a property strongly reduces the\nchaining effect arising in region growing processes.", "authors": ["Michel Jourlin", "Guillaume Noyel"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10472v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10472v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10472v1", "published_time": "6/27/2018", "rawpid": "1806.10472", "tags": ["cs.CV", "math.NA"], "title": "Homogeneity of a region in the logarithmic image processing framework:\n  application to region growing algorithms"}, {"abstract": "This paper proposes LPRNet - end-to-end method for Automatic License Plate\nRecognition without preliminary character segmentation. Our approach is\ninspired by recent breakthroughs in Deep Neural Networks, and works in\nreal-time with recognition accuracy up to 95% for Chinese license plates: 3\nms/plate on nVIDIA GeForce GTX 1080 and 1.3 ms/plate on Intel Core i7-6700K\nCPU. LPRNet consists of the lightweight Convolutional Neural Network, so it can\nbe trained in end-to-end way. To the best of our knowledge, LPRNet is the first\nreal-time License Plate Recognition system that does not use RNNs. As a result,\nthe LPRNet algorithm may be used to create embedded solutions for LPR that\nfeature high level accuracy even on challenging Chinese license plates.", "authors": ["Sergey Zherzdev", "Alexey Gruzdev"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10447v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10447v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10447v1", "published_time": "6/27/2018", "rawpid": "1806.10447", "tags": ["cs.CV"], "title": "LPRNet: License Plate Recognition via Deep Neural Networks"}, {"abstract": "Recently, deep learning has shown its power in steganalysis. However, the\nproposed deep models have been often learned from pre-calculated noise\nresiduals with fixed high-pass filters rather than from raw images. In this\npaper, we propose a new end-to-end learning framework that can learn\nsteganalytic features directly from pixels. In the meantime, the high-pass\nfilters are also automatically learned. Besides class labels, we make use of\nadditional pixel level supervision of cover-stego image pair to jointly and\niteratively train the proposed network which consists of a residual calculation\nnetwork and a steganalysis network. The experimental results prove the\neffectiveness of the proposed architecture.", "authors": ["Wei Wang", "Jing Dong", "Yinlong Qian", "Tieniu Tan"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10443v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10443v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10443v1", "published_time": "6/27/2018", "rawpid": "1806.10443", "tags": ["cs.CV"], "title": "Deep Steganalysis: End-to-End Learning with Supervisory Information\n  beyond Class Labels"}, {"abstract": "In this paper, we investigate the potential of estimating the soil-moisture\ncontent based on VNIR hyperspectral data combined with IR data. Measurements\nfrom a multi-sensor field campaign represent the benchmark dataset which\ncontains measured hyperspectral, IR, and soil-moisture data. We introduce a\nregression framework with three steps consisting of feature selection,\npreprocessing, and well-chosen regression models. The latter are mainly\nsupervised machine learning models. An exception are the self-organizing maps\nwhich are a combination of unsupervised and supervised learning. We analyze the\nimpact of the distinct preprocessing methods on the regression results. Of all\nregression models, the extremely randomized trees model without preprocessing\nprovides the best estimation performance. Our results reveal the potential of\nthe respective regression framework combined with the VNIR hyperspectral data\nto estimate soil moisture. In conclusion, the results of this paper provide a\nbasis for further improvements in different research directions.", "authors": ["Sina Keller", "Felix M. Riese", "Johanna St\u00f6tzer", "Philipp M. Maier", "Stefan Hinz"], "category": "cs.CV", "comment": "Submitted to an ISPRS conference", "img": "/static/thumbs/1804.09046v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.09046v2", "num_discussion": 0, "originally_published_time": "4/24/2018", "pid": "1804.09046v2", "published_time": "6/27/2018", "rawpid": "1804.09046", "tags": ["cs.CV", "cs.LG", "stat.ML"], "title": "Developing a machine learning framework for estimating soil moisture\n  with VNIR hyperspectral data"}, {"abstract": "In this contribution, we investigate the potential of hyperspectral data\ncombined with either simulated ground penetrating radar (GPR) or simulated\n(sensor-like) soil-moisture data to estimate soil moisture. We propose two\nsimulation approaches to extend a given multi-sensor dataset which contains\nsparse GPR data. In the first approach, simulated GPR data is generated either\nby an interpolation along the time axis or by a machine learning model. The\nsecond approach includes the simulation of soil-moisture along the GPR profile.\nThe soil-moisture estimation is improved significantly by the fusion of\nhyperspectral and GPR data. In contrast, the combination of simulated,\nsensor-like soil-moisture values and hyperspectral data achieves the worst\nregression performance. In conclusion, the estimation of soil moisture with\nhyperspectral and GPR data engages further investigations.", "authors": ["Felix M. Riese", "Sina Keller"], "category": "cs.CV", "comment": "This work has been accepted to the IEEE WHISPERS 2018 conference. (C)\n  2018 IEEE", "img": "/static/thumbs/1804.05273v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.05273v2", "num_discussion": 0, "originally_published_time": "4/14/2018", "pid": "1804.05273v2", "published_time": "6/27/2018", "rawpid": "1804.05273", "tags": ["cs.CV", "physics.geo-ph"], "title": "Fusion of hyperspectral and ground penetrating radar to estimate soil\n  moisture"}, {"abstract": "In this work, we propose bag of adversarial features (BAF) for identifying\nmild traumatic brain injury (MTBI) patients from their diffusion magnetic\nresonance images (MRI) (obtained within one month of injury) by incorporating\nunsupervised feature learning techniques. MTBI is a growing public health\nproblem with an estimated incidence of over 1.7 million people annually in US.\nDiagnosis is based on clinical history and symptoms, and accurate, concrete\nmeasures of injury are lacking. Unlike most of previous works, which use\nhand-crafted features extracted from different parts of brain for MTBI\nclassification, we employ feature learning algorithms to learn more\ndiscriminative representation for this task. A major challenge in this field\nthus far is the relatively small number of subjects available for training.\nThis makes it difficult to use an end-to-end convolutional neural network to\ndirectly classify a subject from MR images. To overcome this challenge, we\nfirst apply an adversarial auto-encoder (with convolutional structure) to learn\npatch-level features, from overlapping image patches extracted from different\nbrain regions. We then aggregate these features through a bag-of-word approach.\nWe perform an extensive experimental study on a dataset of 227 subjects\n(including 109 MTBI patients, and 118 age and sex matched healthy controls),\nand compare the bag-of-deep-features with several previous approaches. Our\nexperimental results show that the BAF significantly outperforms earlier works\nrelying on the mean values of MR metrics in selected brain regions.", "authors": ["Shervin Minaee", "Yao Wang", "Alp Aygar", "Sohae Chung", "Xiuyuan Wang", "Yvonne W. Lui", "Els Fieremans", "Steven Flanagan", "Joseph Rath"], "category": "cs.CV", "comment": "IEEE Transactions on Medical Imaging", "img": "/static/thumbs/1806.10419v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10419v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10419v1", "published_time": "6/27/2018", "rawpid": "1806.10419", "tags": ["cs.CV"], "title": "MTBI Identification From Diffusion MR Images Using Bag of Adversarial\n  Visual Features"}, {"abstract": "We present a novel method to model and calculate deformation fields between\nshapes embedded in $\\mathbb{R}^D$. Our framework combines naturally\ninterpolating the two input shapes and calculating correspondences at the same\ntime. The key idea is to compute a divergence-free deformation field\nrepresented in a coarse-to-fine basis using the Karhunen-Lo\\`eve expansion. The\nadvantages are that there is no need to discretize the embedding space and the\ndeformation is volume-preserving. Furthermore, the optimization is done on\ndownsampled versions of the shapes but the morphing can be applied to any\nresolution without a heavy increase in complexity. We show results for shape\ncorrespondence, registration, inter- and extrapolation on the TOSCA and FAUST\ndata sets.", "authors": ["Marvin Eisenberger", "Zorah L\u00e4hner", "Daniel Cremers"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10417v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10417v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10417v1", "published_time": "6/27/2018", "rawpid": "1806.10417", "tags": ["cs.CV", "cs.GR"], "title": "Divergence-Free Shape Interpolation and Correspondence"}, {"abstract": "We propose a Bayesian convolutional neural network built upon Bayes by\nBackprop and elaborate how this known method can serve as the fundamental\nconstruct of our novel, reliable variational inference method for convolutional\nneural networks. First, we show how Bayes by Backprop can be applied to\nconvolutional layers where weights in filters have probability distributions\ninstead of point-estimates; and second, how our proposed framework leads with\nvarious network architectures to performances comparable to convolutional\nneural networks with point-estimates weights. In the past, Bayes by Backprop\nhas been successfully utilised in feedforward and recurrent neural networks,\nbut not in convolutional ones. This work symbolises the extension of the group\nof Bayesian neural networks which encompasses all three aforementioned types of\nnetwork architectures now.", "authors": ["Felix Laumann", "Kumar Shridhar", "Adrian Llopart Maurin"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.05978v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.05978v2", "num_discussion": 0, "originally_published_time": "6/15/2018", "pid": "1806.05978v2", "published_time": "6/27/2018", "rawpid": "1806.05978", "tags": ["cs.LG", "cs.CV", "cs.NE", "stat.ML"], "title": "Bayesian Convolutional Neural Networks"}, {"abstract": "For random matrix models, the parameter estimation based on the traditional\nlikelihood is not straightforward in particular when there is only one sample\nmatrix. We introduce a new parameter optimization method of random matrix\nmodels which works even in such a case not based on the traditional likelihood,\ninstead based on the spectral distribution. We use the spectral distribution\nperturbed by Cauchy noises because the free deterministic equivalent, which is\na tool in free probability theory, allows us to approximate it by a smooth and\naccessible density function.\n  Moreover, we study an asymptotic property of a determination gap, which has a\nsimilar role as the generalization gap. In addition, we propose a new\ndimensionality recovery method for the signal-plus-noise model, and\nexperimentally demonstrate that it recovers the rank of the signal part even if\nthe rank is not low. It is a simultaneous rank selection and parameter\nestimation procedure.", "authors": ["Tomohiro Hayase"], "category": "stat.ML", "comment": "29 pages, 13 figures, Our simulation code is available at\n  https://github.com/ThayaFluss/cnl", "img": "/static/thumbs/1804.03154v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.03154v2", "num_discussion": 0, "originally_published_time": "4/9/2018", "pid": "1804.03154v2", "published_time": "6/27/2018", "rawpid": "1804.03154", "tags": ["stat.ML", "cs.LG", "math.OA", "math.PR"], "title": "Cauchy noise loss for stochastic optimization of random matrix models\n  via free deterministic equivalents"}, {"abstract": "We study a stylized dynamic assortment planning problem during a selling\nseason of finite length $T$, by considering a nested multinomial logit model\nwith $M$ nests and $N$ items per nest. Our policy simultaneously learns\ncustomers\u0027 choice behavior and makes dynamic decisions on assortments based on\nthe current knowledge. It achieves the regret at the order of\n$\\tilde{O}(\\sqrt{MNT}+MN^2)$, where $M$ is the number of nests and $N$ is the\nnumber of products in each nest. We further provide a lower bound result of\n$\\Omega(\\sqrt{MT})$, which shows the optimality of the upper bound when $T\u003eM$\nand $N$ is small. However, the $N^2$ term in the upper bound is not ideal for\napplications where $N$ is large as compared to $T$. To address this issue, we\nfurther generalize our first policy by introducing a discretization technique,\nwhich leads to a regret of $\\tilde{O}(\\sqrt{M}T^{2/3}+MNT^{1/3})$ with a\nspecific choice of discretization granularity. It improves the previous regret\nbound whenever $N\u003eT^{1/3}$. We provide numerical results to demonstrate the\nempirical performance of both proposed policies.", "authors": ["Xi Chen", "Yining Wang", "Yuan Zhou"], "category": "stat.ML", "comment": "31 pages", "img": "/static/thumbs/1806.10410v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10410v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10410v1", "published_time": "6/27/2018", "rawpid": "1806.10410", "tags": ["stat.ML", "cs.LG"], "title": "Dynamic Assortment Selection under the Nested Logit Models"}, {"abstract": "Ultraslow diffusion (i.e. logarithmic diffusion) has been extensively studied\ntheoretically, but has hardly been observed empirically. In this paper,\nfirstly, we find the ultraslow-like diffusion of the time-series of word counts\nof already popular words by analysing three different nationwide language\ndatabases: (i) newspaper articles (Japanese), (ii) blog articles (Japanese),\nand (iii) page views of Wikipedia (English, French, Chinese, and Japanese).\nSecondly, we use theoretical analysis to show that this diffusion is basically\nexplained by the random walk model with the power-law forgetting with the\nexponent $\\beta \\approx 0.5$, which is related to the fractional Langevin\nequation. The exponent $\\beta$ characterises the speed of forgetting and $\\beta\n\\approx 0.5$ corresponds to (i) the border (or thresholds) between the\nstationary and the nonstationary and (ii) the right-in-the-middle dynamics\nbetween the IID noise for $\\beta=1$ and the normal random walk for $\\beta=0$.\nThirdly, the generative model of the time-series of word counts of already\npopular words, which is a kind of Poisson process with the Poisson parameter\nsampled by the above-mentioned random walk model, can almost reproduce not only\nthe empirical mean-squared displacement but also the power spectrum density and\nthe probability density function.", "authors": ["Hayafumi Watanabe"], "category": "physics.soc-ph", "comment": "", "img": "/static/thumbs/1801.07948v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1801.07948v4", "num_discussion": 0, "originally_published_time": "1/24/2018", "pid": "1801.07948v4", "published_time": "6/27/2018", "rawpid": "1801.07948", "tags": ["physics.soc-ph", "cs.CL", "cs.CY"], "title": "Empirical observations of ultraslow diffusion driven by the fractional\n  dynamics in languages: Dynamical statistical properties of word counts of\n  already popular words"}, {"abstract": "Integrated information theory provides a mathematical framework to fully\ncharacterize the cause-effect structure of a physical system. Here, we\nintroduce PyPhi, a Python software package that implements this framework for\ncausal analysis and unfolds the full cause-effect structure of discrete\ndynamical systems of binary elements. The software allows users to easily study\nthese structures, serves as an up-to-date reference implementation of the\nformalisms of integrated information theory, and has been applied in research\non complexity, emergence, and certain biological questions. We first provide an\noverview of the main algorithm and demonstrate PyPhi\u0027s functionality in the\ncourse of analyzing an example system, and then describe details of the\nalgorithm\u0027s design and implementation.\n  PyPhi can be installed with Python\u0027s package manager via the command \u0027pip\ninstall pyphi\u0027 on Linux and macOS systems equipped with Python 3.4 or higher.\nPyPhi is open-source and licensed under the GPLv3; the source code is hosted on\nGitHub at https://github.com/wmayner/pyphi . Comprehensive and\ncontinually-updated documentation is available at https://pyphi.readthedocs.io/\n. The pyphi-users mailing list can be joined at\nhttps://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical\ninterface to the software is available at\nhttp://integratedinformationtheory.org/calculate.html .", "authors": ["William G. P. Mayner", "William Marshall", "Larissa Albantakis", "Graham Findlay", "Robert Marchman", "Giulio Tononi"], "category": "q-bio.NC", "comment": "22 pages, 4 figures, 6 pages of appendices. Supporting information\n  \"S1 Calculating Phi\" can be fou...", "img": "/static/thumbs/1712.09644v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1712.09644v3", "num_discussion": 0, "originally_published_time": "12/27/2017", "pid": "1712.09644v3", "published_time": "6/27/2018", "rawpid": "1712.09644", "tags": ["q-bio.NC", "cs.AI", "q-bio.QM"], "title": "PyPhi: A toolbox for integrated information theory"}, {"abstract": "Using the machine learning approach known as reservoir computing, it is\npossible to train one dynamical system to emulate another. We show that such\ntrained reservoir computers reproduce the properties of the attractor of the\nchaotic system sufficiently well to exhibit chaos synchronisation. That is, the\ntrained reservoir computer, weakly driven by the chaotic system, will\nsynchronise with the chaotic system. Conversely, the chaotic system, weakly\ndriven by a trained reservoir computer, will synchronise with the reservoir\ncomputer. We illustrate this behaviour on the Mackey-Glass and Lorenz systems.\nWe then show that trained reservoir computers can be used to crack chaos based\ncryptography and illustrate this on a chaos cryptosystem based on the\nMackey-Glass system. We conclude by discussing why reservoir computers are so\ngood at emulating chaotic systems.", "authors": ["Piotr Antonik", "Marvyn Gulina", "Ja\u00ebl Pauwels", "Serge Massar"], "category": "cs.NE", "comment": "10 pages, 6 figures", "img": "/static/thumbs/1802.02844v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.02844v2", "num_discussion": 0, "originally_published_time": "2/8/2018", "pid": "1802.02844v2", "published_time": "6/27/2018", "rawpid": "1802.02844", "tags": ["cs.NE"], "title": "Using a reservoir computer to learn chaotic attractors, with\n  applications to chaos synchronisation and cryptography"}, {"abstract": "This article is a study about the existence and the uniqueness of solutions\nof a specific quadratic first-order ODE that frequently appears in multiple\nreconstruction problems. It is called the \\emph{planar-perspective equation}\ndue to the duality with the geometric problem of reconstruction of\nplanar-perspective curves from their modulus. Solutions of the\n\\emph{planar-perspective equation} are related with planar curves parametrized\nwith perspective parametrization due to this geometric interpretation. The\narticle proves the existence of only two local solutions to the \\emph{initial\nvalue problem} with \\emph{regular initial conditions} and a maximum of two\nanalytic solutions with \\emph{critical initial conditions}. The article also\ngives theorems to extend the local definition domain where the existence of\nboth solutions are guaranteed. It introduces the \\emph{maximal depth function}\nas a function that upper-bound all possible solutions of the\n\\emph{planar-perspective equation} and contains all its possible \\emph{critical\npoints}. Finally, the article describes the \\emph{maximal-depth solution\nproblem} that consists of finding the solution of the referred equation that\nhas maximum the depth and proves its uniqueness. It is an important problem as\nit does not need initial conditions to obtain the unique solution and its the\nfrequent solution that practical algorithms of the state-of-the-art give.", "authors": ["David Casillas-Perez", "Daniel Pizarro", "Manuel Mazo", "Adrien Bartoli"], "category": "cs.NA", "comment": "The version 2: New change of variable. Maximal Curve Maximal Solution\n  Convergence Cones The versio...", "img": "/static/thumbs/1710.04265v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1710.04265v3", "num_discussion": 0, "originally_published_time": "10/11/2017", "pid": "1710.04265v3", "published_time": "6/27/2018", "rawpid": "1710.04265", "tags": ["cs.NA", "cs.CV"], "title": "Solutions of Quadratic First-Order ODEs applied to Computer Vision\n  Problems"}, {"abstract": "Neural network models that are not conditioned on class identities were shown\nto facilitate knowledge transfer between classes and to be well-suited for\none-shot learning tasks. Following this motivation, we further explore and\nestablish such models and present a novel neural network architecture for the\ntask of weakly supervised one-shot detection. Our model is only conditioned on\na single exemplar of an unseen class and a larger target example that may or\nmay not contain an instance of the same class as the exemplar. By pairing a\nSiamese similarity network with an attention mechanism, we design a model that\nmanages to simultaneously identify and localise instances of classes unseen at\ntraining time. In experiments with datasets from the computer vision and audio\ndomains, the proposed method considerably outperforms the baseline methods for\nthe weakly supervised one-shot detection task.", "authors": ["Gil Keren", "Maximilian Schmitt", "Thomas Kehrenberg", "Bj\u00f6rn Schuller"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1801.03329v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1801.03329v3", "num_discussion": 0, "originally_published_time": "1/10/2018", "pid": "1801.03329v3", "published_time": "6/27/2018", "rawpid": "1801.03329", "tags": ["stat.ML", "cs.LG"], "title": "Weakly Supervised One-Shot Detection with Attention Similarity Networks"}, {"abstract": "One of the fundamental properties of a salient object region is its contrast\nwith the immediate context. The problem is that numerous object regions exist\nwhich potentially can all be salient. One way to prevent an exhaustive search\nover all object regions is by using object proposal algorithms. These return a\nlimited set of regions which are most likely to contain an object. Several\nsaliency estimation methods have used object proposals. However, they focus on\nthe saliency of the proposal only, and the importance of its immediate context\nhas not been evaluated.\n  In this paper, we aim to improve salient object detection. Therefore, we\nextend object proposal methods with context proposals, which allow to\nincorporate the immediate context in the saliency computation. We propose\nseveral saliency features which are computed from the context proposals. In the\nexperiments, we evaluate five object proposal methods for the task of saliency\nsegmentation, and find that Multiscale Combinatorial Grouping outperforms the\nothers. Furthermore, experiments show that the proposed context features\nimprove performance, and that our method matches results on the FT datasets and\nobtains competitive results on three other datasets (PASCAL-S, MSRA-B and\nECSSD).", "authors": ["Aymen Azaza", "Joost van de Weijer", "Ali Douik", "Marc Masana"], "category": "cs.CV", "comment": "Accepted at Computer Vision and Image Understanding (CVIU)", "img": "/static/thumbs/1806.10359v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10359v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10359v1", "published_time": "6/27/2018", "rawpid": "1806.10359", "tags": ["cs.CV"], "title": "Context Proposals for Saliency Detection"}, {"abstract": "Camera equipped drones are nowadays being used to explore large scenes and\nreconstruct detailed 3D maps. When free space in the scene is approximately\nknown, an offline planner can generate optimal plans to efficiently explore the\nscene. However, for exploring unknown scenes, the planner must predict and\nmaximize usefulness of where to go on the fly. Traditionally, this has been\nachieved using handcrafted utility functions. We propose to learn a better\nutility function that predicts the usefulness of future viewpoints. Our learned\nutility function is based on a 3D convolutional neural network. This network\ntakes as input a novel volumetric scene representation that implicitly captures\npreviously visited viewpoints and generalizes to new scenes. We evaluate our\nmethod on several large 3D models of urban scenes using simulated depth\ncameras. We show that our method outperforms existing utility measures in terms\nof reconstruction performance and is robust to sensor noise.", "authors": ["Benjamin Hepp", "Debadeepta Dey", "Sudipta N. Sinha", "Ashish Kapoor", "Neel Joshi", "Otmar Hilliges"], "category": "cs.CV", "comment": "11 pages, 6 figures, 5 tables", "img": "/static/thumbs/1806.10354v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10354v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10354v1", "published_time": "6/27/2018", "rawpid": "1806.10354", "tags": ["cs.CV"], "title": "Learn-to-Score: Efficient 3D Scene Exploration by Predicting View\n  Utility"}, {"abstract": "We present a simple solution for segmenting grayscale images using existing\nConnected Component Labeling (CCL) algorithms (which are generally applied to\nbinary images), which was efficient enough to be implemented in a constrained\n(embedded automotive) architecture. Our solution customizes the region growing\nand merging approach, and is primarily targeted for stereoscopic disparity\nimages where nearer objects carry more relevance. We provide results from a\nstandard OpenCV implementation for some basic cases and an image from the\nTsukuba stereo-pair dataset.", "authors": ["Viktor Mukha", "Inon Sharony"], "category": "cs.CV", "comment": "7 pages, 5 figures, 2 tables, 1 algorithm", "img": "/static/thumbs/1806.10350v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10350v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10350v1", "published_time": "6/27/2018", "rawpid": "1806.10350", "tags": ["cs.CV", "68U10, 68W99", "I.4.6; I.4.5"], "title": "Disparity Image Segmentation For ADAS"}, {"abstract": "With the rise of deep neural networks for quantum chemistry applications,\nthere is a pressing need for architectures that, beyond delivering accurate\npredictions of chemical properties, are readily interpretable by researchers.\nHere, we describe interpretation techniques for atomistic neural networks on\nthe example of Behler-Parrinello networks as well as the end-to-end model\nSchNet. Both models obtain predictions of chemical properties by aggregating\natom-wise contributions. These latent variables can serve as local explanations\nof a prediction and are obtained during training without additional cost. Due\nto their correspondence to well-known chemical concepts such as atomic energies\nand partial charges, these atom-wise explanations enable insights not only\nabout the model but more importantly about the underlying quantum-chemical\nregularities. We generalize from atomistic explanations to 3d space, thus\nobtaining spatially resolved visualizations which further improve\ninterpretability. Finally, we analyze learned embeddings of chemical elements\nthat exhibit a partial ordering that resembles the order of the periodic table.\nAs the examined neural networks show excellent agreement with chemical\nknowledge, the presented techniques open up new venues for data-driven research\nin chemistry, physics and materials science.", "authors": ["Kristof T. Sch\u00fctt", "Michael Gastegger", "Alexandre Tkatchenko", "Klaus-Robert M\u00fcller"], "category": "physics.comp-ph", "comment": "", "img": "/static/thumbs/1806.10349v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10349v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10349v1", "published_time": "6/27/2018", "rawpid": "1806.10349", "tags": ["physics.comp-ph", "cs.LG", "physics.chem-ph", "stat.ML"], "title": "Quantum-chemical insights from interpretable atomistic neural networks"}, {"abstract": "We study the problem of grounding distributional representations of texts on\nthe visual domain, namely visual-semantic embeddings (VSE for short). Begin\nwith an insightful adversarial attack on VSE embeddings, we show the limitation\nof current frameworks and image-text datasets (e.g., MS-COCO) both\nquantitatively and qualitatively. The large gap between the number of possible\nconstitutions of real-world semantics and the size of parallel data, to a large\nextent, restricts the model to establish the link between textual semantics and\nvisual concepts. We alleviate this problem by augmenting the MS-COCO image\ncaptioning datasets with textual contrastive adversarial samples. These samples\nare synthesized using linguistic rules and the WordNet knowledge base. The\nconstruction procedure is both syntax- and semantics-aware. The samples enforce\nthe model to ground learned embeddings to concrete concepts within the image.\nThis simple but powerful technique brings a noticeable improvement over the\nbaselines on a diverse set of downstream tasks, in addition to defending\nknown-type adversarial attacks. We release the codes at\nhttps://github.com/ExplorerFreda/VSE-C.", "authors": ["Haoyue Shi", "Jiayuan Mao", "Tete Xiao", "Yuning Jiang", "Jian Sun"], "category": "cs.CL", "comment": "To Appear at COLING 2018", "img": "/static/thumbs/1806.10348v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10348v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10348v1", "published_time": "6/27/2018", "rawpid": "1806.10348", "tags": ["cs.CL", "cs.CV"], "title": "Learning Visually-Grounded Semantics from Contrastive Adversarial\n  Samples"}, {"abstract": "Key role in the prevention of diet-related chronic diseases plays the\nbalanced nutrition together with a proper diet. The conventional dietary\nassessment methods are time-consuming, expensive and prone to errors. New\ntechnology-based methods that provide reliable and convenient dietary\nassessment, have emerged during the last decade. The advances in the field of\ncomputer vision permitted the use of meal image to assess the nutrient content\nusually through three steps: food segmentation, recognition and volume\nestimation. In this paper, we propose a use one RGB meal image as input to a\nmulti-task learning based Convolutional Neural Network (CNN). The proposed\napproach achieved outstanding performance, while a comparison with\nstate-of-the-art methods indicated that the proposed approach exhibits clear\nadvantage in accuracy, along with a massive reduction of processing time.", "authors": ["Ya Lu", "Dario Allegra", "Marios Anthimopoulos", "Filippo Stanco", "Giovanni Maria Farinella", "Stavroula Mougiakakou"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10343v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10343v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10343v1", "published_time": "6/27/2018", "rawpid": "1806.10343", "tags": ["cs.CV"], "title": "A Multi-Task Learning Approach for Meal Assessment"}, {"abstract": "Glaucoma is the leading cause of irreversible but preventable blindness in\nthe world. Its major treatable risk factor is the intra-ocular pressure,\nalthough other biomarkers are being explored to improve the understanding of\nthe pathophysiology of the disease. It has been recently observed that glaucoma\ninduces changes in the ocular hemodynamics. However, its effects on the\nfunctional behavior of the retinal arterioles have not been studied yet. In\nthis paper we propose a first approach for characterizing those changes using\ncomputational hemodynamics. The retinal blood flow is simulated using a 0D\nmodel for a steady, incompressible non Newtonian fluid in rigid domains. The\nsimulation is performed on patient-specific arterial trees extracted from\nfundus images. We also propose a novel feature representation technique to\ncomprise the outcomes of the simulation stage into a fixed length feature\nvector that can be used for classification studies. Our experiments on a new\ndatabase of fundus images show that our approach is able to capture\nrepresentative changes in the hemodynamics of glaucomatous patients. Code and\ndata are publicly available in https://ignaciorlando.github.io.", "authors": ["Jos\u00e9 Ignacio Orlando", "Jo\u00e3o Barbosa Breda", "Karel van Keer", "Matthew B. Blaschko", "Pablo J. Blanco", "Carlos A. Bulant"], "category": "cs.CV", "comment": "MICCAI 2018 paper", "img": "/static/thumbs/1805.10273v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.10273v3", "num_discussion": 0, "originally_published_time": "5/25/2018", "pid": "1805.10273v3", "published_time": "6/27/2018", "rawpid": "1805.10273", "tags": ["cs.CV"], "title": "Towards a glaucoma risk index based on simulated hemodynamics from\n  fundus images"}, {"abstract": "Objective: Segmentation of colorectal cancerous regions from the Magnetic\nResonance (MR) image is a crucial procedure for radiotherapy, which requires to\naccurately delineate boundaries of the tumors. This work aims to address this\nimportant while challenging task in an accurate as well as efficient manner.\nMethods: We propose a novel multi-tasking framework, referred to as 3D\nRoI-aware U-Net (3D RU-Net), for RoI localization and intra-RoI segmentation,\nwhere the two tasks share one backbone network. With the region proposals from\nthe localization branch, we crop multi-level feature maps from the backbone\nnetwork to form a U-Net-like intra-RoI segmentation branch. To effectively\ntrain the model, we propose a novel Dice based hybrid loss to tackle the issue\nof class-imbalance under the multi-task setting. Furthermore, we design a\nmulti-resolution model ensemble strategy to improve the discrimination\ncapability of the framework. Results: Our method has been validated on 64\ncancerous cases with a four-fold cross-validation, outperforming\nstate-of-the-art methods by a significant margin in terms of both accuracy and\nspeed. Conclusion: Experimental results demonstrated that the proposed method\nenables accurate and fast whole volume RoI localization and intra-RoI\nsegmentation. Significance: This paper proposes a general 3D segmentation\nframework which rapidly locates the RoI region in large volumetric images and\naccurately segments the in-region targets. The method has a great potential to\nbe extended to other small 3D object segmentation tasks from medical images.", "authors": ["Yi-Jie Huang", "Qi Dou", "Zi-Xian Wang", "Li-Zhi Liu", "Ying Jin", "Chao-Feng Li", "Lisheng Wang", "Hao Chen", "Rui-Hua Xu"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10342v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10342v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10342v1", "published_time": "6/27/2018", "rawpid": "1806.10342", "tags": ["cs.CV"], "title": "3D RoI-aware U-Net for Accurate and Efficient Colorectal Tumor\n  Segmentation"}, {"abstract": "Recent studies on neural architecture search have shown that automatically\ndesigned neural networks perform as good as human-designed architectures. While\nmost existing works on neural architecture search aim at finding architectures\nthat optimize for prediction accuracy. These methods may generate complex\narchitectures consuming excessively high energy consumption, which is not\nsuitable for computing environment with limited power budgets. We propose\nMONAS, a Multi-Objective Neural Architecture Search with novel reward functions\nthat consider both prediction accuracy and power consumption when exploring\nneural architectures. MONAS effectively explores the design space and searches\nfor architectures satisfying the given requirements. The experimental results\ndemonstrate that the architectures found by MONAS achieve accuracy comparable\nto or better than the state-of-the-art models, while having better energy\nefficiency.", "authors": ["Chi-Hung Hsu", "Shu-Huan Chang", "Da-Cheng Juan", "Jia-Yu Pan", "Yu-Ting Chen", "Wei Wei", "Shih-Chieh Chang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10332v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10332v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10332v1", "published_time": "6/27/2018", "rawpid": "1806.10332", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "MONAS: Multi-Objective Neural Architecture Search using Reinforcement\n  Learning"}, {"abstract": "Modern AI and robotic systems are characterized by a high and ever-increasing\nlevel of autonomy. At the same time, their applications in fields such as\nautonomous driving, service robotics and digital personal assistants move\ncloser to humans. From the combination of both developments emerges the field\nof AI ethics which recognizes that the actions of autonomous machines entail\nmoral dimensions and tries to answer the question of how we can build moral\nmachines. In this paper we argue for taking inspiration from Aristotelian\nvirtue ethics by showing that it forms a suitable combination with modern AI\ndue to its focus on learning from experience. We furthermore propose that\nimitation learning from moral exemplars, a central concept in virtue ethics,\ncan solve the value alignment problem. Finally, we show that an intelligent\nsystem endowed with the virtues of temperance and friendship to humans would\nnot pose a control problem as it would not have the desire for limitless\nself-improvement.", "authors": ["Nicolas Berberich", "Klaus Diepold"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10322v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10322v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10322v1", "published_time": "6/27/2018", "rawpid": "1806.10322", "tags": ["cs.AI"], "title": "The Virtuous Machine - Old Ethics for New Technology?"}, {"abstract": "Advances in deep learning have led to substantial increases in prediction\naccuracy but have been accompanied by increases in the cost of rendering\npredictions. We conjecture that fora majority of real-world inputs, the recent\nadvances in deep learning have created models that effectively \"overthink\" on\nsimple inputs. In this paper, we revisit the classic question of building model\ncascades that primarily leverage class asymmetry to reduce cost. We introduce\nthe \"I Don\u0027t Know\"(IDK) prediction cascades framework, a general framework to\nsystematically compose a set of pre-trained models to accelerate inference\nwithout a loss in prediction accuracy. We propose two search based methods for\nconstructing cascades as well as a new cost-aware objective within this\nframework. The proposed IDK cascade framework can be easily adopted in the\nexisting model serving systems without additional model re-training. We\nevaluate the proposed techniques on a range of benchmarks to demonstrate the\neffectiveness of the proposed framework.", "authors": ["Xin Wang", "Yujia Luo", "Daniel Crankshaw", "Alexey Tumanov", "Fisher Yu", "Joseph E. Gonzalez"], "category": "cs.CV", "comment": "UAI 2018 camera ready", "img": "/static/thumbs/1706.00885v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.00885v4", "num_discussion": 0, "originally_published_time": "6/3/2017", "pid": "1706.00885v4", "published_time": "6/27/2018", "rawpid": "1706.00885", "tags": ["cs.CV", "cs.LG"], "title": "IDK Cascades: Fast Deep Learning by Learning not to Overthink"}, {"abstract": "In this report, our approach to tackling the task of ActivityNet 2018\nKinetics-600 challenge is described in detail. Though spatial-temporal\nmodelling methods, which adopt either such end-to-end framework as I3D\n\\cite{i3d} or two-stage frameworks (i.e., CNN+RNN), have been proposed in\nexisting state-of-the-arts for this task, video modelling is far from being\nwell solved. In this challenge, we propose spatial-temporal network (StNet) for\nbetter joint spatial-temporal modelling and comprehensively video\nunderstanding. Besides, given that multi-modal information is contained in\nvideo source, we manage to integrate both early-fusion and later-fusion\nstrategy of multi-modal information via our proposed improved temporal Xception\nnetwork (iTXN) for video understanding. Our StNet RGB single model achieves\n78.99\\% top-1 precision in the Kinetics-600 validation set and that of our\nimproved temporal Xception network which integrates RGB, flow and audio\nmodalities is up to 82.35\\%. After model ensemble, we achieve top-1 precision\nas high as 85.0\\% on the validation set and rank No.1 among all submissions.", "authors": ["Dongliang He", "Fu Li", "Qijie Zhao", "Xiang Long", "Yi Fu", "Shilei Wen"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10319v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10319v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10319v1", "published_time": "6/27/2018", "rawpid": "1806.10319", "tags": ["cs.CV"], "title": "Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human\n  Action Recognition"}, {"abstract": "This paper investigates to what extent cognitive biases may affect human\nunderstanding of interpretable machine learning models, in particular of rules\ndiscovered from data. Twenty cognitive biases are covered, as are possible\ndebiasing techniques that can be adopted by designers of machine learning\nalgorithms and software. Our review transfers results obtained in cognitive\npsychology to the domain of machine learning, aiming to bridge the current gap\nbetween these two areas. It needs to be followed by empirical studies\nspecifically aimed at the machine learning domain.", "authors": ["Tom\u00e1\u0161 Kliegr", "\u0160t\u011bp\u00e1n Bahn\u00edk", "Johannes F\u00fcrnkranz"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1804.02969v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.02969v3", "num_discussion": 0, "originally_published_time": "4/9/2018", "pid": "1804.02969v3", "published_time": "6/27/2018", "rawpid": "1804.02969", "tags": ["stat.ML", "cs.AI", "cs.LG"], "title": "A review of possible effects of cognitive biases on interpretation of\n  rule-based machine learning models"}, {"abstract": "Recent advances in neural autoregressive models have improve the performance\nof speech synthesis (SS). However, as they lack the ability to model global\ncharacteristics of speech (such as speaker individualities or speaking styles),\nparticularly when these characteristics have not been labeled, making neural\nautoregressive SS systems more expressive is still an open issue. In this\npaper, we propose to combine VoiceLoop, an autoregressive SS model, with\nVariational Autoencoder (VAE). This approach, unlike traditional autoregressive\nSS systems, uses VAE to model the global characteristics explicitly, enabling\nthe expressiveness of the synthesized speech to be controlled in an\nunsupervised manner. Experiments using the VCTK and Blizzard2012 datasets show\nthe VAE helps VoiceLoop to generate higher quality speech and to control the\nexpressions in its synthesized speech by incorporating global characteristics\ninto the speech generating process.", "authors": ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "category": "cs.CL", "comment": "Accepted by Interspeech 2018", "img": "/static/thumbs/1804.02135v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.02135v2", "num_discussion": 0, "originally_published_time": "4/6/2018", "pid": "1804.02135v2", "published_time": "6/27/2018", "rawpid": "1804.02135", "tags": ["cs.CL", "cs.SD", "eess.AS"], "title": "Expressive Speech Synthesis via Modeling Expressions with Variational\n  Autoencoder"}, {"abstract": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach.", "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Avirup Bhattacharyya", "Umapada Pal"], "category": "cs.CV", "comment": "(Submitted)", "img": "/static/thumbs/1708.05529v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1708.05529v5", "num_discussion": 0, "originally_published_time": "8/18/2017", "pid": "1708.05529v5", "published_time": "6/27/2018", "rawpid": "1708.05529", "tags": ["cs.CV", "cs.IR"], "title": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding"}, {"abstract": "Bayesian neural networks (BNNs) allow us to reason about uncertainty in a\nprincipled way. Stochastic Gradient Langevin Dynamics (SGLD) enables efficient\nBNN learning by drawing samples from the BNN posterior using mini-batches.\nHowever, SGLD and its extensions require storage of many copies of the model\nparameters, a potentially prohibitive cost, especially for large neural\nnetworks. We propose a framework, Adversarial Posterior Distillation, to\ndistill the SGLD samples using a Generative Adversarial Network (GAN). At\ntest-time, samples are generated by the GAN. We show that this distillation\nframework incurs no loss in performance on recent BNN applications including\nanomaly detection, active learning, and defense against adversarial attacks. By\nconstruction, our framework not only distills the Bayesian predictive\ndistribution, but the posterior itself. This allows one to compute quantities\nsuch as the approximate model variance, which is useful in downstream tasks. To\nour knowledge, these are the first results applying MCMC-based BNNs to the\naforementioned downstream applications.", "authors": ["Kuan-Chieh Wang", "Paul Vicol", "James Lucas", "Li Gu", "Roger Grosse", "Richard Zemel"], "category": "cs.LG", "comment": "accepted at ICML 2018", "img": "/static/thumbs/1806.10317v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10317v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10317v1", "published_time": "6/27/2018", "rawpid": "1806.10317", "tags": ["cs.LG", "stat.ML"], "title": "Adversarial Distillation of Bayesian Neural Network Posteriors"}, {"abstract": "In this paper, we consider matrix completion from non-uniformly sampled\nentries including fully observed and partially observed columns. Specifically,\nwe assume that a small number of columns are randomly selected and fully\nobserved, and each remaining column is partially observed with uniform\nsampling. To recover the unknown matrix, we first recover its column space from\nthe fully observed columns. Then, for each partially observed column, we\nrecover it by finding a vector which lies in the recovered column space and\nconsists of the observed entries. When the unknown $m\\times n$ matrix is\nlow-rank, we show that our algorithm can exactly recover it from merely\n$\\Omega(rn\\ln n)$ entries, where $r$ is the rank of the matrix. Furthermore,\nfor a noisy low-rank matrix, our algorithm computes a low-rank approximation of\nthe unknown matrix and enjoys an additive error bound measured by Frobenius\nnorm. Experimental results on synthetic datasets verify our theoretical claims\nand demonstrate the effectiveness of our proposed algorithm.", "authors": ["Yuanyu Wan", "Jinfeng Yi", "Lijun Zhang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10308v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10308v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10308v1", "published_time": "6/27/2018", "rawpid": "1806.10308", "tags": ["cs.LG", "stat.ML"], "title": "Matrix Completion from Non-Uniformly Sampled Entries"}, {"abstract": "In automatic speech recognition (ASR) systems, recurrent neural network\nlanguage models (RNNLM) are used to rescore a word lattice or N-best hypotheses\nlist. Due to the expensive training, the RNNLM\u0027s vocabulary set accommodates\nonly small shortlist of most frequent words. This leads to suboptimal\nperformance if an input speech contains many out-of-shortlist (OOS) words. An\neffective solution is to increase the shortlist size and retrain the entire\nnetwork which is highly inefficient. Therefore, we propose an efficient method\nto expand the shortlist set of a pretrained RNNLM without incurring expensive\nretraining and using additional training data. Our method exploits the\nstructure of RNNLM which can be decoupled into three parts: input projection\nlayer, middle layers, and output projection layer. Specifically, our method\nexpands the word embedding matrices in projection layers and keeps the middle\nlayers unchanged. In this approach, the functionality of the pretrained RNNLM\nwill be correctly maintained as long as OOS words are properly modeled in two\nembedding spaces. We propose to model the OOS words by borrowing linguistic\nknowledge from appropriate in-shortlist words. Additionally, we propose to\ngenerate the list of OOS words to expand vocabulary in unsupervised manner by\nautomatically extracting them from ASR output.", "authors": ["Yerbolat Khassanov", "Eng Siong Chng"], "category": "cs.CL", "comment": "5 pages, 1 figure, accepted at INTERSPEECH 2018", "img": "/static/thumbs/1806.10306v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10306v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10306v1", "published_time": "6/27/2018", "rawpid": "1806.10306", "tags": ["cs.CL"], "title": "Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural\n  Network Language Models in ASR"}, {"abstract": "The unclear development direction of human society is a deep reason for that\nit is difficult to form a uniform ethical standard for human society and\nartificial intelligence. Since the 21st century, the latest advances in the\nInternet, brain science and artificial intelligence have brought new\ninspiration to the research on the development direction of human society.\nThrough the study of the Internet brain model, AI IQ evaluation, and the\nevolution of the brain, this paper proposes that the evolution of population\nknowledge base is the key for judging the development direction of human\nsociety, thereby discussing the standards and norms for the construction of\nartificial intelligence ethics.", "authors": ["Feng Liu", "Yong Shi"], "category": "cs.OH", "comment": "13 pages, 6 figures,1 table", "img": "/static/thumbs/1806.10095v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10095v2", "num_discussion": 0, "originally_published_time": "6/9/2018", "pid": "1806.10095v2", "published_time": "6/27/2018", "rawpid": "1806.10095", "tags": ["cs.OH", "cs.AI", "cs.CY"], "title": "Research on Artificial Intelligence Ethics Based on the Evolution of\n  Population Knowledge Base"}, {"abstract": "In image fusion task, feature extraction and processing are keys to fusion\nalgorithm. And most of deep learning-based methods use deep features directly\nwithout feature processing. This will lead to the fusion performance\ndegradation in some cases. To solve this drawback, in this paper, a novel\nfusion framework which is based on deep features and zero-phase component\nanalysis(ZCA) is proposed. Firstly, the residual network(ResNet) is used to\nextract deep features from source images. Then ZCA and l_1-norm are utilized to\nnormalize the deep features and obtain initial weight maps. And the final\nweight maps are obtained by initial weight maps and soft-max operation.\nFinally, the fused image is reconstructed by weighted-averaging strategy.\nCompared with the existing fusion methods, experimental results demonstrate\nthat our algorithm achieves better performance in both objective assessment and\nvisual quality. And the code of our fusion algorithm is available at\nhttps://github.com/exceptionLi/imagefusion_resnet50", "authors": ["Hui Li", "Xiao-Jun Wu"], "category": "cs.CV", "comment": "15pages, 8 figures, 7 tables", "img": "/static/thumbs/1806.07119v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.07119v2", "num_discussion": 0, "originally_published_time": "6/19/2018", "pid": "1806.07119v2", "published_time": "6/27/2018", "rawpid": "1806.07119", "tags": ["cs.CV"], "title": "Infrared and Visible Image Fusion with ResNet and zero-phase component\n  analysis"}, {"abstract": "We propose a new regularization method based on virtual adversarial loss: a\nnew measure of local smoothness of the conditional label distribution given\ninput. Virtual adversarial loss is defined as the robustness of the conditional\nlabel distribution around each input data point against local perturbation.\nUnlike adversarial training, our method defines the adversarial direction\nwithout label information and is hence applicable to semi-supervised learning.\nBecause the directions in which we smooth the model are only \"virtually\"\nadversarial, we call our method virtual adversarial training (VAT). The\ncomputational cost of VAT is relatively low. For neural networks, the\napproximated gradient of virtual adversarial loss can be computed with no more\nthan two pairs of forward- and back-propagations. In our experiments, we\napplied VAT to supervised and semi-supervised learning tasks on multiple\nbenchmark datasets. With a simple enhancement of the algorithm based on the\nentropy minimization principle, our VAT achieves state-of-the-art performance\nfor semi-supervised learning tasks on SVHN and CIFAR-10.", "authors": ["Takeru Miyato", "Shin-ichi Maeda", "Masanori Koyama", "Shin Ishii"], "category": "stat.ML", "comment": "To be appeared in IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "img": "/static/thumbs/1704.03976v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.03976v2", "num_discussion": 0, "originally_published_time": "4/13/2017", "pid": "1704.03976v2", "published_time": "6/27/2018", "rawpid": "1704.03976", "tags": ["stat.ML", "cs.LG"], "title": "Virtual Adversarial Training: A Regularization Method for Supervised and\n  Semi-Supervised Learning"}, {"abstract": "In this paper, we study the problem of learning vision-based dynamic\nmanipulation skills using a scalable reinforcement learning approach. We study\nthis problem in the context of grasping, a longstanding challenge in robotic\nmanipulation. In contrast to static learning behaviors that choose a grasp\npoint and then execute the desired grasp, our method enables closed-loop\nvision-based control, whereby the robot continuously updates its grasp strategy\nbased on the most recent observations to optimize long-horizon grasp success.\nTo that end, we introduce QT-Opt, a scalable self-supervised vision-based\nreinforcement learning framework that can leverage over 580k real-world grasp\nattempts to train a deep neural network Q-function with over 1.2M parameters to\nperform closed-loop, real-world grasping that generalizes to 96% grasp success\non unseen objects. Aside from attaining a very high success rate, our method\nexhibits behaviors that are quite distinct from more standard grasping systems:\nusing only RGB vision-based perception from an over-the-shoulder camera, our\nmethod automatically learns regrasping strategies, probes objects to find the\nmost effective grasps, learns to reposition objects and perform other\nnon-prehensile pre-grasp manipulations, and responds dynamically to\ndisturbances and perturbations.", "authors": ["Dmitry Kalashnikov", "Alex Irpan", "Peter Pastor", "Julian Ibarz", "Alexander Herzog", "Eric Jang", "Deirdre Quillen", "Ethan Holly", "Mrinal Kalakrishnan", "Vincent Vanhoucke", "Sergey Levine"], "category": "cs.LG", "comment": "22 pages, 14 figures", "img": "/static/thumbs/1806.10293v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10293v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10293v1", "published_time": "6/27/2018", "rawpid": "1806.10293", "tags": ["cs.LG", "cs.AI", "cs.CV", "cs.RO", "stat.ML"], "title": "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic\n  Manipulation"}, {"abstract": "Occlusions, complex backgrounds, scale variations and non-uniform\ndistributions present great challenges for crowd counting in practical\napplications. In this paper, we propose a novel method using an attention model\nto exploit head locations which are the most important cue for crowd counting.\nThe attention model estimates a probability map in which high probabilities\nindicate locations where heads are likely to be present. The estimated\nprobability map is used to suppress non-head regions in feature maps from\nseveral multi-scale feature extraction branches of a convolution neural network\nfor crowd density estimation, which makes our method robust to complex\nbackgrounds, scale variations and non-uniform distributions. In addition, we\nintroduce a relative deviation loss to compensate a commonly used training\nloss, Euclidean distance, to improve the accuracy of sparse crowd density\nestimation. Experiments on Shanghai-Tech, UCF_CC_50 and World-Expo\u002710 data sets\ndemonstrate the effectiveness of our method.", "authors": ["Youmei Zhang", "Chunluan Zhou", "Faliang Chang", "Alex C. Kot"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10287v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10287v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10287v1", "published_time": "6/27/2018", "rawpid": "1806.10287", "tags": ["cs.CV"], "title": "Attention to Head Locations for Crowd Counting"}, {"abstract": "Recently, researchers have discovered that the state-of-the-art object\nclassifiers can be fooled easily by small perturbations in the input\nunnoticeable to human eyes. It is also known that an attacker can generate\nstrong adversarial examples if she knows the classifier parameters. Conversely,\na defender can robustify the classifier by retraining if she has access to the\nadversarial examples. We explain and formulate this adversarial example problem\nas a two-player continuous zero-sum game, and demonstrate the fallacy of\nevaluating a defense or an attack as a static problem. To find the best\nworst-case defense against whitebox attacks, we propose a continuous minimax\noptimization algorithm. We demonstrate the minimax defense with two types of\nattack classes -- gradient-based and neural network-based attacks. Experiments\nwith the MNIST and the CIFAR-10 datasets demonstrate that the defense found by\nnumerical minimax optimization is indeed more robust than non-minimax defenses.\nWe discuss directions for improving the result toward achieving robustness\nagainst multiple types of attack classes.", "authors": ["Jihun Hamm", "Akshay Mehra"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1711.04368v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1711.04368v3", "num_discussion": 0, "originally_published_time": "11/12/2017", "pid": "1711.04368v3", "published_time": "6/27/2018", "rawpid": "1711.04368", "tags": ["cs.LG", "stat.ML"], "title": "Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples"}, {"abstract": "Optimal scheduling of hydrogen production in dynamic pricing power market can\nmaximize the profit of hydrogen producer; however, it highly depends on the\naccurate forecast of hydrogen consumption. In this paper, we propose a deep\nleaning based forecasting approach for predicting hydrogen consumption of fuel\ncell vehicles in future taxi industry. The cost of hydrogen production is\nminimized by utilizing the proposed forecasting tool to reduce the hydrogen\nproduced during high cost on-peak hours and guide hydrogen producer to store\nsufficient hydrogen during low cost off-peak hours.", "authors": ["Yusheng Luo", "Min Xian", "Manish Mohanpurkar", "Bishnu P. Bhattarai", "Anudeep Medam", "Rahul Kadavil", "Rob Hovsapian"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10283v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10283v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10283v1", "published_time": "6/27/2018", "rawpid": "1806.10283", "tags": ["cs.LG", "stat.ML"], "title": "Optimal Scheduling of Electrolyzer in Power Market with Dynamic Prices"}, {"abstract": "Deep reinforcement learning has achieved many recent successes, but our\nunderstanding of its strengths and limitations is hampered by the lack of rich\nenvironments in which we can fully characterize optimal behavior, and\ncorrespondingly diagnose individual actions against such a characterization.\nHere we consider a family of combinatorial games, arising from work of Erdos,\nSelfridge, and Spencer, and we propose their use as environments for evaluating\nand comparing different approaches to reinforcement learning. These games have\na number of appealing features: they are challenging for current learning\napproaches, but they form (i) a low-dimensional, simply parametrized\nenvironment where (ii) there is a linear closed form solution for optimal\nbehavior from any state, and (iii) the difficulty of the game can be tuned by\nchanging environment parameters in an interpretable way. We use these\nErdos-Selfridge-Spencer games not only to compare different algorithms, but\ntest for generalization, make comparisons to supervised learning, analyse\nmultiagent play, and even develop a self play algorithm.", "authors": ["Maithra Raghu", "Alex Irpan", "Jacob Andreas", "Robert Kleinberg", "Quoc V. Le", "Jon Kleinberg"], "category": "cs.AI", "comment": "Accepted to ICML 2018", "img": "/static/thumbs/1711.02301v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1711.02301v4", "num_discussion": 0, "originally_published_time": "11/7/2017", "pid": "1711.02301v4", "published_time": "6/27/2018", "rawpid": "1711.02301", "tags": ["cs.AI", "cs.NE", "stat.ML"], "title": "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?"}, {"abstract": "While neural architecture search (NAS) has drawn increasing attention for\nautomatically tuning deep neural networks, existing search algorithms usually\nsuffer from expensive computational cost. Network morphism, which keeps the\nfunctionality of a neural network while changing its neural architecture, could\nbe helpful for NAS by enabling a more efficient training during the search.\nHowever, network morphism based NAS is still computationally expensive due to\nthe inefficient process of selecting the proper morph operation for existing\narchitectures. As we know, Bayesian optimization has been widely used to\noptimize functions based on a limited number of observations, motivating us to\nexplore the possibility of making use of Bayesian optimization to accelerate\nthe morph operation selection process. In this paper, we propose a novel\nframework enabling Bayesian optimization to guide the network morphism for\nefficient neural architecture search by introducing a neural network kernel and\na tree-structured acquisition function optimization algorithm. With Bayesian\noptimization to select the network morphism operations, the exploration of the\nsearch space is more efficient. Moreover, we carefully wrapped our method into\nan open-source software, namely Auto-Keras for people without rich machine\nlearning background to use. Intensive experiments on real-world datasets have\nbeen done to demonstrate the superior performance of the developed framework\nover the state-of-the-art baseline methods.", "authors": ["Haifeng Jin", "Qingquan Song", "Xia Hu"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10282v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10282v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10282v1", "published_time": "6/27/2018", "rawpid": "1806.10282", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Efficient Neural Architecture Search with Network Morphism"}, {"abstract": "Traditional image stitching algorithms use transforms such as homography to\ncombine different views of a scene. They usually work well when the scene is\nplanar or when the camera is only rotated, keeping its position static. This\nseverely limits their use in real world scenarios where an unmanned aerial\nvehicle (UAV) potentially hovers around and flies in an enclosed area while\nrotating to capture a video sequence. We utilize known scene geometry along\nwith recorded camera trajectory to create cylindrical images captured in a\ngiven environment such as a tunnel where the camera rotates around its center.\nThe captured images of the inner surface of the given scene are combined to\ncreate a composite panoramic image that is textured onto a 3D geometrical\nobject in Unity graphical engine to create an immersive environment for end\nusers.", "authors": ["Ramanpreet Singh Pahwa", "Wei Kiat Leong", "Shaohui Foong", "Karianto Leman", "Minh N. Do"], "category": "cs.CV", "comment": "6 pages", "img": "/static/thumbs/1806.10278v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10278v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10278v1", "published_time": "6/27/2018", "rawpid": "1806.10278", "tags": ["cs.CV"], "title": "Feature-less Stitching of Cylindrical Tunnel"}, {"abstract": "Premature ventricular contraction(PVC) is a type of premature ectopic beat\noriginating from the ventricles. Automatic method for accurate and robust\ndetection of PVC is highly clinically desired.Currently, most of these methods\nare developed and tested using the same database divided into training and\ntesting set and their generalization performance across databases has not been\nfully validated. In this paper, a method based on densely connected\nconvolutional neural network and spatial pyramid pooling is proposed for PVC\ndetection which can take arbitrarily-sized QRS complexes as input both in\ntraining and testing. With a much less complicated and more straightforward\narchitecture,the proposed network achieves comparable results to current\nstate-of-the-art deep learning based method with regard to accuracy,sensitivity\nand specificity by training and testing using the MIT-BIH arrhythmia database\nas benchmark.Besides the benchmark database,QRS complexes are extracted from\nfour more open databases namely the St-Petersburg Institute of Cardiological\nTechnics 12-lead Arrhythmia Database,The MIT-BIH Normal Sinus Rhythm\nDatabase,The MIT-BIH Long Term Database and European ST-T Database. The\nextracted QRS complexes are different in length and sampling rate among the\nfive databases.Cross-database training and testing is also experimented.The\nperformance of the network shows an improvement on the benchmark database\naccording to the result demonstrating the advantage of using multiple databases\nfor training over using only a single database.The network also achieves\nsatisfactory scores on the other four databases showing good generalization\ncapability.", "authors": ["Jianning Li"], "category": "cs.CV", "comment": "7 figures, 4 Tables", "img": "/static/thumbs/1806.04564v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.04564v5", "num_discussion": 0, "originally_published_time": "6/12/2018", "pid": "1806.04564v5", "published_time": "6/27/2018", "rawpid": "1806.04564", "tags": ["cs.CV"], "title": "Detection of Premature Ventricular Contractions Using Densely Connected\n  Deep Convolutional Neural Network with Spatial Pyramid Pooling Layer"}, {"abstract": "Type B aortic dissection (TBAD) is a rare but life threatening disease.\nSegmentation of the entire aorta and truefalse lumen is crucial for the\nplanning and follow-up of endovascular repair of TBAD. Manual segmentation in a\nslice-wise manner is time-consuming and requires expert experience. Current\ncomputer-aided methods have several limitations like focusing only on a\nspecific part oftheaorta atatimeorrequiringhumaninteraction. Mostimportantly,\nthese methods can not segment the entire aorta and detect true-false lumen at\nthe same time. We report in this study a fully automatic approach based on\nmulti-task deep convolutional neural network that segments the entire aorta and\ntrue-false lumen fromCTA images in a unified framework.\nFortraining,webuiltadatabasecontaining254CTA images from both pre-operative and\npost-operative TBAD patients. These images are from multiple manufacturers.\nSlice-wise manual segmentation of the entire aorta and the true-false lumen for\neach 3-D CTA image is also provided. Our method is evaluated on 16 CTA data (11\npreoperative and 5 postoperative) whose ground truth segmentation is provided\nby experienced vascular surgeons.Resultsshow that our method can segment type B\naortic dissection with robustness and accuracy. Furthermore,our method can be\neasily extended to the segmentation of the entire aorta without dissection.", "authors": ["Jianning Li", "Long Cao", "Yangyang Ge", "Cheng W", "Bowen M", "Wei G"], "category": "cs.CV", "comment": "9 pages", "img": "/static/thumbs/1806.09860v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09860v2", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09860v2", "published_time": "6/27/2018", "rawpid": "1806.09860", "tags": ["cs.CV"], "title": "Multi-Task Deep Convolutional Neural Network for the Segmentation of\n  Type B Aortic Dissection"}, {"abstract": "Two fundamental problems in computational game theory are computing a Nash\nequilibrium and learning to exploit opponents given observations of their play\n(opponent exploitation). The latter is perhaps even more important than the\nformer: Nash equilibrium does not have a compelling theoretical justification\nin game classes other than two-player zero-sum, and for all games one can\npotentially do better by exploiting perceived weaknesses of the opponent than\nby following a static equilibrium strategy throughout the match. The natural\nsetting for opponent exploitation is the Bayesian setting where we have a prior\nmodel that is integrated with observations to create a posterior opponent model\nthat we respond to. The most natural, and a well-studied prior distribution is\nthe Dirichlet distribution. An exact polynomial-time algorithm is known for\nbest-responding to the posterior distribution for an opponent assuming a\nDirichlet prior with multinomial sampling in normal-form games; however, for\nimperfect-information games the best known algorithm is based on approximating\nan infinite integral without theoretical guarantees. We present the first exact\nalgorithm for a natural class of imperfect-information games. We demonstrate\nthat our algorithm runs quickly in practice and outperforms the best prior\napproaches. We also present an algorithm for the uniform prior setting.", "authors": ["Sam Ganzfried", "Qingyun Sun"], "category": "cs.GT", "comment": "", "img": "/static/thumbs/1603.03491v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1603.03491v5", "num_discussion": 0, "originally_published_time": "3/10/2016", "pid": "1603.03491v5", "published_time": "6/27/2018", "rawpid": "1603.03491", "tags": ["cs.GT", "cs.AI", "cs.MA", "math.PR", "stat.CO"], "title": "Bayesian Opponent Exploitation in Imperfect-Information Games"}, {"abstract": "Primary object segmentation plays an important role in understanding videos\ngenerated by unmanned aerial vehicles. In this paper, we propose a large-scale\ndataset APD with 500 aerial videos, in which the primary objects are manually\nannotated on 5,014 sparsely sampled frames. To the best of our knowledge, it is\nthe largest dataset to date for the task of primary object segmentation in\naerial videos. From this dataset, we find that most aerial videos contain\nlarge-scale scenes, small sized primary objects as well as consistently varying\nscales and viewpoints. Inspired by that, we propose a novel hierarchical\ntemporal slicing approach that repeatedly divides a video into two sub-videos\nformed by the odd and even frames, respectively. In this manner, an aerial\nvideo can be represented by a set of hierarchically organized short video\nclips, and the primary objects they share can be segmented by training\nend-to-end co-segmentation CNNs and finally refined within the neighborhood\nreversible flows. Experimental results show that our approach remarkably\noutperforms 24 state-of-the-art methods in segmenting primary objects in\nvarious types of aerial videos.", "authors": ["Pengcheng Yuan", "Jia Li", "Daxin Gu", "Yonghong Tian"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10274v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10274v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10274v1", "published_time": "6/27/2018", "rawpid": "1806.10274", "tags": ["cs.CV"], "title": "Primary Object Segmentation in Aerial Videos via Hierarchical Temporal\n  Slicing and Co-Segmentation"}, {"abstract": "Many modern machine learning models are trained to achieve zero or near-zero\ntraining error in order to obtain near-optimal (but non-zero) test error. This\nphenomenon of strong generalization performance for \"overfitted\" / interpolated\nclassifiers appears to be ubiquitous in high-dimensional data, having been\nobserved in deep networks, kernel machines, boosting and random forests. Their\nperformance is robust even when the data contain large amounts of label noise.\n  Very little theory is available to explain these observations. The vast\nmajority of theoretical analyses of generalization allows for interpolation\nonly when there is little or no label noise. This paper takes a step toward a\ntheoretical foundation for interpolated classifiers by analyzing local\ninterpolating schemes, including geometric simplicial interpolation algorithm\nand weighted $k$-nearest neighbor schemes. Consistency or near-consistency is\nproved for these schemes in classification and regression problems. These\nschemes have an inductive bias that benefits from higher dimension, a kind of\n\"blessing of dimensionality\". Finally, connections to kernel machines, random\nforests, and adversarial examples in the interpolated regime are discussed.", "authors": ["Mikhail Belkin", "Daniel Hsu", "Partha Mitra"], "category": "stat.ML", "comment": "Improved analysis of weighted k-NN regression", "img": "/static/thumbs/1806.05161v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.05161v2", "num_discussion": 0, "originally_published_time": "6/13/2018", "pid": "1806.05161v2", "published_time": "6/27/2018", "rawpid": "1806.05161", "tags": ["stat.ML", "cond-mat.stat-mech", "cs.LG"], "title": "Overfitting or perfect fitting? Risk bounds for classification and\n  regression rules that interpolate"}, {"abstract": "Machine Learning models have proved extremely successful for a wide variety\nof supervised learning problems, but the predictions of many of these models\nare difficult to interpret. A recent literature interprets the predictions of\nmore general \"black-box\" machine learning models by approximating these models\nin terms of simpler models such as piecewise linear or piecewise constant\nmodels. Existing literature constructs these approximations in an ad-hoc\nmanner. We provide a tractable dynamic programming algorithm that partitions\nthe feature space into clusters in a principled way and then uses this\npartition to provide both piecewise constant and piecewise linear\ninterpretations of an arbitrary \"black-box\" model. When loss is measured in\nterms of mean squared error, our approximation is optimal (under certain\nconditions); for more general loss functions, our interpretation is probably\napproximately optimal (in the sense of PAC learning). Experiments with real and\nsynthetic data show that it continues to provide significant improvements (in\nterms of mean squared error) over competing approaches.", "authors": ["Kartik Ahuja", "William R. Zame", "Mihaela van der Schaar"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10270v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10270v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10270v1", "published_time": "6/27/2018", "rawpid": "1806.10270", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Piecewise Approximations of Black Box Models for Model Interpretation"}, {"abstract": "Per-pixel masks of semantic objects are very useful in many applications,\nwhich, however, are tedious to be annotated. In this paper, we propose a\nhuman-agent collaborative annotation approach that can efficiently generate\nper-pixel masks of semantic objects in tagged images with multi-granularity\nsupervisions. Given a set of tagged image, a computer agent is first\ndynamically generated to roughly localize the semantic objects described by the\ntag. The agent first extracts massive object proposals from an image and then\ninfer the tag-related ones under the weak and strong supervisions from\nlinguistically and visually similar images and previously annotated object\nmasks. By representing such supervisions by over-complete dictionaries, the\ntag-related object proposals can pop-out according to their sparse coding\nlength, which are then converted to superpixels with binary labels. After that,\nhuman annotators participate in the annotation process by flipping labels and\ndividing superpixels with mouse clicks, which are used as click supervisions\nthat teach the agent to recover false positives/negatives in processing images\nwith the same tags. Experimental results show that our approach can facilitate\nthe annotation process and generate object masks that are highly consistent\nwith those generated by the LabelMe toolbox.", "authors": ["Lishi Zhang", "Chenghan Fu", "Jia Li"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10269v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10269v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10269v1", "published_time": "6/27/2018", "rawpid": "1806.10269", "tags": ["cs.CV"], "title": "Collaborative Annotation of Semantic Objects in Images with\n  Multi-granularity Supervisions"}, {"abstract": "The objective of this paper is speaker recognition under noisy and\nunconstrained conditions.\n  We make two key contributions. First, we introduce a very large-scale\naudio-visual speaker recognition dataset collected from open-source media.\nUsing a fully automated pipeline, we curate VoxCeleb2 which contains over a\nmillion utterances from over 6,000 speakers. This is several times larger than\nany publicly available speaker recognition dataset.\n  Second, we develop and compare Convolutional Neural Network (CNN) models and\ntraining strategies that can effectively recognise identities from voice under\nvarious conditions. The models trained on the VoxCeleb2 dataset surpass the\nperformance of previous works on a benchmark dataset by a significant margin.", "authors": ["Joon Son Chung", "Arsha Nagrani", "Andrew Zisserman"], "category": "cs.SD", "comment": "To appear in Interspeech 2018. The audio-visual dataset can be\n  downloaded from http://www.robots.o...", "img": "/static/thumbs/1806.05622v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.05622v2", "num_discussion": 0, "originally_published_time": "6/14/2018", "pid": "1806.05622v2", "published_time": "6/27/2018", "rawpid": "1806.05622", "tags": ["cs.SD", "cs.CV", "eess.AS"], "title": "VoxCeleb2: Deep Speaker Recognition"}, {"abstract": "In the area of human fixation prediction, dozens of computational saliency\nmodels are proposed to reveal certain saliency characteristics under different\nassumptions and definitions. As a result, saliency model benchmarking often\nrequires several evaluation metrics to simultaneously assess saliency models\nfrom multiple perspectives. However, most computational metrics are not\ndesigned to directly measure the perceptual similarity of saliency maps so that\nthe evaluation results may be sometimes inconsistent with the subjective\nimpression. To address this problem, this paper first conducts extensive\nsubjective tests to find out how the visual similarities between saliency maps\nare perceived by humans. Based on the crowdsourced data collected in these\ntests, we conclude several key factors in assessing saliency maps and quantize\nthe performance of existing metrics. Inspired by these factors, we propose to\nlearn a saliency evaluation metric based on a two-stream convolutional neural\nnetwork using crowdsourced perceptual judgements. Specifically, the relative\nsaliency score of each pair from the crowdsourced data is utilized to\nregularize the network during the training process. By capturing the key\nfactors shared by various subjects in comparing saliency maps, the learned\nmetric better aligns with human perception of saliency maps, making it a good\ncomplement to the existing metrics. Experimental results validate that the\nlearned metric can be generalized to the comparisons of saliency maps from new\nimages, new datasets, new models and synthetic data. Due to the effectiveness\nof the learned metric, it also can be used to facilitate the development of new\nmodels for fixation prediction.", "authors": ["Changqun Xia", "Jia Li", "Jinming Su", "Ali Borji"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10257v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10257v1", "num_discussion": 0, "originally_published_time": "6/27/2018", "pid": "1806.10257v1", "published_time": "6/27/2018", "rawpid": "1806.10257", "tags": ["cs.CV"], "title": "Learning a Saliency Evaluation Metric Using Crowdsourced Perceptual\n  Judgments"}, {"abstract": "In this paper we study generative modeling via autoencoders while using the\nelegant geometric properties of the optimal transport (OT) problem and the\nWasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE),\nwhich are generative models that enable one to shape the distribution of the\nlatent space into any samplable probability distribution without the need for\ntraining an adversarial network or defining a closed-form for the distribution.\nIn short, we regularize the autoencoder loss with the sliced-Wasserstein\ndistance between the distribution of the encoded training samples and a\npredefined samplable distribution. We show that the proposed formulation has an\nefficient numerical solution that provides similar capabilities to Wasserstein\nAutoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an\nembarrassingly simple implementation.", "authors": ["Soheil Kolouri", "Phillip E. Pope", "Charles E. Martin", "Gustavo K. Rohde"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1804.01947v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.01947v3", "num_discussion": 0, "originally_published_time": "4/5/2018", "pid": "1804.01947v3", "published_time": "6/27/2018", "rawpid": "1804.01947", "tags": ["cs.LG", "stat.ML"], "title": "Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative\n  Model"}, {"abstract": "In many robotic applications, an autonomous agent must act within and explore\na partially observed environment that is unobserved by its human teammate. We\nconsider such a setting in which the agent can, while acting, transmit\ndeclarative information to the human that helps them understand aspects of this\nunseen environment. Naturally, the human will have preferences about what\ninformation they are given. This work adopts an information-theoretic view of\nthe human\u0027s preferences: the human scores information based on the induced\nchange in weighted entropy of their belief about the environment state. We\nformulate this setting as a belief MDP and give an algorithm for solving it\napproximately. Then, we give an algorithm that allows the agent to learn the\nhuman\u0027s preferences online. We validate our approach experimentally in\nsimulated discrete and continuous partially observed search-and-recover\ndomains.", "authors": ["Rohan Chitnis", "Leslie Pack Kaelbling", "Tom\u00e1s Lozano-P\u00e9rez"], "category": "cs.AI", "comment": "Updated problem formulation, added figure showing example execution", "img": "/static/thumbs/1805.08263v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.08263v3", "num_discussion": 0, "originally_published_time": "5/21/2018", "pid": "1805.08263v3", "published_time": "6/26/2018", "rawpid": "1805.08263", "tags": ["cs.AI", "cs.RO"], "title": "Planning to Give Information in Partially Observed Domains with a\n  Learned Weighted Entropy Model"}, {"abstract": "We examine the phase transition phenomenon for the Knapsack problem from both\na computational and a human perspective. We first provide, via an empirical and\na theoretical analysis, a characterization of the phenomenon in terms of two\ninstance properties; normalised capacity and normalised profit. Then, we show\nevidence that average time spent by human decision makers in solving an\ninstance peaks near the phase transition. Given the ubiquity of the Knapsack\nproblem in every-day life, a better understanding of its structure can improve\nour understanding not only of computational techniques but also of human\nbehavior, including the use and development of heuristics and occurrence of\nbiases.", "authors": ["Nitin Yadav", "Carsten Murawski", "Sebastian Sardina", "Peter Bossaerts"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10244v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10244v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10244v1", "published_time": "6/26/2018", "rawpid": "1806.10244", "tags": ["cs.AI", "cs.CC"], "title": "Phase transition in the knapsack problem"}, {"abstract": "Gaussian processes (GPs) offer a flexible class of priors for nonparametric\nBayesian regression, but popular GP posterior inference methods are typically\nprohibitively slow or lack desirable finite-data guarantees on quality. We\ndevelop an approach to scalable approximate GP regression with finite-data\nguarantees on the accuracy of pointwise posterior mean and variance estimates.\nOur main contribution is a novel objective for approximate inference in the\nnonparametric setting: the \"preconditioned Fisher (pF) divergence.\" We show\nthat unlike popular divergences such as Kullback--Leibler (used in variational\ninference), the pF divergence bounds the 2-Wasserstein distance, which in turn\nbounds the pointwise difference of the mean and variance functions. We\ndemonstrate that, for sparse GP likelihood approximations, we can minimize the\npF divergence efficiently. Our experiments show that optimizing the pF\ndivergence has the same computational requirements as variational sparse GPs\nwhile providing comparable empirical performance---in addition to our novel\nfinite-data quality guarantees.", "authors": ["Jonathan H. Huggins", "Trevor Campbell", "Miko\u0142aj Kasprzak", "Tamara Broderick"], "category": "stat.ML", "comment": "19 pages, 5 figures", "img": "/static/thumbs/1806.10234v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10234v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10234v1", "published_time": "6/26/2018", "rawpid": "1806.10234", "tags": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "title": "Scalable Gaussian Process Inference with Finite-data Mean and Variance\n  Guarantees"}, {"abstract": "Many applications in machine learning require optimizing a function whose\ntrue gradient is unknown, but where surrogate gradient information (directions\nthat may be correlated with, but not necessarily identical to, the true\ngradient) is available instead. This arises when an approximate gradient is\neasier to compute than the full gradient (e.g. in meta-learning or unrolled\noptimization), or when a true gradient is intractable and is replaced with a\nsurrogate (e.g. in certain reinforcement learning applications, or when using\nsynthetic gradients). We propose Guided Evolutionary Strategies, a method for\noptimally using surrogate gradient directions along with random search. We\ndefine a search distribution for evolutionary strategies that is elongated\nalong a guiding subspace spanned by the surrogate gradients. This allows us to\nestimate a descent direction which can then be passed to a first-order\noptimizer. We analytically and numerically characterize the tradeoffs that\nresult from tuning how strongly the search distribution is stretched along the\nguiding subspace, and we use this to derive a setting of the hyperparameters\nthat works well across problems. Finally, we apply our method to example\nproblems including truncated unrolled optimization and a synthetic gradient\nproblem, demonstrating improvement over both standard evolutionary strategies\nand first-order methods that directly follow the surrogate gradient. We provide\na demo of Guided ES at:\nhttps://github.com/brain-research/guided-evolutionary-strategies.", "authors": ["Niru Maheswaranathan", "Luke Metz", "George Tucker", "Jascha Sohl-Dickstein"], "category": "cs.NE", "comment": "", "img": "/static/thumbs/1806.10230v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10230v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10230v1", "published_time": "6/26/2018", "rawpid": "1806.10230", "tags": ["cs.NE", "cs.LG", "stat.ML"], "title": "Guided evolutionary strategies: escaping the curse of dimensionality in\n  random search"}, {"abstract": "We consider the following conditional linear regression problem: the task is\nto identify both (i) a $k$-DNF condition $c$ and (ii) a linear rule $f$ such\nthat the probability of $c$ is (approximately) at least some given bound $\\mu$,\nand $f$ minimizes the $\\ell_p$ loss of predicting the target $z$ in the\ndistribution of examples conditioned on $c$. Thus, the task is to identify a\nportion of the distribution on which a linear rule can provide a good fit.\nAlgorithms for this task are useful in cases where simple, learnable rules only\naccurately model portions of the distribution. The prior state-of-the-art for\nsuch algorithms could only guarantee finding a condition of probability\n$\\Omega(\\mu/n^k)$ when a condition of probability $\\mu$ exists, and achieved an\n$O(n^k)$-approximation to the target loss, where $n$ is the number of Boolean\nattributes. Here, we give efficient algorithms for solving this task with a\ncondition $c$ that nearly matches the probability of the ideal condition, while\nalso improving the approximation to the target loss. We also give an algorithm\nfor finding a $k$-DNF reference class for prediction at a given query point,\nthat obtains a sparse regression fit that has loss within $O(n^k)$ of optimal\namong all sparse regression parameters and sufficiently large $k$-DNF reference\nclasses containing the query point.", "authors": ["John Hainline", "Brendan Juba", "Hai S. Le", "David Woodruff"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10222v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10222v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10222v1", "published_time": "6/26/2018", "rawpid": "1806.10222", "tags": ["cs.LG", "cs.DS", "stat.ML"], "title": "Conditional Sparse $\\ell_p$-norm Regression With Optimal Probability"}, {"abstract": "Recently, graph neural networks (GNNs) have revolutionized the field of graph\nrepresentation learning through effectively learned node embeddings, and\nachieved state-of-the-art results in tasks such as node classification and link\nprediction. However, current GNN methods are inherently flat and do not learn\nhierarchical representations of graphs---a limitation that is especially\nproblematic for the task of graph classification, where the goal is to predict\nthe label associated with an entire graph. Here we propose DiffPool, a\ndifferentiable graph pooling module that can generate hierarchical\nrepresentations of graphs and can be combined with various graph neural network\narchitectures in an end-to-end fashion. DiffPool learns a differentiable soft\ncluster assignment for nodes at each layer of a deep GNN, mapping nodes to a\nset of clusters, which then form the coarsened input for the next GNN layer.\nOur experimental results show that combining existing GNN methods with DiffPool\nyields an average improvement of 5-10% accuracy on graph classification\nbenchmarks, compared to all existing pooling approaches, achieving a new\nstate-of-the-art on four out of five benchmark data sets.", "authors": ["Rex Ying", "Jiaxuan You", "Christopher Morris", "Xiang Ren", "William L. Hamilton", "Jure Leskovec"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.08804v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.08804v2", "num_discussion": 0, "originally_published_time": "6/22/2018", "pid": "1806.08804v2", "published_time": "6/26/2018", "rawpid": "1806.08804", "tags": ["cs.LG", "cs.NE", "cs.SI", "stat.ML"], "title": "Hierarchical Graph Representation Learning with Differentiable Pooling"}, {"abstract": "In this paper, we introduce a new dataset for student engagement detection\nand localization. Digital revolution has transformed the traditional teaching\nprocedure and a result analysis of the student engagement in an e-learning\nenvironment would facilitate effective task accomplishment and learning. Well\nknown social cues of engagement/disengagement can be inferred from facial\nexpressions, body movements and gaze pattern. In this paper, student\u0027s response\nto various stimuli videos are recorded and important cues are extracted to\nestimate variations in engagement level. In this paper, we study the\nassociation of a subject\u0027s behavioral cues with his/her engagement level, as\nannotated by labelers. We then localize engaging/non-engaging parts in the\nstimuli videos using a deep multiple instance learning based framework, which\ncan give useful insight into designing Massive Open Online Courses (MOOCs)\nvideo material. Recognizing the lack of any publicly available dataset in the\ndomain of user engagement, a new `in the wild\u0027 dataset is created to study the\nsubject engagement problem. The dataset contains 195 videos captured from 78\nsubjects which is about 16.5 hours of recording. We present detailed baseline\nresults using different classifiers ranging from traditional machine learning\nto deep learning based approaches. The subject independent analysis is\nperformed so that it can be generalized to new users. The problem of engagement\nprediction is modeled as a weakly supervised learning problem. The dataset is\nmanually annotated by different labelers for four levels of engagement\nindependently and the correlation studies between annotated and predicted\nlabels of videos by different classifiers is reported. This dataset creation is\nan effort to facilitate research in various e-learning environments such as\nintelligent tutoring systems, MOOCs, and others.", "authors": ["Amanjot Kaur", "Aamir Mustafa", "Love Mehta", "Abhinav Dhall"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1804.00858v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.00858v4", "num_discussion": 0, "originally_published_time": "4/3/2018", "pid": "1804.00858v4", "published_time": "6/26/2018", "rawpid": "1804.00858", "tags": ["cs.CV"], "title": "Prediction and Localization of Student Engagement in the Wild"}, {"abstract": "Statistical language models (LM) play a key role in Automatic Speech\nRecognition (ASR) systems used by conversational agents. These ASR systems\nshould provide a high accuracy under a variety of speaking styles, domains,\nvocabulary and argots. In this paper, we present a DNN-based method to adapt\nthe LM to each user-agent interaction based on generalized contextual\ninformation, by predicting an optimal, context-dependent set of LM\ninterpolation weights. We show that this framework for contextual adaptation\nprovides accuracy improvements under different possible mixture LM partitions\nthat are relevant for both (1) Goal-oriented conversational agents where it\u0027s\nnatural to partition the data by the requested application and for (2) Non-goal\noriented conversational agents where the data can be partitioned using topic\nlabels that come from predictions of a topic classifier. We obtain a relative\nWER improvement of 3% with a 1-pass decoding strategy and 6% in a 2-pass\ndecoding framework, over an unadapted model. We also show up to a 15% relative\nimprovement in recognizing named entities which is of significant value for\nconversational ASR systems.", "authors": ["Anirudh Raju", "Behnam Hedayatnia", "Linda Liu", "Ankur Gandhe", "Chandra Khatri", "Angeliki Metallinou", "Anu Venkatesh", "Ariya Rastrow"], "category": "cs.CL", "comment": "Interspeech 2018", "img": "/static/thumbs/1806.10215v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10215v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10215v1", "published_time": "6/26/2018", "rawpid": "1806.10215", "tags": ["cs.CL", "I.2.7"], "title": "Contextual ASR Adaptation for Conversational Agents"}, {"abstract": "We propose Deep Feature Factorization (DFF), a method capable of localizing\nsimilar semantic concepts within an image or a set of images. We use DFF to\ngain insight into a deep convolutional neural network\u0027s learned features, where\nwe detect hierarchical cluster structures in feature space. This is visualized\nas heat maps, which highlight semantically matching regions across a set of\nimages, revealing what the network `perceives\u0027 as similar. DFF can also be used\nto perform co-segmentation and co-localization, and we report state-of-the-art\nresults on these tasks.", "authors": ["Edo Collins", "Radhakrishna Achanta", "Sabine S\u00fcsstrunk"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10206v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10206v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10206v1", "published_time": "6/26/2018", "rawpid": "1806.10206", "tags": ["cs.LG", "stat.ML"], "title": "Deep Feature Factorization For Concept Discovery"}, {"abstract": "We propose an entity-centric neural cross-lingual coreference model that\nbuilds on multi-lingual embeddings and language-independent features. We\nperform both intrinsic and extrinsic evaluations of our model. In the intrinsic\nevaluation, we show that our model, when trained on English and tested on\nChinese and Spanish, achieves competitive results to the models trained\ndirectly on Chinese and Spanish respectively. In the extrinsic evaluation, we\nshow that our English model helps achieve superior entity linking accuracy on\nChinese and Spanish test sets than the top 2015 TAC system without using any\nannotated data from Chinese or Spanish.", "authors": ["Gourab Kundu", "Avirup Sil", "Radu Florian", "Wael Hamza"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1806.10201v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10201v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10201v1", "published_time": "6/26/2018", "rawpid": "1806.10201", "tags": ["cs.CL"], "title": "Neural Cross-Lingual Coreference Resolution and its Application to\n  Entity Linking"}, {"abstract": "We provide tight finite-time convergence bounds for gradient descent and\nstochastic gradient descent on quadratic functions, when the gradients are\ndelayed and reflect iterates from $\\tau$ rounds ago. First, we show that\nwithout stochastic noise, delays strongly affect the attainable optimization\nerror: In fact, the error can be as bad as non-delayed gradient descent ran on\nonly $1/\\tau$ of the gradients. In sharp contrast, we quantify how stochastic\nnoise makes the effect of delays negligible, improving on previous work which\nonly showed this phenomenon asymptotically or for much smaller delays. Also, in\nthe context of distributed optimization, the results indicate that the\nperformance of gradient descent with delays is competitive with synchronous\napproaches such as mini-batching. Our results are based on a novel technique\nfor analyzing convergence of optimization algorithms using generating\nfunctions.", "authors": ["Yossi Arjevani", "Ohad Shamir", "Nathan Srebro"], "category": "math.OC", "comment": "", "img": "/static/thumbs/1806.10188v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10188v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10188v1", "published_time": "6/26/2018", "rawpid": "1806.10188", "tags": ["math.OC", "cs.LG", "stat.ML"], "title": "A Tight Convergence Analysis for Stochastic Gradient Descent with\n  Delayed Updates"}, {"abstract": "We present a dual subspace ascent algorithm for support vector machine\ntraining that respects a budget constraint limiting the number of support\nvectors. Budget methods are effective for reducing the training time of kernel\nSVM while retaining high accuracy. To date, budget training is available only\nfor primal (SGD-based) solvers. Dual subspace ascent methods like sequential\nminimal optimization are attractive for their good adaptation to the problem\nstructure, their fast convergence rate, and their practical speed. By\nincorporating a budget constraint into a dual algorithm, our method enjoys the\nbest of both worlds. We demonstrate considerable speed-ups over primal budget\ntraining methods.", "authors": ["Sahar Qaadan", "Merlin Sch\u00fcler", "Tobias Glasmachers"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10182v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10182v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10182v1", "published_time": "6/26/2018", "rawpid": "1806.10182", "tags": ["cs.LG", "stat.ML"], "title": "Dual SVM Training on a Budget"}, {"abstract": "It is widely believed that the backpropagation algorithm is essential for\nlearning good feature detectors in early layers of artificial neural networks,\nso that these detectors are useful for the task performed by the higher layers\nof that neural network. At the same time, the traditional form of\nbackpropagation is biologically implausible. In the present paper we propose an\nunusual learning rule, which has a degree of biological plausibility, and which\nis motivated by Hebb\u0027s idea that change of the synapse strength should be local\n- i.e. should depend only on the activities of the pre and post synaptic\nneurons. We design a learning algorithm that utilizes global inhibition in the\nhidden layer, and is capable of learning early feature detectors in a\ncompletely unsupervised way. These learned lower layer feature detectors can be\nused to train higher layer weights in a usual supervised way so that the\nperformance of the full network is comparable to the performance of standard\nfeedforward networks trained end-to-end with a backpropagation algorithm.", "authors": ["Dmitry Krotov", "John Hopfield"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10181v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10181v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10181v1", "published_time": "6/26/2018", "rawpid": "1806.10181", "tags": ["cs.LG", "cs.CV", "cs.NE", "q-bio.NC", "stat.ML"], "title": "Unsupervised Learning by Competing Hidden Units"}, {"abstract": "Limiting the model size of a kernel support vector machine to a pre-defined\nbudget is a well-established technique that allows to scale SVM learning and\nprediction to large-scale data. Its core addition to simple stochastic gradient\ntraining is budget maintenance through merging of support vectors. This\nrequires solving an inner optimization problem with an iterative method many\ntimes per gradient step. In this paper we replace the iterative procedure with\na fast lookup. We manage to reduce the merging time by up to 65% and the total\ntraining time by 44% without any loss of accuracy.", "authors": ["Tobias Glasmachers", "Sahar Qaadan"], "category": "cs.LG", "comment": "arXiv admin note: text overlap with arXiv:1806.10179", "img": "/static/thumbs/1806.10180v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10180v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10180v1", "published_time": "6/26/2018", "rawpid": "1806.10180", "tags": ["cs.LG", "stat.ML"], "title": "Speeding Up Budgeted Stochastic Gradient Descent SVM Training with\n  Precomputed Golden Section Search"}, {"abstract": "Budgeted Stochastic Gradient Descent (BSGD) is a state-of-the-art technique\nfor training large-scale kernelized support vector machines. The budget\nconstraint is maintained incrementally by merging two points whenever the\npre-defined budget is exceeded. The process of finding suitable merge partners\nis costly; it can account for up to 45% of the total training time. In this\npaper we investigate computationally more efficient schemes that merge more\nthan two points at once. We obtain significant speed-ups without sacrificing\naccuracy.", "authors": ["Sahar Qaadan", "Tobias Glasmachers"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10179v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10179v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10179v1", "published_time": "6/26/2018", "rawpid": "1806.10179", "tags": ["cs.LG", "stat.ML"], "title": "Multi-Merge Budget Maintenance for Stochastic Gradient Descent SVM\n  Training"}, {"abstract": "Formal ontologies are axiomatizations in a logic-based formalism. The\ndevelopment of formal ontologies, and their important role in the Semantic Web\narea, is generating considerable research on the use of automated reasoning\ntechniques and tools that help in ontology engineering. One of the main aims is\nto refine and to improve axiomatizations for enabling automated reasoning tools\nto efficiently infer reliable information. Defects in the axiomatization can\nnot only cause wrong inferences, but can also hinder the inference of expected\ninformation, either by increasing the computational cost of, or even\npreventing, the inference. In this paper, we introduce a novel, fully automatic\nwhite-box testing framework for first-order logic ontologies. Our methodology\nis based on the detection of inference-based redundancies in the given\naxiomatization. The application of the proposed testing method is fully\nautomatic since a) the automated generation of tests is guided only by the\nsyntax of axioms and b) the evaluation of tests is performed by automated\ntheorem provers. Our proposal enables the detection of defects and serves to\ncertify the grade of suitability --for reasoning purposes-- of every axiom. We\nformally define the set of tests that are generated from any axiom and prove\nthat every test is logically related to redundancies in the axiom from which\nthe test has been generated. We have implemented our method and used this\nimplementation to automatically detect several non-trivial defects that were\nhidden in various first-order logic ontologies. Throughout the paper we provide\nillustrative examples of these defects, explain how they were found, and how\neach proof --given by an automated theorem-prover-- provides useful hints on\nthe nature of each defect. Additionally, by correcting all the detected\ndefects, we have obtained an improved version of one of the tested ontologies:\nAdimen-SUMO.", "authors": ["Javier \u00c1lvez", "Montserrat Hermo", "Paqui Lucio", "German Rigau"], "category": "cs.AI", "comment": "35 pages, 5 tables", "img": "/static/thumbs/1705.10219v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1705.10219v2", "num_discussion": 0, "originally_published_time": "5/29/2017", "pid": "1705.10219v2", "published_time": "6/26/2018", "rawpid": "1705.10219", "tags": ["cs.AI", "68T30", "I.2.4"], "title": "Automatic White-Box Testing of First-Order Logic Ontologies"}, {"abstract": "Gradient-based optimization methods are the most popular choice for finding\nlocal optima for classical minimization and saddle point problems. Here, we\nhighlight a systemic issue of gradient dynamics that arise for saddle point\nproblems, namely the presence of undesired stable stationary points that are no\nlocal optima. We propose a novel optimization approach that exploits curvature\ninformation in order to escape from these undesired stationary points. We prove\nthat different optimization methods, including gradient method and adagrad,\nequipped with curvature exploitation can escape non-optimal stationary points.\nWe also provide empirical results on common saddle point problems which confirm\nthe advantage of using curvature exploitation.", "authors": ["Leonard Adolphs", "Hadi Daneshmand", "Aurelien Lucchi", "Thomas Hofmann"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1805.05751v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.05751v2", "num_discussion": 0, "originally_published_time": "5/15/2018", "pid": "1805.05751v2", "published_time": "6/26/2018", "rawpid": "1805.05751", "tags": ["cs.LG", "math.OC", "stat.ML"], "title": "Local Saddle Point Optimization: A Curvature Exploitation Approach"}, {"abstract": "Linear encoding of sparse vectors is widely popular, but is most commonly\ndata-independent -- missing any possible extra (but a-priori unknown) structure\nbeyond sparsity. In this paper we present a new method to learn linear encoders\nthat adapt to data, while still performing well with the widely used $\\ell_1$\ndecoder. The convex $\\ell_1$ decoder prevents gradient propagation as needed in\nstandard autoencoder training. Our method is based on the insight that\nunfolding the convex decoder into $T$ projected gradient steps can address this\nissue. Our method can be seen as a data-driven way to learn a compressed\nsensing matrix. Our experiments show that there is indeed additional structure\nbeyond sparsity in several real datasets. Our autoencoder is able to discover\nit and exploit it to create excellent reconstructions with fewer measurements\ncompared to the previous state of the art methods.", "authors": ["Shanshan Wu", "Alexandros G. Dimakis", "Sujay Sanghavi", "Felix X. Yu", "Daniel Holtmann-Rice", "Dmitry Storcheus", "Afshin Rostamizadeh", "Sanjiv Kumar"], "category": "stat.ML", "comment": "22 pages, 8 figures", "img": "/static/thumbs/1806.10175v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10175v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10175v1", "published_time": "6/26/2018", "rawpid": "1806.10175", "tags": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "title": "The Sparse Recovery Autoencoder"}, {"abstract": "Although timely sepsis diagnosis and prompt interventions in Intensive Care\nUnit (ICU) patients are associated with reduced mortality, early clinical\nrecognition is frequently impeded by non-specific signs of infection and\nfailure to detect signs of sepsis-induced organ dysfunction in a constellation\nof dynamically changing physiological data. The goal of this work is to\nidentify patient at risk of life-threatening sepsis utilizing a data-centered\nand machine learning-driven approach. We derive a mortality risk predictive\ndynamic Bayesian network (DBN) guided by a customized sepsis knowledgebase and\ncompare the predictive accuracy of the derived DBN with the Sepsis-related\nOrgan Failure Assessment (SOFA) score, the Quick SOFA (qSOFA) score, the\nSimplified Acute Physiological Score (SAPS-II) and the Modified Early Warning\nScore (MEWS) tools.\n  A customized sepsis ontology was used to derive the DBN node structure and\nsemantically characterize temporal features derived from both structured\nphysiological data and unstructured clinical notes. We assessed the performance\nin predicting mortality risk of the DBN predictive model and compared\nperformance to other models using Receiver Operating Characteristic (ROC)\ncurves, area under curve (AUROC), calibration curves, and risk distributions.\n  The derived dataset consists of 24,506 ICU stays from 19,623 patients with\nevidence of suspected infection, with 2,829 patients deceased at discharge. The\nDBN AUROC was found to be 0.91, which outperformed the SOFA (0.843), qSOFA\n(0.66), MEWS (0.73), and SAPS-II (0.77) scoring tools. Continuous Net\nReclassification Index and Integrated Discrimination Improvement analysis\nsupported the superiority DBN. Compared with conventional rule-based risk\nscoring tools, the sepsis knowledgebase-driven DBN algorithm offers improved\nperformance for predicting mortality of infected patients in ICUs.", "authors": ["Tony Wang", "Tom Velez", "Emilia Apostolova", "Tim Tschampel", "Thuy L. Ngo", "Joy Hardison"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10174v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10174v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10174v1", "published_time": "6/26/2018", "rawpid": "1806.10174", "tags": ["cs.LG", "stat.ML"], "title": "Semantically Enhanced Dynamic Bayesian Network for Detecting Sepsis\n  Mortality Risk in ICU Patients with Infection"}, {"abstract": "Sparse Representation Theory is a sub-field of signal processing that has led\nto cutting edge results in many applications such as denoising, deblurring,\nsuper resolution and many other inverse problems. Broadly speaking, this field\nputs forward a model that assumes that signals are originated from a sparse\nrepresentation in terms of an over-complete dictionary. Thus, when a corrupted\nmeasurement is given, we seek to estimate its original, clean form by finding\nthe best matched sparse representation of the given signal in the dictionary\ndomain. This process is essentially a non-linear estimation solved by a pursuit\nor a sparse coding algorithm.\n  The concept of Stochastic Resonance (SR) refers to the counter-intuitive idea\nof improving algorithms\u0027 performance by a deliberate noise contamination. In\nthis work we develop novel techniques that apply SR for enhancement of the\nperformance of known pursuit algorithms. We show that these methods provide an\neffective MMSE approximation and are capable of doing so for high-dimensional\nproblems, for which no alternative exists.", "authors": ["Dror Simon", "Jeremias Sulam", "Yaniv Romano", "Yue M. Lue", "Michael Elad"], "category": "eess.SP", "comment": "", "img": "/static/thumbs/1806.10171v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10171v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10171v1", "published_time": "6/26/2018", "rawpid": "1806.10171", "tags": ["eess.SP", "cs.CV"], "title": "Improving Pursuit Algorithms Using Stochastic Resonance"}, {"abstract": "Nowadays, due to tremendous improvements in high performance computing, it\nhas become easier to train Neural Networks. We intend to take advantage of this\nsituation and apply this technology in solving real world problems. There was a\nneed for automatic diagnosis certain diseases from medical images that could\nhelp a doctor and radiologist for further action towards treating the illness.\nWe chose Alzheimer disease for this purpose. Alzheimer disease is the leading\ncause of dementia and memory loss. Alzheimer disease, it is caused by atrophy\nof the certain brain regions and by brain cell death. MRI scans reveal this\ninformation but atrophy regions are different for different people which makes\nthe diagnosis a little trickier and often gets miss-diagnosed by doctors and\nradiologists. The Dataset used for this project is provided by OASIS, which\ncontains over 400 subjects 100 of which having mild to severe dementia and is\nsupplemented by MMSE and CDR standards of diagnosis in the same context. Enter\nCNN, Convolutional Neural Networks are a hybrid of Kernel Convolutions and\nNeural Networks. Kernel Convolutions is a technique that uses filters to\nrecognize and segment images based on features. Neural Networks consist of\nneurons which are loosely based on human brains neuron which represents a\nsingle classifier and interconnected by weights, have different biases and are\nactivated by some activation functions. By using Convolutional Neural Networks,\nthe problem can be solved with minimal error rate. The technologies we intend\nto use are libraries like CUDA CuDNN for making use of GPU and its multiple\ncores-parallel computing to train models while giving us high performance.", "authors": ["Gururaj Awate", "Sunil Bangare", "G Pradeepini", "S Patil"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10170v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10170v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10170v1", "published_time": "6/26/2018", "rawpid": "1806.10170", "tags": ["cs.CV"], "title": "Detection of Alzheimers Disease from MRI using Convolutional Neural\n  Network with Tensorflow"}, {"abstract": "Many prediction problems, such as those that arise in the context of\nrobotics, have a simplifying underlying structure that could accelerate\nlearning. In this paper, we present a strategy for learning a set of neural\nnetwork modules that can be combined in different ways. We train different\nmodular structures on a set of related tasks and generalize to new tasks by\ncomposing the learned modules in new ways. We show this improves performance in\ntwo robotics-related problems.", "authors": ["Ferran Alet", "Tom\u00e1s Lozano-P\u00e9rez", "Leslie P. Kaelbling"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10166v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10166v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10166v1", "published_time": "6/26/2018", "rawpid": "1806.10166", "tags": ["cs.LG", "cs.RO", "stat.ML"], "title": "Modular meta-learning"}, {"abstract": "Random forests have become an important tool for improving accuracy in\nregression problems since their popularization by [Breiman, 2001] and others.\nIn this paper, we revisit a random forest model originally proposed by\n[Breiman, 2004] and later studied by [Biau, 2012], where a feature is selected\nat random and the split occurs at the midpoint of the box containing the chosen\nfeature. If the Lipschitz regression function is sparse and only depends on a\nsmall, unknown subset of $S$ out of $d$ features, we show that given $n$\nobservations, this random forest model outputs a predictor that has a\nmean-squared prediction error $O((n(\\sqrt{\\log\nn})^{S-1})^{-\\frac{1}{S\\log2+1}})$. When $S \\leq \\lfloor 0.72 d \\rfloor$, this\nrate is significantly better than the minimax optimal rate\n$\\Theta(n^{-\\frac{2}{d+2}})$ for Lipschitz function classes in $ d $\ndimensions. The second part of this article shows that the prediction error for\nthis random forest model cannot generally be improved. As a striking\nconsequence of our analysis, we show that if $\\ell_{avg}$ (resp. $\\ell_{max}$)\nis the average (resp. maximum) number of observations per leaf node, then the\nvariance of this forest is $\\Theta(\\ell^{-1}_{avg}(\\sqrt{\\log n})^{-(S-1)})$.\nWhen $S = d$, this variance is similar in form to the best-case variance lower\nbound $\\Omega(\\ell^{-1}_{max}(\\log n)^{-(d-1)})$ of [Lin and Jeon, 2006] for\nany random forest model with a nonadaptive splitting scheme (i.e., where the\nsplit protocol is independent of the data). We also show that the bias is tight\nfor any linear model with nonzero parameter vector. Finally, a side consequence\nof our analysis is that if the regression function is square-integrable (e.g.,\nit need not be continuous or bounded), then the random forest predictor is\npointwise consistent almost everywhere.", "authors": ["Jason M. Klusowski"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1805.02587v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.02587v4", "num_discussion": 0, "originally_published_time": "5/7/2018", "pid": "1805.02587v4", "published_time": "6/26/2018", "rawpid": "1805.02587", "tags": ["stat.ML", "cs.LG", "62G08, 68W20"], "title": "Complete Analysis of a Random Forest Model"}, {"abstract": "The Variational Autoencoder (VAE) has proven to be an effective model for\nproducing semantically meaningful latent representations for natural data.\nHowever, it has thus far seen limited application to sequential data, and, as\nwe demonstrate, existing recurrent VAE models have difficulty modeling\nsequences with long-term structure. To address this issue, we propose the use\nof a hierarchical decoder, which first outputs embeddings for subsequences of\nthe input and then uses these embeddings to generate each subsequence\nindependently. This structure encourages the model to utilize its latent code,\nthereby avoiding the \"posterior collapse\" problem which remains an issue for\nrecurrent VAEs. We apply this architecture to modeling sequences of musical\nnotes and find that it exhibits dramatically better sampling, interpolation,\nand reconstruction performance than a \"flat\" baseline model. An implementation\nof our \"MusicVAE\" is available online at http://g.co/magenta/musicvae-code.", "authors": ["Adam Roberts", "Jesse Engel", "Colin Raffel", "Curtis Hawthorne", "Douglas Eck"], "category": "cs.LG", "comment": "ICML Camera Ready Version", "img": "/static/thumbs/1803.05428v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.05428v3", "num_discussion": 0, "originally_published_time": "3/13/2018", "pid": "1803.05428v3", "published_time": "6/26/2018", "rawpid": "1803.05428", "tags": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "title": "A Hierarchical Latent Vector Model for Learning Long-Term Structure in\n  Music"}, {"abstract": "We address the problem of algorithmic fairness: ensuring that sensitive\nvariables do not unfairly influence the outcome of a classifier. We present an\napproach based on empirical risk minimization, which incorporates a fairness\nconstraint into the learning problem. It encourages the conditional risk of the\nlearned classifier to be approximately constant with respect to the sensitive\nvariable. We derive both risk and fairness bounds that support the statistical\nconsistency of our approach. We specify our approach to kernel methods and\nobserve that the fairness requirement implies an orthogonality constraint which\ncan be easily added to these methods. We further observe that for linear models\nthe constraint translates into a simple data preprocessing step. Experiments\nindicate that the method is empirically effective and performs favorably\nagainst state-of-the-art approaches.", "authors": ["Michele Donini", "Luca Oneto", "Shai Ben-David", "John Shawe-Taylor", "Massimiliano Pontil"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1802.08626v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.08626v2", "num_discussion": 0, "originally_published_time": "2/23/2018", "pid": "1802.08626v2", "published_time": "6/26/2018", "rawpid": "1802.08626", "tags": ["stat.ML", "cs.LG"], "title": "Empirical Risk Minimization under Fairness Constraints"}, {"abstract": "Multiplayer Online Battle Arena (MOBA) games have received increasing\npopularity recently. In a match of such games, players compete in two teams of\nfive, each controlling an in-game avatars, known as heroes, selected from a\nroster of more than 100. The selection of heroes, also known as pick or draft,\ntakes place before the match starts and alternates between the two teams until\neach player has selected one hero. Heroes are designed with different strengths\nand weaknesses to promote team cooperation in a game. Intuitively, heroes in a\nstrong team should complement each other\u0027s strengths and suppressing those of\nopponents. Hero drafting is therefore a challenging problem due to the complex\nhero-to-hero relationships to consider. In this paper, we propose a novel hero\nrecommendation system that suggests heroes to add to an existing team while\nmaximizing the team\u0027s prospect for victory. To that end, we model the drafting\nbetween two teams as a combinatorial game and use Monte Carlo Tree Search\n(MCTS) for estimating the values of hero combinations. Our empirical evaluation\nshows that hero teams drafted by our recommendation algorithm have\nsignificantly higher win rate against teams constructed by other baseline and\nstate-of-the-art strategies.", "authors": ["Zhengxing Chen", "Truong-Huy D Nguyen", "Yuyu Xu", "Chris Amato", "Seth Cooper", "Yizhou Sun", "Magy Seif El-Nasr"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10130v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10130v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10130v1", "published_time": "6/26/2018", "rawpid": "1806.10130", "tags": ["cs.AI", "cs.HC", "cs.SI"], "title": "The Art of Drafting: A Team-Oriented Hero Recommendation System for\n  Multiplayer Online Battle Arena Games"}, {"abstract": "Unlike natural images, medical images often have intrinsic characteristics\nthat can be leveraged for neural network learning. For example, images that\nbelong to different stages of a disease may continuously follow certain\nprogression pattern. In this paper, we propose a novel method that leverages\ndisease progression learning for medical image recognition, where sequences of\nimages ordered by disease stages are learned by a neural network that consists\nof a shared vision model for feature extraction and a long short-term memory\nnetwork for the learning of stage sequences. Auxiliary vision outputs are also\nincluded to capture stage features that tend to be discrete along disease\nprogression. Our proposed method is evaluated on a diabetic retinopathy\ndataset, and achieves about 3.3% improvement in disease staging accuracy,\ncompared to the baseline method that does not use disease progression learning.", "authors": ["Qicheng Lao", "Thomas Fevens"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10128v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10128v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10128v1", "published_time": "6/26/2018", "rawpid": "1806.10128", "tags": ["cs.CV"], "title": "Leveraging Disease Progression Learning for Medical Image Recognition"}, {"abstract": "Often, when dealing with real-world recognition problems, we do not need, and\noften cannot have, knowledge of the entire set of possible classes that might\nappear during operational testing. Moreover, sometimes some of these classes\nmay be ill-sampled, not sampled at all or undefined. In such cases, we need to\nthink of robust classification methods able to deal with the \"unknown\" and\nproperly reject samples belonging to classes never seen during training.\nNotwithstanding, almost all existing classifiers to date were mostly developed\nfor the closed-set scenario, i.e., the classification setup in which it is\nassumed that all test samples belong to one of the classes with which the\nclassifier was trained. In the open-set scenario, however, a test sample can\nbelong to none of the known classes and the classifier must properly reject it\nby classifying it as unknown. In this work, we extend upon the well-known\nSupport Vector Machines (SVM) classifier and introduce the Specialized Support\nVector Machines (SSVM), which is suitable for recognition in open-set setups.\nSSVM balances the empirical risk and the risk of the unknown and ensures that\nthe region of the feature space in which a test sample would be classified as\nknown (one of the known classes) is always bounded, ensuring a finite risk of\nthe unknown. The same cannot be guaranteed by the traditional SVM formulation,\neven when using the Radial Basis Function (RBF) kernel. In this work, we also\nhighlight the properties of the SVM classifier related to the open-set\nscenario, and provide necessary and sufficient conditions for an RBF SVM to\nhave bounded open-space risk. An extensive set of experiments compares the\nproposed method with existing solutions in the literature for open-set\nrecognition and the reported results show its effectiveness.", "authors": ["Pedro Ribeiro Mendes J\u00fanior", "Terrance E. Boult", "Jacques Wainer", "Anderson Rocha"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1606.03802v5.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1606.03802v5", "num_discussion": 0, "originally_published_time": "6/13/2016", "pid": "1606.03802v5", "published_time": "6/26/2018", "rawpid": "1606.03802", "tags": ["cs.LG", "stat.ML"], "title": "Specialized Support Vector Machines for open-set recognition"}, {"abstract": "Cardiopulmonary resuscitation (CPR) is alongside with electrical\ndefibrillation the most important treatment for sudden cardiac arrest, which\naffects thousands of individuals every year. In this paper, we present a robust\nsinusoid model that uses skeletal motion data from an RGB-D (Kinect) sensor and\nthe Differential Evolution (DE) optimization algorithm to dynamically fit\nsinusoidal curves to derive frequency and depth parameters for cardiopulmonary\nresuscitation training. It is intended to be part of a robust and easy-to-use\nfeedback system for CPR training, allowing its use for unsupervised training.\nThe accuracy of this DE-based approach is evaluated in comparison with data\nrecorded by a state-of-the-art training mannequin. We optimized the DE\nalgorithm constants and have shown that with these optimized parameters the\nfrequency of the CPR is recognized with a median error of 2.55 (2.4%)\ncompressions per minute compared to the reference training mannequin.", "authors": ["Christian Lins", "Daniel Eckhoff", "Andreas Klausen", "Sandra Hellmers", "Andreas Hein", "Sebastian Fudickar"], "category": "cs.NE", "comment": "21 pages, submitted to Applied Soft Computing", "img": "/static/thumbs/1806.10115v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10115v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10115v1", "published_time": "6/26/2018", "rawpid": "1806.10115", "tags": ["cs.NE"], "title": "Cardiopulmonary Resuscitation Quality Parameters from Motion Capture\n  Data using Differential Evolution Fitting of Sinusoids"}, {"abstract": "This paper proposes a new data-driven approach to model detailed splashes for\nliquid simulations with neural networks. Our model learns to generate\nsmall-scale splash detail for the fluid-implicit-particle method using training\ndata acquired from physically parametrized, high resolution simulations. We use\nneural networks to model the regression of splash formation using a classifier\ntogether with a velocity modifier. For the velocity modification, we employ a\nheteroscedastic model. We evaluate our method for different spatial scales,\nsimulation setups, and solvers. Our simulation results demonstrate that our\nmodel significantly improves visual fidelity with a large amount of realistic\ndroplet formation and yields splash detail much more efficiently than finer\ndiscretizations.", "authors": ["Kiwon Um", "Xiangyu Hu", "Nils Thuerey"], "category": "cs.GR", "comment": "to appear in Computer Graphics Forum, more information:\n  https://ge.in.tum.de/publications/2018-mlf...", "img": "/static/thumbs/1704.04456v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1704.04456v2", "num_discussion": 0, "originally_published_time": "4/14/2017", "pid": "1704.04456v2", "published_time": "6/26/2018", "rawpid": "1704.04456", "tags": ["cs.GR", "cs.LG"], "title": "Liquid Splash Modeling with Neural Networks"}, {"abstract": "Randomized experiments are the gold standard for evaluating the effects of\nchanges to real-world systems. Data in these tests may be difficult to collect\nand outcomes may have high variance, resulting in potentially large measurement\nerror. Bayesian optimization is a promising technique for efficiently\noptimizing multiple continuous parameters, but existing approaches degrade in\nperformance when the noise level is high, limiting its applicability to many\nrandomized experiments. We derive an expression for expected improvement under\ngreedy batch optimization with noisy observations and noisy constraints, and\ndevelop a quasi-Monte Carlo approximation that allows it to be efficiently\noptimized. Simulations with synthetic functions show that optimization\nperformance on noisy, constrained problems outperforms existing methods. We\nfurther demonstrate the effectiveness of the method with two real-world\nexperiments conducted at Facebook: optimizing a ranking system, and optimizing\nserver compiler flags.", "authors": ["Benjamin Letham", "Brian Karrer", "Guilherme Ottoni", "Eytan Bakshy"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1706.07094v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.07094v2", "num_discussion": 0, "originally_published_time": "6/21/2017", "pid": "1706.07094v2", "published_time": "6/26/2018", "rawpid": "1706.07094", "tags": ["stat.ML", "cs.LG", "stat.AP"], "title": "Constrained Bayesian Optimization with Noisy Experiments"}, {"abstract": "In this work, a region-based Deep Convolutional Neural Network framework is\nproposed for document structure learning. The contribution of this work\ninvolves efficient training of region based classifiers and effective\nensembling for document image classification. A primary level of `inter-domain\u0027\ntransfer learning is used by exporting weights from a pre-trained VGG16\narchitecture on the ImageNet dataset to train a document classifier on whole\ndocument images. Exploiting the nature of region based influence modelling, a\nsecondary level of `intra-domain\u0027 transfer learning is used for rapid training\nof deep learning models for image segments. Finally, stacked generalization\nbased ensembling is utilized for combining the predictions of the base deep\nneural network models. The proposed method achieves state-of-the-art accuracy\nof 92.2% on the popular RVL-CDIP document image dataset, exceeding benchmarks\nset by existing algorithms.", "authors": ["Arindam Das", "Saikat Roy", "Ujjwal Bhattacharya", "Swapan Kumar Parui"], "category": "cs.CV", "comment": "Accepted in 24th International Conference in Pattern Recognition\n  (ICPR), Beijing, China, 2018", "img": "/static/thumbs/1801.09321v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1801.09321v2", "num_discussion": 0, "originally_published_time": "1/29/2018", "pid": "1801.09321v2", "published_time": "6/26/2018", "rawpid": "1801.09321", "tags": ["cs.CV", "cs.LG"], "title": "Document Image Classification with Intra-Domain Transfer Learning and\n  Stacked Generalization of Deep Convolutional Neural Networks"}, {"abstract": "Realistic music generation is a challenging task. When building generative\nmodels of music that are learnt from data, typically high-level representations\nsuch as scores or MIDI are used that abstract away the idiosyncrasies of a\nparticular performance. But these nuances are very important for our perception\nof musicality and realism, so in this work we embark on modelling music in the\nraw audio domain. It has been shown that autoregressive models excel at\ngenerating raw audio waveforms of speech, but when applied to music, we find\nthem biased towards capturing local signal structure at the expense of\nmodelling long-range correlations. This is problematic because music exhibits\nstructure at many different timescales. In this work, we explore autoregressive\ndiscrete autoencoders (ADAs) as a means to enable autoregressive models to\ncapture long-range correlations in waveforms. We find that they allow us to\nunconditionally generate piano music directly in the raw audio domain, which\nshows stylistic consistency across tens of seconds.", "authors": ["Sander Dieleman", "A\u00e4ron van den Oord", "Karen Simonyan"], "category": "cs.SD", "comment": "13 pages, 2 figures, submitted to NIPS 2018", "img": "/static/thumbs/1806.10474v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10474v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10474v1", "published_time": "6/26/2018", "rawpid": "1806.10474", "tags": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "title": "The challenge of realistic music generation: modelling raw audio at\n  scale"}, {"abstract": "In partially observed environments, it can be useful for a human to provide\nthe robot with declarative information that represents probabilistic relational\nconstraints on properties of objects in the world, augmenting the robot\u0027s\nsensory observations. For instance, a robot tasked with a search-and-rescue\nmission may be informed by the human that two victims are probably in the same\nroom. An important question arises: how should we represent the robot\u0027s\ninternal knowledge so that this information is correctly processed and combined\nwith raw sensory information? In this paper, we provide an efficient belief\nstate representation that dynamically selects an appropriate factoring,\ncombining aspects of the belief when they are correlated through information\nand separating them when they are not. This strategy works in open domains, in\nwhich the set of possible objects is not known in advance, and provides\nsignificant improvements in inference time over a static factoring, leading to\nmore efficient planning for complex partially observed tasks. We validate our\napproach experimentally in two open-domain planning problems: a 2D discrete\ngridworld task and a 3D continuous cooking task.", "authors": ["Rohan Chitnis", "Leslie Pack Kaelbling", "Tom\u00e1s Lozano-P\u00e9rez"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1803.00119v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.00119v3", "num_discussion": 0, "originally_published_time": "2/28/2018", "pid": "1803.00119v3", "published_time": "6/26/2018", "rawpid": "1803.00119", "tags": ["cs.AI", "cs.RO"], "title": "Integrating Human-Provided Information Into Belief State Representation\n  Using Dynamic Factorization"}, {"abstract": "We present a framework and algorithm for peer-to-peer teaching in cooperative\nmultiagent reinforcement learning. Our algorithm, Learning to Coordinate and\nTeach Reinforcement (LeCTR), trains advising policies by using students\u0027\nlearning progress as a teaching reward. Agents using LeCTR learn to assume the\nrole of a teacher or student at the appropriate moments, exchanging action\nadvice to accelerate the entire learning process. Our algorithm supports\nteaching heterogeneous teammates, advising under communication constraints, and\nlearns both what and when to advise. LeCTR is demonstrated to outperform the\nfinal performance and rate of learning of prior teaching methods on multiple\nbenchmark domains. To our knowledge, this is the first approach for learning to\nteach in a multiagent setting.", "authors": ["Shayegan Omidshafiei", "Dong-Ki Kim", "Miao Liu", "Gerald Tesauro", "Matthew Riemer", "Christopher Amato", "Murray Campbell", "Jonathan P. How"], "category": "cs.MA", "comment": "", "img": "/static/thumbs/1805.07830v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.07830v3", "num_discussion": 0, "originally_published_time": "5/20/2018", "pid": "1805.07830v3", "published_time": "6/26/2018", "rawpid": "1805.07830", "tags": ["cs.MA", "cs.AI"], "title": "Learning to Teach in Cooperative Multiagent Reinforcement Learning"}, {"abstract": "An algorithm is proposed for solving stochastic and finite sum minimization\nproblems. Based on a trust region methodology, the algorithm employs normalized\nsteps, at least as long as the norms of the stochastic gradient estimates are\nwithin a specified interval. The complete algorithm---which dynamically chooses\nwhether or not to employ normalized steps---is proved to have convergence\nguarantees that are similar to those possessed by a traditional stochastic\ngradient approach under various sets of conditions related to the accuracy of\nthe stochastic gradient estimates and choice of stepsize sequence. The results\nof numerical experiments are presented when the method is employed to minimize\nconvex and nonconvex machine learning test problems. These results illustrate\nthat the method can outperform a traditional stochastic gradient approach.", "authors": ["Frank E. Curtis", "Katya Scheinberg", "Rui Shi"], "category": "math.OC", "comment": "", "img": "/static/thumbs/1712.10277v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1712.10277v3", "num_discussion": 0, "originally_published_time": "12/29/2017", "pid": "1712.10277v3", "published_time": "6/26/2018", "rawpid": "1712.10277", "tags": ["math.OC", "stat.ML"], "title": "A Stochastic Trust Region Algorithm Based on Careful Step Normalization"}, {"abstract": "We explore recently introduced definition modeling technique that provided\nthe tool for evaluation of different distributed vector representations of\nwords through modeling dictionary definitions of words. In this work, we study\nthe problem of word ambiguities in definition modeling and propose a possible\nsolution by employing latent variable modeling and soft attention mechanisms.\nOur quantitative and qualitative evaluation and analysis of the model shows\nthat taking into account words ambiguity and polysemy leads to performance\nimprovement.", "authors": ["Artyom Gadetsky", "Ilya Yakubovskiy", "Dmitry Vetrov"], "category": "cs.CL", "comment": "Accepted as a conference paper at ACL 2018", "img": "/static/thumbs/1806.10090v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10090v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10090v1", "published_time": "6/26/2018", "rawpid": "1806.10090", "tags": ["cs.CL"], "title": "Conditional Generators of Words Definitions"}, {"abstract": "Interpretable deep learning is a fundamental building block towards safer AI,\nespecially when the deployment possibilities of deep learning-based\ncomputer-aided medical diagnostic systems are so eminent. However, without a\ncomputational formulation of black-box interpretation, general interpretability\nresearch rely heavily on subjective bias. Clear decision structure of the\nmedical diagnostics lets us approximate the decision process of a radiologist\nas a model - removed from subjective bias. We define the process of\ninterpretation as a finite communication between a known model and a black-box\nmodel to optimally map the black box\u0027s decision process in the known model.\nConsequently, we define interpretability as maximal information gain over the\ninitial uncertainty about the black-box\u0027s decision within finite communication.\nWe relax this definition based on the observation that diagnostic\ninterpretation is typically achieved by a process of minimal querying. We\nderive an algorithm to calculate diagnostic interpretability. The usual\nquestion of accuracy-interpretability tradeoff, i.e. whether a black-box\nmodel\u0027s prediction accuracy is dependent on its ability to be interpreted by a\nknown source model, does not arise in this theory. With multiple example\nsimulation experiments of various complexity levels, we demonstrate the working\nof such a theoretical model in synthetic supervised classification scenarios.", "authors": ["Anirban Mukhopadhyay"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10080v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10080v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10080v1", "published_time": "6/26/2018", "rawpid": "1806.10080", "tags": ["cs.LG", "stat.ML"], "title": "A Theory of Diagnostic Interpretation in Supervised Classification"}, {"abstract": "Adversarial examples that fool machine learning models, particularly deep\nneural networks, have been a topic of intense research interest, with attacks\nand defenses being developed in a tight back-and-forth. Most past defenses are\nbest-effort and have been shown to be vulnerable to sophisticated attacks.\nRecently a set of certified defenses have been introduced, which provide\nguarantees of robustness to norm-bounded attacks, but they either do not scale\nto large datasets or are limited in the types of models they can support. This\npaper presents the first certified defense that both scales to large networks\nand datasets (such as Google\u0027s Inception network for ImageNet) and applies\nbroadly to arbitrary model types. Our defense is based on a novel connection\nbetween robustness against adversarial examples and differential privacy, a\ncryptographically-inspired technique, that provides a rigorous, generic, and\nflexible foundation for defense.", "authors": ["Mathias Lecuyer", "Vaggelis Atlidakis", "Roxana Geambasu", "Daniel Hsu", "Suman Jana"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1802.03471v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.03471v2", "num_discussion": 0, "originally_published_time": "2/9/2018", "pid": "1802.03471v2", "published_time": "6/26/2018", "rawpid": "1802.03471", "tags": ["stat.ML", "cs.AI", "cs.CR", "cs.LG"], "title": "Certified Robustness to Adversarial Examples with Differential Privacy"}, {"abstract": "A long-standing problem in the theory of stochastic gradient descent (SGD) is\nto prove that its without-replacement version RandomShuffle converges faster\nthan the usual with-replacement version. We present the first (to our\nknowledge) non-asymptotic solution to this problem, which shows that after a\n\"reasonable\" number of epochs RandomShuffle indeed converges faster than SGD.\nSpecifically, we prove that under strong convexity and second-order smoothness,\nthe sequence generated by RandomShuffle converges to the optimal solution at\nthe rate O(1/T^2 + n^3/T^3), where n is the number of components in the\nobjective, and T is the total number of iterations. This result shows that\nafter a reasonable number of epochs RandomShuffle is strictly better than SGD\n(which converges as O(1/T)). The key step toward showing this better dependence\non T is the introduction of n into the bound; and as our analysis will show, in\ngeneral a dependence on n is unavoidable without further changes to the\nalgorithm. We show that for sparse data RandomShuffle has the rate O(1/T^2),\nagain strictly better than SGD. Furthermore, we discuss extensions to nonconvex\ngradient dominated functions, as well as non-strongly convex settings.", "authors": ["Jeffery Z. HaoChen", "Suvrit Sra"], "category": "math.OC", "comment": "", "img": "/static/thumbs/1806.10077v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10077v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10077v1", "published_time": "6/26/2018", "rawpid": "1806.10077", "tags": ["math.OC", "stat.ML"], "title": "Random Shuffling Beats SGD after Finite Epochs"}, {"abstract": "Social conventions - arbitrary ways to organize group behavior - are an\nimportant part of social life. Any agent that wants to enter an existing\nsociety must be able to learn its conventions (e.g. which side of the road to\ndrive on, which language to speak) from relatively few observations or risk\nbeing unable to coordinate with everyone else. We consider the game theoretic\nframework of David Lewis which views the selection of a social convention as\nthe selection of an equilibrium in a coordination game. We ask how to construct\nreinforcement learning based agents that can solve the convention learning task\nin the self-play paradigm: at training time the agent has access to a good\nmodel of the environment and a small amount of observations about how\nindividuals in society act. The agent then has to construct a policy that is\ncompatible with the test-time social convention. We study three environments\nfrom the literature which have multiple conventions: traffic, communication,\nand risky coordination. In each of these we observe that adding a small amount\nof imitation learning during self-play training greatly increases the\nprobability that the strategy found by self-play fits well with the social\nconvention the agent will face at test time. We show that this works even in an\nenvironment where standard independent multi-agent RL very rarely finds the\ncorrect test-time equilibrium.", "authors": ["Adam Lerer", "Alexander Peysakhovich"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10071v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10071v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10071v1", "published_time": "6/26/2018", "rawpid": "1806.10071", "tags": ["cs.AI", "cs.GT"], "title": "Learning Social Conventions in Markov Games"}, {"abstract": "We study in this paper the problem of jointly clustering and learning\nrepresentations. As several previous studies have shown, learning\nrepresentations that are both faithful to the data to be clustered and adapted\nto the clustering algorithm can lead to better clustering performance, all the\nmore so that the two tasks are performed jointly. We propose here such an\napproach for $k$-Means clustering based on a continuous reparametrization of\nthe objective function that leads to a truly joint solution. The behavior of\nour approach is illustrated on various datasets showing its efficacy in\nlearning representations for objects while clustering them.", "authors": ["Maziar Moradi Fard", "Thibaut Thonet", "Eric Gaussier"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.10069v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10069v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10069v1", "published_time": "6/26/2018", "rawpid": "1806.10069", "tags": ["cs.LG", "stat.ML"], "title": "Deep $k$-Means: Jointly Clustering with $k$-Means and Learning\n  Representations"}, {"abstract": "The success of recent deep convolutional neural networks (CNNs) depends on\nlearning hidden representations that can summarize the important factors of\nvariation behind the data. However, CNNs often criticized as being black boxes\nthat lack interpretability, since they have millions of unexplained model\nparameters. In this work, we describe Network Dissection, a method that\ninterprets networks by providing labels for the units of their deep visual\nrepresentations. The proposed method quantifies the interpretability of CNN\nrepresentations by evaluating the alignment between individual hidden units and\na set of visual semantic concepts. By identifying the best alignments, units\nare given human interpretable labels across a range of objects, parts, scenes,\ntextures, materials, and colors. The method reveals that deep representations\nare more transparent and interpretable than expected: we find that\nrepresentations are significantly more interpretable than they would be under a\nrandom equivalently powerful basis. We apply the method to interpret and\ncompare the latent representations of various network architectures trained to\nsolve different supervised and self-supervised training tasks. We then examine\nfactors affecting the network interpretability such as the number of the\ntraining iterations, regularizations, different initializations, and the\nnetwork depth and width. Finally we show that the interpreted units can be used\nto provide explicit explanations of a prediction given by a CNN for an image.\nOur results highlight that interpretability is an important property of deep\nneural networks that provides new insights into their hierarchical structure.", "authors": ["Bolei Zhou", "David Bau", "Aude Oliva", "Antonio Torralba"], "category": "cs.CV", "comment": "*B. Zhou and D. Bau contributed equally to this work. 15 pages, 27\n  figures", "img": "/static/thumbs/1711.05611v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1711.05611v2", "num_discussion": 0, "originally_published_time": "11/15/2017", "pid": "1711.05611v2", "published_time": "6/26/2018", "rawpid": "1711.05611", "tags": ["cs.CV", "I.2.10"], "title": "Interpreting Deep Visual Representations via Network Dissection"}, {"abstract": "The most widely used activation functions in current deep feed-forward neural\nnetworks are rectified linear units (ReLU), and many alternatives have been\nsuccessfully applied, as well. However, none of the alternatives have managed\nto consistently outperform the rest and there is no unified theory connecting\nproperties of the task and network with properties of activation functions for\nmost efficient training. A possible solution is to have the network learn its\npreferred activation functions. In this work, we introduce Adaptive Blending\nUnits (ABUs), a trainable linear combination of a set of activation functions.\nSince ABUs learn the shape, as well as the overall scaling of the activation\nfunction, we also analyze the effects of adaptive scaling in common activation\nfunctions. We experimentally demonstrate advantages of both adaptive scaling\nand ABUs over common activation functions across a set of systematically varied\nnetwork specifications. We further show that adaptive scaling works by\nmitigating covariate shifts during training, and that the observed advantages\nin performance of ABUs likewise rely largely on the activation function\u0027s\nability to adapt over the course of training.", "authors": ["Leon Ren\u00e9 S\u00fctfeld", "Flemming Brieger", "Holger Finger", "Sonja F\u00fcllhase", "Gordon Pipa"], "category": "cs.LG", "comment": "10 pages, 2 figures", "img": "/static/thumbs/1806.10064v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10064v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10064v1", "published_time": "6/26/2018", "rawpid": "1806.10064", "tags": ["cs.LG", "stat.ML"], "title": "Adaptive Blending Units: Trainable Activation Functions for Deep Neural\n  Networks"}, {"abstract": "Classification problems in security settings are usually contemplated as\nconfrontations in which one or more adversaries try to fool a classifier to\nobtain a benefit. Most approaches to such adversarial classification problems\nhave focused on game theoretical ideas with strong underlying common knowledge\nassumptions, which are actually not realistic in security domains. We provide\nan alternative framework to such problem based on adversarial risk analysis,\nwhich we illustrate with several examples. Computational and implementation\nissues are discussed.", "authors": ["Roi Naveiro", "Alberto Redondo", "David R\u00edos Insua", "Fabrizio Ruggeri"], "category": "stat.ML", "comment": "We are currently working on this paper", "img": "/static/thumbs/1802.07513v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.07513v2", "num_discussion": 0, "originally_published_time": "2/21/2018", "pid": "1802.07513v2", "published_time": "6/26/2018", "rawpid": "1802.07513", "tags": ["stat.ML", "cs.GT", "cs.LG"], "title": "Adversarial classification: An adversarial risk analysis approach"}, {"abstract": "We propose a framework for automated classification of Advertisement Images,\nusing not just Visual features but also Textual cues extracted from embedded\ntext. Our approach takes inspiration from the assumption that Ad images contain\nmeaningful textual content, that can provide discriminative semantic\ninterpretetion, and can thus aid in classifcation tasks. To this end, we\ndevelop a framework using off-the-shelf components, and demonstrate the\neffectiveness of Textual cues in semantic Classfication tasks.", "authors": ["Arka Ujjal dey", "Suman K. Ghosh", "Ernest Valveny"], "category": "cs.CV", "comment": "Accepted in CVPR 2018 Workshop: Towards Automatic Understanding of\n  Visual Advertisements (ADS)", "img": "/static/thumbs/1806.08279v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.08279v2", "num_discussion": 0, "originally_published_time": "6/21/2018", "pid": "1806.08279v2", "published_time": "6/26/2018", "rawpid": "1806.08279", "tags": ["cs.CV"], "title": "Don\u0027t only Feel Read: Using Scene text to understand advertisements"}, {"abstract": "Recent image-to-image translation tasks attempt to extend the model from\none-to-one mapping to multiple mappings by injecting latent code. Based on the\nmathematical formulation of networks with existing way of latent code\ninjection, we show the role of latent code is to control the mean of the\nfeature maps after convolution. Then we find common normalization strategies\nmight reduce the diversity of different mappings or the consistency of one\nspecific mapping, which is not suitable for the multi-mapping tasks. We provide\nthe mathematical derivation that the effects of latent code are eliminated\nafter instance normalization and the distributions of the same mapping become\ninconsistent after batch normalization. To address these problems, we present\nconsistency within diversity design criteria for multi-mapping networks and\npropose central biasing normalization by applying a slight yet significant\nchange to existing normalization strategies. Instead of spatial replicating and\nconcatenating into the input layers, we inject the latent code into the\nnormalization layers where the offset of feature maps is eliminated to ensure\nthe output consistency for one specific mapping and the bias calculated by\nlatent code is appended to achieve the output diversity for different mappings.\nIn this way, not only is the proposed design criteria met, but the modified\ngenerator network has much smaller number of parameters. We apply this\ntechnique to multi-modal and multi-domain translation tasks. Both quantitative\nand qualitative evaluations show that our method outperforms current\nstate-of-the-art methods. Code and pretrained models are available at\nhttps://github.com/Xiaoming-Yu/cbn.", "authors": ["Xiaoming Yu", "Zhenqiang Ying", "Ge Li", "Wen Gao"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10050v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10050v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10050v1", "published_time": "6/26/2018", "rawpid": "1806.10050", "tags": ["cs.CV"], "title": "Multi-Mapping Image-to-Image Translation with Central Biasing\n  Normalization"}, {"abstract": "Crowd counting is one of the core tasks in various surveillance applications.\nA practical system involves estimating accurate head counts in dynamic\nscenarios under different lightning, camera perspective and occlusion states.\nPrevious approaches estimate head counts despite that they can vary\ndramatically in different density settings; the crowd is often unevenly\ndistributed and the results are therefore unsatisfactory. In this paper, we\npropose a lightweight deep learning framework that can automatically estimate\nthe crowd density level and adaptively choose between different counter\nnetworks that are explicitly trained for different density domains. Experiments\non two recent crowd counting datasets, UCF_CC_50 and ShanghaiTech, show that\nthe proposed mechanism achieves promising improvements over state-of-the-art\nmethods. Moreover, runtime speed is 20 FPS on a single GPU.", "authors": ["Li Wang", "Weiyuan Shao", "Yao Lu", "Hao Ye", "Jian Pu", "Yingbin Zheng"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.10040v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10040v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10040v1", "published_time": "6/26/2018", "rawpid": "1806.10040", "tags": ["cs.CV"], "title": "Crowd Counting with Density Adaption Networks"}, {"abstract": "We present an adversarial exploration strategy, a simple yet effective\nimitation learning scheme that incentivizes exploration of an environment\nwithout any extrinsic reward or human demonstration. Our framework consists of\na deep reinforcement learning (DRL) agent and an inverse dynamics model\ncontesting with each other. The former collects training samples for the\nlatter, and its objective is to maximize the error of the latter. The latter is\ntrained with samples collected by the former, and generates rewards for the\nformer when it fails to predict the actual action taken by the former. In such\na competitive setting, the DRL agent learns to generate samples that the\ninverse dynamics model fails to predict correctly, and the inverse dynamics\nmodel learns to adapt to the challenging samples. We further propose a reward\nstructure that ensures the DRL agent collects only moderately hard samples and\nnot overly hard ones that prevent the inverse model from imitating effectively.\nWe evaluate the effectiveness of our method on several OpenAI gym robotic arm\nand hand manipulation tasks against a number of baseline models. Experimental\nresults show that our method is comparable to that directly trained with expert\ndemonstrations, and superior to the other baselines even without any human\npriors.", "authors": ["Zhang-Wei Hong", "Tsu-Jui Fu", "Tzu-Yun Shann", "Yi-Hsiang Chang", "Chun-Yi Lee"], "category": "cs.LG", "comment": "Submitted to NIPS-2018", "img": "/static/thumbs/1806.10019v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10019v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10019v1", "published_time": "6/26/2018", "rawpid": "1806.10019", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Adversarial Exploration Strategy for Self-Supervised Imitation Learning"}, {"abstract": "Combinatorial preference aggregation has many applications in AI. Given the\nexponential nature of these preferences, compact representations are needed and\n($m$)CP-nets are among the most studied ones. Sequential and global voting are\ntwo ways to aggregate preferences over CP-nets. In the former, preferences are\naggregated feature-by-feature. Hence, when preferences have specific feature\ndependencies, sequential voting may exhibit voting paradoxes, i.e., it might\nselect sub-optimal outcomes. To avoid paradoxes in sequential voting, one has\noften assumed the $\\mathcal{O}$-legality restriction, which imposes a shared\ntopological order among all the CP-nets. On the contrary, in global voting,\nCP-nets are considered as a whole during preference aggregation. For this\nreason, global voting is immune from paradoxes, and there is no need to impose\nrestrictions over the CP-nets\u0027 topological structure. Sequential voting over\n$\\mathcal{O}$-legal CP-nets has extensively been investigated. On the other\nhand, global voting over non-$\\mathcal{O}$-legal CP-nets has not carefully been\nanalyzed, despite it was stated in the literature that a theoretical comparison\nbetween global and sequential voting was promising and a precise complexity\nanalysis for global voting has been asked for multiple times. In quite few\nworks, very partial results on the complexity of global voting over CP-nets\nhave been given. We start to fill this gap by carrying out a thorough\ncomplexity analysis of Pareto and majority global voting over not necessarily\n$\\mathcal{O}$-legal acyclic binary polynomially connected (m)CP-nets. We settle\nthese problems in the polynomial hierarchy, and some of them in PTIME or\nLOGSPACE, whereas EXPTIME was the previously known upper bound for most of\nthem. We show various tight lower bounds and matching upper bounds for problems\nthat up to date did not have any explicit non-obvious lower bound.", "authors": ["Thomas Lukasiewicz", "Enrico Malizia"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.10018v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10018v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.10018v1", "published_time": "6/26/2018", "rawpid": "1806.10018", "tags": ["cs.AI", "cs.GT"], "title": "Complexity Results for Preference Aggregation over (m)CP-nets: Pareto\n  and Majority Voting"}, {"abstract": "Grammar induction is the task of learning a grammar from a set of examples.\nRecently, neural networks have been shown to be powerful learning machines that\ncan identify patterns in streams of data. In this work we investigate their\neffectiveness in inducing a regular grammar from data, without any assumptions\nabout the grammar. We train a recurrent neural network to distinguish between\nstrings that are in or outside a regular language, and utilize an algorithm for\nextracting the learned finite-state automaton. We apply this method to several\nregular languages and find unexpected results regarding the connections between\nthe network\u0027s states that may be regarded as evidence for generalization.", "authors": ["Mor Cohen", "Avi Caciularu", "Idan Rejwan", "Jonathan Berant"], "category": "cs.CL", "comment": "Accepted to L\u0026R 2018 workshop, ICML \u0026 IJCAI", "img": "/static/thumbs/1710.10453v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1710.10453v2", "num_discussion": 0, "originally_published_time": "10/28/2017", "pid": "1710.10453v2", "published_time": "6/26/2018", "rawpid": "1710.10453", "tags": ["cs.CL"], "title": "Inducing Regular Grammars Using Recurrent Neural Networks"}, {"abstract": "Deep Reinforcement Learning has managed to achieve state-of-the-art results\nin learning control policies directly from raw pixels. However, despite its\nremarkable success, it fails to generalize, a fundamental component required in\na stable Artificial Intelligence system. Using the Atari game Breakout, we\ndemonstrate the difficulty of a trained agent in adjusting to simple\nmodifications in the raw image, ones that a human could adapt to trivially. In\ntransfer learning, the goal is to use the knowledge gained from the source task\nto make the training of the target task faster and better. We show that using\nvarious forms of fine-tuning, a common method for transfer learning, is not\neffective for adapting to such small visual changes. In fact, it is often\neasier to re-train the agent from scratch than to fine-tune a trained agent. We\nsuggest that in some cases transfer learning can be improved by adding a\ndedicated component whose goal is to learn to visually map between the known\ndomain and the new one. Concretely, we use Generative Adversarial Networks\n(GANs) to create a mapping function to translate images in the target task to\ncorresponding images in the source task, allowing us to transform between the\ndifferent tasks. We show that learning this mapping is substantially more\nefficient than re-training. A visualization of a trained agent playing in a\nmodified condition, with and without the GAN transfer, can be seen in\nhttps://youtu.be/e2TwjduPT8g .", "authors": ["Shani Gamrian", "Yoav Goldberg"], "category": "cs.CV", "comment": "10 pages, 3 figures, 2 tables. v3 - fixing a broken link", "img": "/static/thumbs/1806.07377v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.07377v3", "num_discussion": 0, "originally_published_time": "5/31/2018", "pid": "1806.07377v3", "published_time": "6/26/2018", "rawpid": "1806.07377", "tags": ["cs.CV", "cs.AI", "cs.LG"], "title": "Transfer Learning for Related Reinforcement Learning Tasks via\n  Image-to-Image Translation"}, {"abstract": "We specialize the decoupled extended Kalman filter (DEKF) for online\nparameter learning in factorization models, including factorization machines,\nmatrix and tensor factorization, and illustrate the effectiveness of the\napproach through simulations. Learning model parameters through the DEKF makes\nfactorization models more broadly useful by allowing for more flexible\nobservations through the entire exponential family, modeling parameter drift,\nand producing parameter uncertainty estimates that can enable explore/exploit\nand other applications. We use a more general dynamics of the parameters than\nthe standard DEKF, allowing parameter drift while encouraging reasonable\nvalues. We also present an alternate derivation of the regular extended Kalman\nfilter and DEKF that connects these methods to natural gradient methods, and\nsuggests a similarly decoupled version of the iterated extended Kalman filter.", "authors": ["Carlos Alberto Gomez-Uribe", "Brian Karrer"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1806.09976v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09976v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09976v1", "published_time": "6/26/2018", "rawpid": "1806.09976", "tags": ["stat.ML", "cs.LG"], "title": "The decoupled extended Kalman filter for dynamic exponential-family\n  factorization models"}, {"abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic\nway to perform a multitude of tasks in human-centric environments. However,\neffectively controlling them remains challenging due to their high\ndimensionality and large number of potential contacts. Deep reinforcement\nlearning (DRL) provides a model-agnostic approach to control complex dynamical\nsystems, but has not been shown to scale to high-dimensional dexterous\nmanipulation. Furthermore, deployment of DRL on physical systems remains\nchallenging due to sample inefficiency. Consequently, the success of DRL in\nrobotics has thus far been limited to simpler manipulators and tasks. In this\nwork, we show that model-free DRL can effectively scale up to complex\nmanipulation tasks with a high-dimensional 24-DoF hand, and solve them from\nscratch in simulated experiments. Furthermore, with the use of a small number\nof human demonstrations, the sample complexity can be significantly reduced,\nwhich enables learning with sample sizes equivalent to a few hours of robot\nexperience. The use of demonstrations result in policies that exhibit very\nnatural movements and, surprisingly, are also substantially more robust.", "authors": ["Aravind Rajeswaran", "Vikash Kumar", "Abhishek Gupta", "Giulia Vezzani", "John Schulman", "Emanuel Todorov", "Sergey Levine"], "category": "cs.LG", "comment": "Accepted for presentation at Robotics: Science and Systems (RSS)\n  2018. Project page:\n  https://sit...", "img": "/static/thumbs/1709.10087v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1709.10087v2", "num_discussion": 0, "originally_published_time": "9/28/2017", "pid": "1709.10087v2", "published_time": "6/26/2018", "rawpid": "1709.10087", "tags": ["cs.LG", "cs.AI", "cs.RO"], "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning\n  and Demonstrations"}, {"abstract": "Online social networks are more and more studied. The links between users of\na social network are important and have to be well qualified in order to detect\ncommunities and find influencers for example. In this paper, we present an\napproach based on the theory of belief functions to estimate the degrees of\ncognitive independence between users in a social network. We experiment the\nproposed method on a large amount of data gathered from the Twitter social\nnetwork.", "authors": ["Manel Chehibi", "Mouna Chebbah", "Arnaud Martin"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.09959v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09959v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09959v1", "published_time": "6/26/2018", "rawpid": "1806.09959", "tags": ["cs.AI", "cs.SI"], "title": "Independence of Sources in Social Networks"}, {"abstract": "Local feature description is a fundamental yet challenging task in 3D\ncomputer vision. This paper proposes a novel descriptor, named Statistic of\nDeviation Angles on Subdivided Space (SDASS), of encoding geometrical and\nspatial information of local surface on Local Reference Axis (LRA). In terms of\nencoding geometrical information, considering that surface normals, which are\nusually used for encoding geometrical information of local surface, are\nvulnerable to various nuisances (e.g., noise, varying mesh resolutions etc.),\nwe propose a robust geometrical attribute, called Local Minimum Axis (LMA), to\nreplace the normals for generating the geometrical feature in our SDASS\ndescriptor. For encoding spatial information, we use two spatial features for\nfully encoding the spatial information of a local surface based on LRA which\nusually presents high overall repeatability than Local Reference Axis (LRF).\nBesides, an improved LRA is proposed for increasing the robustness of our SDASS\nto noise and varying mesh resolutions. The performance of the SDASS descriptor\nis rigorously tested on four popular datasets. The results show that our\ndescriptor has a high descriptiveness and strong robustness, and its\nperformance outperform existing algorithms by a large margin. Finally, the\nproposed descriptor is applied to 3D registration. The accurate result further\nconfirms the effectiveness of our SDASS method.", "authors": ["Bao Zhao", "Xinyi Le", "Juntong Xi"], "category": "cs.CV", "comment": "21 pages, 15 figures", "img": "/static/thumbs/1711.05368v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1711.05368v3", "num_discussion": 0, "originally_published_time": "11/15/2017", "pid": "1711.05368v3", "published_time": "6/26/2018", "rawpid": "1711.05368", "tags": ["cs.CV"], "title": "A Novel SDASS Descriptor for Fully Encoding the Information of 3D Local\n  Surface"}, {"abstract": "We present a general constraint-based encoding for domain-independent task\nplanning. Task planning is characterized by causal relationships expressed as\nconditions and effects of optional actions. Possible actions are typically\nrepresented by templates, where each template can be instantiated into a number\nof primitive actions. While most previous work for domain-independent task\nplanning has focused on primitive actions in a state-oriented view, our\nencoding uses a fully lifted representation at the level of action templates.\nIt follows a time-oriented view in the spirit of previous work in\nconstraint-based scheduling. As a result, the proposed encoding is simple and\ncompact as it grows with the number of actions in a solution plan rather than\nthe number of possible primitive actions. When solved with an SMT solver, we\nshow that the proposed encoding is slightly more efficient than\nstate-of-the-art methods on temporally constrained planning benchmarks while\nclearly outperforming other fully constraint-based approaches.", "authors": ["Arthur Bit-Monnot"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.09954v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09954v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09954v1", "published_time": "6/26/2018", "rawpid": "1806.09954", "tags": ["cs.AI"], "title": "A Constraint-based Encoding for Domain-Independent Temporal Planning"}, {"abstract": "The problem of low-rank matrix estimation recently received a lot of\nattention due to challenging applications. A lot of work has been done on\nrank-penalized methods and convex relaxation, both on the theoretical and\napplied sides. However, only a few papers considered Bayesian estimation. In\nthis paper, we review the different type of priors considered on matrices to\nfavour low-rank. We also prove that the obtained Bayesian estimators, under\nsuitable assumptions, enjoys the same optimality properties as the ones based\non penalization.", "authors": ["Pierre Alquier"], "category": "stat.ML", "comment": "Corrected version of a paper published in the proceedings of ALT 2013", "img": "/static/thumbs/1306.3862v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1306.3862v2", "num_discussion": 0, "originally_published_time": "6/17/2013", "pid": "1306.3862v2", "published_time": "6/26/2018", "rawpid": "1306.3862", "tags": ["stat.ML"], "title": "Bayesian methods for low-rank matrix estimation: short survey and\n  theoretical study"}, {"abstract": "Black box systems for automated decision making, often based on machine\nlearning over (big) data, map a user\u0027s features into a class or a score without\nexposing the reasons why. This is problematic not only for lack of\ntransparency, but also for possible biases hidden in the algorithms, due to\nhuman prejudices and collection artifacts hidden in the training data, which\nmay lead to unfair or wrong decisions. We introduce the local-to-global\nframework for black box explanation, a novel approach with promising early\nresults, which paves the road for a wide spectrum of future developments along\nthree dimensions: (i) the language for expressing explanations in terms of\nhighly expressive logic-based rules, with a statistical and causal\ninterpretation; (ii) the inference of local explanations aimed at revealing the\nlogic of the decision adopted for a specific instance by querying and auditing\nthe black box in the vicinity of the target instance; (iii), the bottom-up\ngeneralization of the many local explanations into simple global ones, with\nalgorithms that optimize the quality and comprehensibility of explanations.", "authors": ["Dino Pedreschi", "Fosca Giannotti", "Riccardo Guidotti", "Anna Monreale", "Luca Pappalardo", "Salvatore Ruggieri", "Franco Turini"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.09936v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09936v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09936v1", "published_time": "6/26/2018", "rawpid": "1806.09936", "tags": ["cs.AI", "cs.CY", "cs.LG"], "title": "Open the Black Box Data-Driven Explanation of Black Box Decision Systems"}, {"abstract": "In this paper we present a new method for text-independent speaker\nverification that combines segmental dynamic time warping (SDTW) and the\nd-vector approach. The d-vectors, generated from a feed forward deep neural\nnetwork trained to distinguish between speakers, are used as features to\nperform alignment and hence calculate the overall distance between the\nenrolment and test utterances.We present results on the NIST 2008 data set for\nspeaker verification where the proposed method outperforms the conventional\ni-vector baseline with PLDA scores and outperforms d-vector approach with local\ndistances based on cosine and PLDA scores. Also score combination with the\ni-vector/PLDA baseline leads to significant gains over both methods.", "authors": ["Mohamed Adel", "Mohamed Afify", "Akram Gaballah"], "category": "cs.SD", "comment": "Submitted to SLT 2018", "img": "/static/thumbs/1806.09932v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09932v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09932v1", "published_time": "6/26/2018", "rawpid": "1806.09932", "tags": ["cs.SD", "cs.CL", "eess.AS"], "title": "Text-Independent Speaker Verification Based on Deep Neural Networks and\n  Segmental Dynamic Time Warping"}, {"abstract": "Medical imaging tasks often involve multiple contrasts, such as T1- and\nT2-weighted magnetic resonance imaging (MRI) data. These contrasts capture\ninformation associated with the same underlying anatomy and thus exhibit\nsimilarities. In this paper, we propose a Coupled Dictionary Learning based\nmulti-contrast MRI reconstruction (CDLMRI) approach to leverage an available\nguidance contrast to restore the target contrast. Our approach consists of\nthree stages: coupled dictionary learning, coupled sparse denoising, and\n$k$-space consistency enforcing. The first stage learns a group of dictionaries\nthat capture correlations among multiple contrasts. By capitalizing on the\nlearned adaptive dictionaries, the second stage performs joint sparse coding to\ndenoise the corrupted target image with the aid of a guidance contrast. The\nthird stage enforces consistency between the denoised image and the\nmeasurements in the $k$-space domain. Numerical experiments on the\nretrospective under-sampling of clinical MR images demonstrate that\nincorporating additional guidance contrast via our design improves MRI\nreconstruction, compared to state-of-the-art approaches.", "authors": ["Pingfan Song", "Lior Weizman", "Joao F. C. Mota", "Yonina C. Eldar", "Miguel R. D. Rodrigues"], "category": "cs.CV", "comment": "2018 IEEE International Conference on Image Processing (ICIP)", "img": "/static/thumbs/1806.09930v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09930v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09930v1", "published_time": "6/26/2018", "rawpid": "1806.09930", "tags": ["cs.CV"], "title": "Coupled Dictionary Learning for Multi-contrast MRI Reconstruction"}, {"abstract": "This work introduces the concept of tangent space regularization for\nneural-network models of dynamical systems. The tangent space to the dynamics\nfunction of many physical systems of interest in control applications exhibits\nuseful properties, e.g., smoothness, motivating regularization of the model\nJacobian along system trajectories using assumptions on the tangent space of\nthe dynamics. Without assumptions, large amounts of training data are required\nfor a neural network to learn the full non-linear dynamics without overfitting.\nWe compare different network architectures on one-step prediction and\nsimulation performance and investigate the propensity of different\narchitectures to learn models with correct input-output Jacobian. Furthermore,\nthe influence of $L_2$ weight regularization on the learned Jacobian eigenvalue\nspectrum, and hence system stability, is investigated.", "authors": ["Fredrik Bagge Carlson", "Rolf Johansson", "Anders Robertsson"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09919v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09919v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09919v1", "published_time": "6/26/2018", "rawpid": "1806.09919", "tags": ["cs.LG", "cs.SY", "stat.ML"], "title": "Tangent-Space Regularization for Neural-Network Models of Dynamical\n  Systems"}, {"abstract": "Decision making is a process that is extremely prone to different biases. In\nthis paper we consider learning fair representation that aim at removing\nnuisance (sensitive) information from the decision process. For this purpose,\nwe propose to use deep generative modeling and adapt a hierarchical Variational\nAuto-Encoder to learn fair representations. Moreover, we utilize the mutual\ninformation as a useful regularizer for enforcing fairness of a representation.\nIn experiments on two benchmark datasets and two scenarios where the sensitive\nvariables are fully and partially observable, we show that the proposed\napproach either outperforms or performs on par with the current best model.", "authors": ["Philip Botros", "Jakub M. Tomczak"], "category": "stat.ML", "comment": "ICML Workshop on Theoretical Foundations and Applications of Deep\n  Generative Models 2018", "img": "/static/thumbs/1806.09918v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09918v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09918v1", "published_time": "6/26/2018", "rawpid": "1806.09918", "tags": ["stat.ML", "cs.LG"], "title": "Hierarchical VampPrior Variational Fair Auto-Encoder"}, {"abstract": "Although Deep Convolutional Neural Networks trained with strong pixel-level\nannotations have significantly pushed the performance in semantic segmentation,\nannotation efforts required for the creation of training data remains a\nroadblock for further improvements. We show that augmentation of the weakly\nannotated training dataset with synthetic images minimizes both the annotation\nefforts and also the cost of capturing images with sufficient variety.\nEvaluation on the PASCAL 2012 validation dataset shows an increase in mean IOU\nfrom 52.80% to 55.47% by adding just 100 synthetic images per object class. Our\napproach is thus a promising solution to the problems of annotation and dataset\ncollection.", "authors": ["Manik Goyal", "Param Rajpura", "Hristo Bojinov", "Ravi Hegde"], "category": "cs.CV", "comment": "13 pages, 5 figures", "img": "/static/thumbs/1709.00849v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1709.00849v3", "num_discussion": 0, "originally_published_time": "9/4/2017", "pid": "1709.00849v3", "published_time": "6/26/2018", "rawpid": "1709.00849", "tags": ["cs.CV"], "title": "Dataset Augmentation with Synthetic Images Improves Semantic\n  Segmentation"}, {"abstract": "Organ image segmentation can be improved by implementing prior knowledge\nabout the anatomy. One way of doing this is by training an autoencoder to learn\na lowdimensional representation of the segmentation. In this paper, this is\napplied in multi-label prostate MR segmentation, with some positive results.", "authors": ["Ard de Gelder", "Henkjan Huisman"], "category": "eess.IV", "comment": "", "img": "/static/thumbs/1806.08216v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.08216v2", "num_discussion": 0, "originally_published_time": "6/9/2018", "pid": "1806.08216v2", "published_time": "6/26/2018", "rawpid": "1806.08216", "tags": ["eess.IV", "cs.NE"], "title": "Autoencoders for Multi-Label Prostate MR Segmentation"}, {"abstract": "Structured prediction provides a general framework to deal with supervised\nproblems where the outputs have semantically rich structure. While classical\napproaches consider finite, albeit potentially huge, output spaces, in this\npaper we discuss how structured prediction can be extended to a continuous\nscenario. Specifically, we study a structured prediction approach to manifold\nvalued regression. We characterize a class of problems for which the considered\napproach is statistically consistent and study how geometric optimization can\nbe used to compute the corresponding estimator. Promising experimental results\non both simulated and real data complete our study.", "authors": ["Alessandro Rudi", "Carlo Ciliberto", "Gian Maria Marconi", "Lorenzo Rosasco"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1806.09908v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09908v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09908v1", "published_time": "6/26/2018", "rawpid": "1806.09908", "tags": ["stat.ML", "cs.LG"], "title": "Manifold Structured Prediction"}, {"abstract": "Medical image registration is an active research topic and forms a basis for\nmany medical image analysis tasks. Although image registration is a rather\ngeneral concept specialized methods are usually required to target a specific\nregistration problem. The development and implementation of such methods has\nbeen tough so far as the gradient of the objective has to be computed. Also,\nits evaluation has to be performed preferably on a GPU for larger images and\nfor more complex transformation models and regularization terms. This hinders\nresearchers from rapid prototyping and poses hurdles to reproduce research\nresults. There is a clear need for an environment which hides this complexity\nto put the modeling and the experimental exploration of registration methods\ninto the foreground. With the \"Autograd Image Registration Laboratory\"\n(AirLab), we introduce an open laboratory for image registration tasks, where\nthe analytic gradients of the objective function are computed automatically and\nthe device where the computations are performed, on a CPU or a GPU, is\ntransparent. It is meant as a laboratory for researchers and developers\nenabling them to rapidly try out new ideas for registering images and to\nreproduce registration results which have already been published. AirLab is\nimplemented in Python using PyTorch as tensor and optimization library and\nSimpleITK for basic image IO. Therefore, it profits from recent advances made\nby the machine learning community concerning optimization and deep neural\nnetwork models.\n  The present draft of this paper roughly outlines AirLab with first code\nsnippets and performance analyses. A more exhaustive introduction will follow\nas a final version soon.", "authors": ["Robin Sandk\u00fchler", "Christoph Jud", "Simon Andermatt", "Philippe C. Cattin"], "category": "cs.CV", "comment": "Corresponding author: Christoph Jud, e-mail: christoph.jud@unibas.ch", "img": "/static/thumbs/1806.09907v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09907v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09907v1", "published_time": "6/26/2018", "rawpid": "1806.09907", "tags": ["cs.CV"], "title": "AirLab: Autograd Image Registration Laboratory"}, {"abstract": "Existing automatic music generation approaches that feature deep learning can\nbe broadly classified into two types: raw audio models and symbolic models.\nSymbolic models, which train and generate at the note level, are currently the\nmore prevalent approach; these models can capture long-range dependencies of\nmelodic structure, but fail to grasp the nuances and richness of raw audio\ngenerations. Raw audio models, such as DeepMind\u0027s WaveNet, train directly on\nsampled audio waveforms, allowing them to produce realistic-sounding, albeit\nunstructured music. In this paper, we propose an automatic music generation\nmethodology combining both of these approaches to create structured,\nrealistic-sounding compositions. We consider a Long Short Term Memory network\nto learn the melodic structure of different styles of music, and then use the\nunique symbolic generations from this model as a conditioning input to a\nWaveNet-based raw audio generator, creating a model for automatic, novel music.\nWe then evaluate this approach by showcasing results of this work.", "authors": ["Rachel Manzelli", "Vijay Thakkar", "Ali Siahkamari", "Brian Kulis"], "category": "cs.SD", "comment": "Presented at the ISMIR 2018 Conference", "img": "/static/thumbs/1806.09905v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09905v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09905v1", "published_time": "6/26/2018", "rawpid": "1806.09905", "tags": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "title": "Conditioning Deep Generative Raw Audio Models for Structured Automatic\n  Music"}, {"abstract": "Attributing the pixels of an input image to a certain category is an\nimportant and well-studied problem in computer vision, with applications\nranging from weakly supervised localisation to understanding hidden effects in\nthe data. In recent years, approaches based on interpreting a previously\ntrained neural network classifier have become the de facto state-of-the-art and\nare commonly used on medical as well as natural image datasets. In this paper,\nwe discuss a limitation of these approaches which may lead to only a subset of\nthe category specific features being detected. To address this problem we\ndevelop a novel feature attribution technique based on Wasserstein Generative\nAdversarial Networks (WGAN), which does not suffer from this limitation. We\nshow that our proposed method performs substantially better than the\nstate-of-the-art for visual attribution on a synthetic dataset and on real 3D\nneuroimaging data from patients with mild cognitive impairment (MCI) and\nAlzheimer\u0027s disease (AD). For AD patients the method produces compellingly\nrealistic disease effect maps which are very close to the observed effects.", "authors": ["Christian F. Baumgartner", "Lisa M. Koch", "Kerem Can Tezcan", "Jia Xi Ang", "Ender Konukoglu"], "category": "cs.CV", "comment": "Accepted to CVPR 2018", "img": "/static/thumbs/1711.08998v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1711.08998v3", "num_discussion": 0, "originally_published_time": "11/24/2017", "pid": "1711.08998v3", "published_time": "6/26/2018", "rawpid": "1711.08998", "tags": ["cs.CV"], "title": "Visual Feature Attribution using Wasserstein GANs"}, {"abstract": "Visual Question answering is a challenging problem requiring a combination of\nconcepts from Computer Vision and Natural Language Processing. Most existing\napproaches use a two streams strategy, computing image and question features\nthat are consequently merged using a variety of techniques. Nonetheless, very\nfew rely on higher level image representations, which allow to capture semantic\nand spatial relationships. In this paper, we propose a novel graph-based\napproach for Visual Question Answering. Our method combines a graph learner\nmodule, which learns a question specific graph representation of the input\nimage, with the recent concept of graph convolutions, aiming to learn image\nrepresentations that capture question specific interactions. We test our\napproach on the VQA v2 dataset using a simple baseline architecture enhanced by\nthe proposed graph learner module. We obtain state of the art results with\n65.77% accuracy and demonstrate the interpretability of the proposed method.", "authors": ["Will Norcliffe-Brown", "Efstathios Vafeias", "Sarah Parisot"], "category": "cs.CV", "comment": "11 pages, 6 figures", "img": "/static/thumbs/1806.07243v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.07243v4", "num_discussion": 0, "originally_published_time": "6/19/2018", "pid": "1806.07243v4", "published_time": "6/26/2018", "rawpid": "1806.07243", "tags": ["cs.CV"], "title": "Learning Conditioned Graph Structures for Interpretable Visual Question\n  Answering"}, {"abstract": "Deep Convolutional Sparse Coding (D-CSC) is a framework reminiscent of deep\nconvolutional neural networks (DCNNs), but by omitting the learning of the\ndictionaries one can more transparently analyse the role of the activation\nfunction and its ability to recover activation paths through the layers.\nPapyan, Romano, and Elad conducted an analysis of such an architecture,\ndemonstrated the relationship with DCNNs and proved conditions under which the\nD-CSC is guaranteed to recover specific activation paths. A technical\ninnovation of their work highlights that one can view the efficacy of the ReLU\nnonlinear activation function of a DCNN through a new variant of the tensor\u0027s\nsparsity, referred to as stripe-sparsity. Using this they proved that\nrepresentations with an activation density proportional to the ambient\ndimension of the data are recoverable. We extend their uniform guarantees to a\nmodified model and prove that with high probability the true activation is\ntypically possible to recover for a greater density of activations per layer.\nOur extension follows from incorporating the prior work on one step\nthresholding by Schnass and Vandergheynst.", "authors": ["Michael Murray", "Jared Tanner"], "category": "cs.LG", "comment": "Long version (12 pages excluding references) of paper accepted at the\n  IEEE 2018 Data Science Works...", "img": "/static/thumbs/1806.09888v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09888v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09888v1", "published_time": "6/26/2018", "rawpid": "1806.09888", "tags": ["cs.LG", "stat.ML"], "title": "Towards an understanding of CNNs: analysing the recovery of activation\n  pathways via Deep Convolutional Sparse Coding"}, {"abstract": "Cancer diagnosis and treatment often require a personalized analysis for each\npatient nowadays, due to the heterogeneity among the different types of tumor\nand among patients. Radiomics is a recent medical imaging field that has shown\nduring the past few years to be promising for achieving this personalization.\nHowever, a recent study shows that most of the state-of-the-art works in\nRadiomics fail to identify this problem as a multi-view learning task and that\nmulti-view learning techniques are generally more efficient. In this work, we\npropose to further investigate the potential of one family of multi-view\nlearning methods based on Multiple Classifiers Systems where one classifier is\nlearnt on each view and all classifiers are combined afterwards. In particular,\nwe propose a random forest based dynamic weighted voting scheme, which\npersonalizes the combination of views for each new patient for classification\ntasks. The proposed method is validated on several real-world Radiomics\nproblems.", "authors": ["Hongliu Cao", "Simon Bernard", "Laurent Heutte", "Robert Sabourin"], "category": "cs.CV", "comment": "10 pages", "img": "/static/thumbs/1806.07686v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.07686v2", "num_discussion": 0, "originally_published_time": "6/20/2018", "pid": "1806.07686v2", "published_time": "6/26/2018", "rawpid": "1806.07686", "tags": ["cs.CV"], "title": "Dynamic voting in multi-view learning for radiomics applications"}, {"abstract": "In real-world scenarios, many data processing problems often involve\nheterogeneous images associated with different imaging modalities. Since these\nmultimodal images originate from the same phenomenon, it is realistic to assume\nthat they share common attributes or characteristics. In this paper, we propose\na multi-modal image processing framework based on coupled dictionary learning\nto capture similarities and disparities between different image modalities. In\nparticular, our framework can capture favorable structure similarities across\ndifferent image modalities such as edges, corners, and other elementary\nprimitives in a learned sparse transform domain, instead of the original pixel\ndomain, that can be used to improve a number of image processing tasks such as\ndenoising, inpainting, or super-resolution. Practical experiments demonstrate\nthat incorporating multimodal information using our framework brings notable\nbenefits.", "authors": ["Pingfan Song", "Miguel R. D. Rodrigues"], "category": "cs.CV", "comment": "SPAWC 2018, 19th IEEE International Workshop On Signal Processing\n  Advances In Wireless Communicati...", "img": "/static/thumbs/1806.09882v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09882v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09882v1", "published_time": "6/26/2018", "rawpid": "1806.09882", "tags": ["cs.CV"], "title": "Multi-modal Image Processing based on Coupled Dictionary Learning"}, {"abstract": "In order to reach human performance on complex visual tasks, artificial\nsystems need to incorporate a significant amount of understanding of the world\nin terms of macroscopic objects, movements, forces, etc. Inspired by work on\nintuitive physics in infants, we propose an evaluation framework which\ndiagnoses how much a given system understands about physics by testing whether\nit can tell apart well matched videos of possible versus impossible events. The\ntest requires systems to compute a physical plausibility score over an entire\nvideo. It is free of bias and can test a range of specific physical reasoning\nskills. We then describe the first release of a benchmark dataset aimed at\nlearning intuitive physics in an unsupervised way, using videos constructed\nwith a game engine. We describe two Deep Neural Network baseline systems\ntrained with a future frame prediction objective and tested on the possible\nversus impossible discrimination task. The analysis of their results compared\nto human data gives novel insights in the potentials and limitations of next\nframe prediction architectures.", "authors": ["Ronan Riochet", "Mario Ynocente Castro", "Mathieu Bernard", "Adam Lerer", "Rob Fergus", "V\u00e9ronique Izard", "Emmanuel Dupoux"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1803.07616v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.07616v2", "num_discussion": 0, "originally_published_time": "3/20/2018", "pid": "1803.07616v2", "published_time": "6/26/2018", "rawpid": "1803.07616", "tags": ["cs.AI", "cs.CV"], "title": "IntPhys: A Framework and Benchmark for Visual Intuitive Physics\n  Reasoning"}, {"abstract": "Active learning is relevant and challenging for high-dimensional regression\nmodels when the annotation of the samples is expensive. Yet most of the\nexisting sampling methods cannot be applied to large-scale problems, consuming\ntoo much time for data processing. In this paper, we propose a fast active\nlearning algorithm for regression, tailored for neural network models. It is\nbased on uncertainty estimation from stochastic dropout output of the network.\nExperiments on both synthetic and real-world datasets show comparable or better\nperformance (depending on the accuracy metric) as compared to the baselines.\nThis approach can be generalized to other deep learning architectures. It can\nbe used to systematically improve a machine-learning model as it offers a\ncomputationally efficient way of sampling additional data.", "authors": ["Evgenii Tsymbalov", "Maxim Panov", "Alexander Shapeev"], "category": "cs.LG", "comment": "Report on AIST 2018; will be published in Springer LNCS series", "img": "/static/thumbs/1806.09856v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09856v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09856v1", "published_time": "6/26/2018", "rawpid": "1806.09856", "tags": ["cs.LG", "stat.ML"], "title": "Dropout-based Active Learning for Regression"}, {"abstract": "We introduce a new convex optimization problem, termed quadratic decomposable\nsubmodular function minimization. The problem arises in many learning on graphs\nand hypergraphs settings and is closely related to decomposable submodular\nfunction minimization. We approach the problem via a new dual strategy and\ndescribe an objective that may be optimized via random coordinate descent (RCD)\nmethods and projections onto cones. We also establish the linear convergence\nrate of the RCD algorithm and develop efficient projection algorithms with\nprovable performance guarantees. Numerical experiments in transductive learning\non hypergraphs confirm the efficiency of the proposed algorithm and demonstrate\nthe significant improvements in prediction accuracy with respect to\nstate-of-the-art methods.", "authors": ["Pan Li", "Niao He", "Olgica Milenkovic"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09842v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09842v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09842v1", "published_time": "6/26/2018", "rawpid": "1806.09842", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Quadratic Decomposable Submodular Function Minimization"}, {"abstract": "We propose a new clustering method based on optimal transportation. We solve\noptimal transportation with variational principles and investigate the use of\npower diagrams as transportation plans for aggregating arbitrary domains into a\nfixed number of clusters. We iteratively drive centroids through target domains\nwhile maintaining the minimum clustering energy by adjusting the power\ndiagrams. Thus, we simultaneously pursue clustering and the Wasserstein\ndistances between centroids and target domains, resulting in a robust\nmeasure-preserving mapping. In general, there are two approaches for solving\noptimal transportation problem -- Kantorovich\u0027s v.s. Brenier\u0027s. While most\nresearchers focus on Kantorovich\u0027s approach, we propose a solution to\nclustering problem following Brenier\u0027s approach and achieve a competitive\nresult with the state-of-the-art method. We demonstrate our applications to\ndifferent areas such as domain adaptation, remeshing, and representation\nlearning on synthetic and real data.", "authors": ["Liang Mi", "Wen Zhang", "Xianfeng Gu", "Yalin Wang"], "category": "cs.CV", "comment": "Submitted to ECCV 2018", "img": "/static/thumbs/1806.09045v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09045v2", "num_discussion": 0, "originally_published_time": "6/23/2018", "pid": "1806.09045v2", "published_time": "6/26/2018", "rawpid": "1806.09045", "tags": ["cs.CV"], "title": "Variational Wasserstein Clustering"}, {"abstract": "Can machines design? Can they come up with creative solutions to problems and\nbuild tools and artifacts across a wide range of domains? Recent advances in\nthe field of computational creativity and formal Artificial General\nIntelligence (AGI) provide frameworks for machines with the general ability to\ndesign. In this paper we propose to integrate a formal computational creativity\nframework into the G\\\"odel machine framework. We call the resulting framework\ndesign G\\\"odel machine. Such a machine could solve a variety of design problems\nby generating novel concepts. In addition, it could change the way these\nconcepts are generated by modifying itself. The design G\\\"odel machine is able\nto improve its initial design program, once it has proven that a modification\nwould increase its return on the utility function. Finally, we sketch out a\nspecific version of the design G\\\"odel machine which specifically addresses the\ndesign of complex software and hardware systems. Future work aims at the\ndevelopment of a more formal version of the design G\\\"odel machine and a proof\nof concept implementation.", "authors": ["Andreas Makoto Hein", "H\u00e9l\u00e8ne Condat"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.02091v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.02091v4", "num_discussion": 0, "originally_published_time": "6/6/2018", "pid": "1806.02091v4", "published_time": "6/26/2018", "rawpid": "1806.02091", "tags": ["cs.AI"], "title": "Can Machines Design? An Artificial General Intelligence Approach"}, {"abstract": "A non-vector-based dissimilarity measure is proposed by combining\nvector-based distance metrics and set operations. This proposed compound\ndissimilarity measure (CDM) is applicable to quantify similarity of collections\nof attribute/feature pairs where not all attributes are present in all\ncollections. This is a typical challenge in the context of e.g.,\nfingerprinting-based positioning (FbP). Compared to vector-based distance\nmetrics (e.g., Minkowski), the merits of the proposed CDM are i) the data do\nnot need to be converted to vectors of equal dimension, ii) shared and unshared\nattributes can be weighted differently within the assessment, and iii)\nadditional degrees of freedom within the measure allow to adapt its properties\nto application needs in a data-driven way. We indicate the validity of the\nproposed CDM by demonstrating the improvements of the positioning performance\nof fingerprinting-based WLAN indoor positioning using four different datasets,\nthree of them publicly available. When processing these datasets using CDM\ninstead of conventional distance metrics the accuracy of identifying buildings\nand floors improves by about 5% on average. The 2d positioning errors in terms\nof root mean squared error (RMSE) are reduced by a factor of two, and the\npercentage of position solutions with less than 2m error improves by over 10%.", "authors": ["Caifa Zhou", "Andreas Wieser"], "category": "stat.AP", "comment": "7 pages, 5 figures, 3 tables, a paper accepted to be published IPIN\n  2018, Nantes France", "img": "/static/thumbs/1805.06208v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.06208v2", "num_discussion": 0, "originally_published_time": "5/16/2018", "pid": "1805.06208v2", "published_time": "6/26/2018", "rawpid": "1805.06208", "tags": ["stat.AP", "stat.ML"], "title": "CDM: Compound dissimilarity measure and an application to\n  fingerprinting-based positioning"}, {"abstract": "Repeating spatiotemporal spike patterns exist and carry information. Here we\ninvestigate how a single neuron can optimally signal the presence of one given\npattern (localist coding), or of either one of several patterns (distributed\ncoding, i.e. the neuron\u0027s response is ambiguous but the identity of the pattern\ncould be inferred from the response of multiple neurons). Intuitively, we\nshould connect the detector neuron to the neurons that fire during (subsections\nof) the patterns. Using a threshold-free leaky integrate-and-fire (LIF) neuron\nwith time constant $\\tau$, non-plastic unitary synapses and homogeneous Poisson\ninputs, we derived analytically the signal-to-noise ratio (SNR) of the\nresulting pattern detector, even in the presence of jitter. In most cases, this\nSNR turned out to be optimal for relatively short $\\tau$ (at most a few tens of\nms). Thus long patterns are optimally detected by coincidence detectors working\nat a shorter timescale, although these ignore most of the patterns.\nSurprisingly, when increasing the number of patterns, the SNR decreases slowly,\nand remains acceptable for tens of independent patterns.\n  Next, we wondered if spike-timing-dependent plasticity (STDP) could enable a\nneuron to reach the theoretical optimum. We simulated a LIF equipped with STDP,\nand repeatedly exposed it to multiple input spike patterns. The LIF\nprogressively became selective to every repeating pattern with no supervision,\neven when the patterns were embedded in Poisson activity. Furthermore, using\ncertain STDP parameters, the resulting pattern detectors were optimal. Tens of\nindependent patterns could be learned by a single neuron with a low adaptive\nthreshold, in contrast with previous studies, in which higher thresholds led to\nlocalist coding only.\n  Taken together these results suggest that coincidence detection and STDP are\npowerful mechanisms, compatible with distributed coding.", "authors": ["Timoth\u00e9e Masquelier", "Saeed Reza Kheradpisheh"], "category": "cs.NE", "comment": "15 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1610.07355", "img": "/static/thumbs/1803.00447v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.00447v2", "num_discussion": 0, "originally_published_time": "3/1/2018", "pid": "1803.00447v2", "published_time": "6/26/2018", "rawpid": "1803.00447", "tags": ["cs.NE"], "title": "Optimal localist and distributed coding of spatiotemporal spike patterns\n  through STDP and coincidence detection"}, {"abstract": "Many NLP applications can be framed as a graph-to-sequence learning problem.\nPrevious work proposing neural architectures on this setting obtained promising\nresults compared to grammar-based approaches but still rely on linearisation\nheuristics and/or standard recurrent networks to achieve the best performance.\nIn this work, we propose a new model that encodes the full structural\ninformation contained in the graph. Our architecture couples the recently\nproposed Gated Graph Neural Networks with an input transformation that allows\nnodes and edges to have their own hidden representations, while tackling the\nparameter explosion problem present in previous work. Experimental results show\nthat our model outperforms strong baselines in generation from AMR graphs and\nsyntax-based neural machine translation.", "authors": ["Daniel Beck", "Gholamreza Haffari", "Trevor Cohn"], "category": "cs.CL", "comment": "ACL 2018", "img": "/static/thumbs/1806.09835v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09835v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09835v1", "published_time": "6/26/2018", "rawpid": "1806.09835", "tags": ["cs.CL", "cs.LG"], "title": "Graph-to-Sequence Learning using Gated Graph Neural Networks"}, {"abstract": "We present a novel optimization strategy for training neural networks which\nwe call \"BitNet\". The parameters of neural networks are usually unconstrained\nand have a dynamic range dispersed over all real values. Our key idea is to\nlimit the expressive power of the network by dynamically controlling the range\nand set of values that the parameters can take. We formulate this idea using a\nnovel end-to-end approach that circumvents the discrete parameter space by\noptimizing a relaxed continuous and differentiable upper bound of the typical\nclassification loss function. The approach can be interpreted as a\nregularization inspired by the Minimum Description Length (MDL) principle. For\neach layer of the network, our approach optimizes real-valued translation and\nscaling factors and arbitrary precision integer-valued parameters (weights). We\nempirically compare BitNet to an equivalent unregularized model on the MNIST\nand CIFAR-10 datasets. We show that BitNet converges faster to a superior\nquality solution. Additionally, the resulting model has significant savings in\nmemory due to the use of integer-valued parameters.", "authors": ["Aswin Raghavan", "Mohamed Amer", "Sek Chai", "Graham Taylor"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1708.04788v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1708.04788v2", "num_discussion": 0, "originally_published_time": "8/16/2017", "pid": "1708.04788v2", "published_time": "6/26/2018", "rawpid": "1708.04788", "tags": ["cs.LG", "stat.ML"], "title": "BitNet: Bit-Regularized Deep Neural Networks"}, {"abstract": "The aim of this paper is to provide some theoretical understanding of\nquasi-Bayesian aggregation methods non-negative matrix factorization. We derive\nan oracle inequality for an aggregated estimator. This result holds for a very\ngeneral class of prior distributions and shows how the prior affects the rate\nof convergence.", "authors": ["Pierre Alquier", "Benjamin Guedj"], "category": "stat.ML", "comment": "This is the corrected version of the published paper P. Alquier, B.\n  Guedj, An Oracle Inequality fo...", "img": "/static/thumbs/1601.01345v4.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1601.01345v4", "num_discussion": 0, "originally_published_time": "1/6/2016", "pid": "1601.01345v4", "published_time": "6/26/2018", "rawpid": "1601.01345", "tags": ["stat.ML", "math.ST", "stat.TH"], "title": "An Oracle Inequality for Quasi-Bayesian Non-Negative Matrix\n  Factorization"}, {"abstract": "Pooling is an essential component of a wide variety of sentence\nrepresentation and embedding models. This paper explores generalized pooling\nmethods to enhance sentence embedding. We propose vector-based multi-head\nattention that includes the widely used max pooling, mean pooling, and scalar\nself-attention as special cases. The model benefits from properly designed\npenalization terms to reduce redundancy in multi-head attention. We evaluate\nthe proposed model on three different tasks: natural language inference (NLI),\nauthor profiling, and sentiment classification. The experiments show that the\nproposed model achieves significant improvement over strong\nsentence-encoding-based methods, resulting in state-of-the-art performances on\nfour datasets. The proposed approach can be easily implemented for more\nproblems than we discuss in this paper.", "authors": ["Qian Chen", "Zhen-Hua Ling", "Xiaodan Zhu"], "category": "cs.CL", "comment": "Accepted by COLING 2018", "img": "/static/thumbs/1806.09828v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09828v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09828v1", "published_time": "6/26/2018", "rawpid": "1806.09828", "tags": ["cs.CL"], "title": "Enhancing Sentence Embedding with Generalized Pooling"}, {"abstract": "Classic Topic Models are built under the Bag Of Words assumption, in which\nword position is ignored for simplicity. Besides, symmetric priors are\ntypically used in most applications. In order to easily learn topics with\ndifferent properties among the same corpus, we propose a new line of work in\nwhich the paragraph structure is exploited. Our proposal is based on the\nfollowing assumption: in many text document corpora there are formal\nconstraints shared across all the collection, e.g. sections. When this\nassumption is satisfied, some paragraphs may be related to general concepts\nshared by all documents in the corpus, while others would contain the genuine\ndescription of documents. Assuming each paragraph can be semantically more\ngeneral, specific, or hybrid, we look for ways to measure this, transferring\nthis distinction to topics and being able to learn what we call specific and\ngeneral topics. Experiments show that this is a proper methodology to highlight\ncertain paragraphs in structured documents at the same time we learn\ninteresting and more diverse topics.", "authors": ["Sim\u00f3n Roca-Sotelo", "Jer\u00f3nimo Arenas-Garc\u00eda"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1806.09827v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09827v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09827v1", "published_time": "6/26/2018", "rawpid": "1806.09827", "tags": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "title": "Unveiling the semantic structure of text documents using paragraph-aware\n  Topic Models"}, {"abstract": "The nearest neighbor problem is defined as follows: Given a set $P$ of $n$\npoints in some metric space $(X,D)$, build a data structure that, given any\npoint $q$, returns a point in $P$ that is closest to $q$ (its \"nearest\nneighbor\" in $P$). The data structure stores additional information about the\nset $P$, which is then used to find the nearest neighbor without computing all\ndistances between $q$ and $P$. The problem has a wide range of applications in\nmachine learning, computer vision, databases and other fields.\n  To reduce the time needed to find nearest neighbors and the amount of memory\nused by the data structure, one can formulate the {\\em approximate} nearest\nneighbor problem, where the the goal is to return any point $p\u0027 \\in P$ such\nthat the distance from $q$ to $p\u0027$ is at most $c \\cdot \\min_{p \\in P} D(q,p)$,\nfor some $c \\geq 1$. Over the last two decades, many efficient solutions to\nthis problem were developed. In this article we survey these developments, as\nwell as their connections to questions in geometric functional analysis and\ncombinatorial geometry.", "authors": ["Alexandr Andoni", "Piotr Indyk", "Ilya Razenshteyn"], "category": "cs.DS", "comment": "27 pages, no figures; to appear in the proceedings of ICM 2018\n  (accompanying the talk by P. Indyk)", "img": "/static/thumbs/1806.09823v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09823v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09823v1", "published_time": "6/26/2018", "rawpid": "1806.09823", "tags": ["cs.DS", "cs.CG", "cs.DB", "stat.ML"], "title": "Approximate Nearest Neighbor Search in High Dimensions"}, {"abstract": "This paper demonstrates dynamic hyper-parameter setting, for deep neural\nnetwork training, using Mutual Information (MI). The specific hyper-parameter\nstudied in this paper is the learning rate. MI between the output layer and\ntrue outcomes is used to dynamically set the learning rate of the network\nthrough the training cycle; the idea is also extended to layer-wise setting of\nlearning rate. Two approaches are demonstrated - tracking relative change in\nmutual information and, additionally tracking its value relative to a reference\nmeasure. The paper does not attempt to recommend a specific learning rate\npolicy. Experiments demonstrate that mutual information may be effectively used\nto dynamically set learning rate and achieve competitive to better outcomes in\ncompetitive to better time.", "authors": ["Shrihari Vasudevan"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1805.07249v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1805.07249v2", "num_discussion": 0, "originally_published_time": "5/18/2018", "pid": "1805.07249v2", "published_time": "6/26/2018", "rawpid": "1805.07249", "tags": ["cs.LG", "cs.AI", "cs.NE", "stat.ML"], "title": "Dynamic learning rate using Mutual Information"}, {"abstract": "Although the word-popularity based negative sampler has shown superb\nperformance in the skip-gram model, the theoretical motivation behind\noversampling popular (non-observed) words as negative samples is still not well\nunderstood. In this paper, we start from an investigation of the gradient\nvanishing issue in the skipgram model without a proper negative sampler. By\nperforming an insightful analysis from the stochastic gradient descent (SGD)\nlearning perspective, we demonstrate that, both theoretically and intuitively,\nnegative samples with larger inner product scores are more informative than\nthose with lower scores for the SGD learner in terms of both convergence rate\nand accuracy. Understanding this, we propose an alternative sampling algorithm\nthat dynamically selects informative negative samples during each SGD update.\nMore importantly, the proposed sampler accounts for multi-dimensional\nself-embedded features during the sampling process, which essentially makes it\nmore effective than the original popularity-based (one-dimensional) sampler.\nEmpirical experiments further verify our observations, and show that our\nfine-grained samplers gain significant improvement over the existing ones\nwithout increasing computational complexity.", "authors": ["Long Chen", "Fajie Yuan", "Joemon M. Jose", "Weinan Zhang"], "category": "cs.LG", "comment": "Accepted in WSDM 2018", "img": "/static/thumbs/1710.09805v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1710.09805v3", "num_discussion": 0, "originally_published_time": "10/26/2017", "pid": "1710.09805v3", "published_time": "6/26/2018", "rawpid": "1710.09805", "tags": ["cs.LG", "cs.CL", "stat.ML"], "title": "Improving Negative Sampling for Word Representation using Self-embedded\n  Features"}, {"abstract": "Visually-aware recommender systems use visual signals present in the\nunderlying data to model the visual characteristics of items and users\u0027\npreferences towards them. In the domain of clothing recommendation,\nincorporating items\u0027 visual information (e.g., product images) is particularly\nimportant since clothing item appearance is often a critical factor in\ninfluencing the user\u0027s purchasing decisions. Current state-of-the-art\nvisually-aware recommender systems utilize image features extracted from\npre-trained deep convolutional neural networks, however these extremely\nhigh-dimensional representations are difficult to interpret, especially in\nrelation to the relatively low number of visual properties that may guide\nusers\u0027 decisions.\n  In this paper we propose a novel approach to personalized clothing\nrecommendation that models the dynamics of individual users\u0027 visual\npreferences. By using interpretable image representations generated with a\nunique feature learning process, our model learns to explain users\u0027 prior\nfeedback in terms of their affinity towards specific visual attributes and\nstyles. Our approach achieves state-of-the-art performance on personalized\nranking tasks, and the incorporation of interpretable visual features allows\nfor powerful model introspection, which we demonstrate by using an interactive\nrecommendation algorithm and visualizing the rise and fall of fashion trends\nover time.", "authors": ["Charles Packer", "Julian McAuley", "Arnau Ramisa"], "category": "cs.CV", "comment": "AI for Fashion workshop, held in conjunction with KDD 2018, London. 4\n  pages", "img": "/static/thumbs/1806.09820v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09820v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09820v1", "published_time": "6/26/2018", "rawpid": "1806.09820", "tags": ["cs.CV"], "title": "Visually-Aware Personalized Recommendation using Interpretable Image\n  Representations"}, {"abstract": "Stochastic gradient descent is the most prevalent algorithm to train neural\nnetworks. However, other approaches such as evolutionary algorithms are also\napplicable to this task. Evolutionary algorithms bring unique trade-offs that\nare worth exploring, but computational demands have so far restricted\nexploration to small networks with few parameters. We implement an evolutionary\nalgorithm that executes entirely on the GPU, which allows to efficiently\nbatch-evaluate a whole population of networks. Within this framework, we\nexplore the limited evaluation evolutionary algorithm for neural network\ntraining and find that its batch evaluation idea comes with a large accuracy\ntrade-off. In further experiments, we explore crossover operators and find that\nunprincipled random uniform crossover performs extremely well. Finally, we\ntrain a network with 92k parameters on MNIST using an EA and achieve 97.6 %\ntest accuracy compared to 98 % test accuracy on the same network trained with\nAdam. Code is available at https://github.com/jprellberg/gpuea.", "authors": ["Jonas Prellberg", "Oliver Kramer"], "category": "cs.NE", "comment": "Accepted at KI 2018", "img": "/static/thumbs/1806.09819v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09819v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09819v1", "published_time": "6/26/2018", "rawpid": "1806.09819", "tags": ["cs.NE"], "title": "Limited Evaluation Evolutionary Optimization of Large Neural Networks"}, {"abstract": "Single individual haplotyping is an NP-hard problem that emerges when\nattempting to reconstruct an organism\u0027s inherited genetic variations using data\ntypically generated by high-throughput DNA sequencing platforms. Genomes of\ndiploid organisms, including humans, are organized into homologous pairs of\nchromosomes that differ from each other in a relatively small number of variant\npositions. Haplotypes are ordered sequences of the nucleotides in the variant\npositions of the chromosomes in a homologous pair; for diploids, haplotypes\nassociated with a pair of chromosomes may be conveniently represented by means\nof complementary binary sequences. In this paper, we consider a binary matrix\nfactorization formulation of the single individual haplotyping problem and\nefficiently solve it by means of alternating minimization. We analyze the\nconvergence properties of the alternating minimization algorithm and establish\ntheoretical bounds for the achievable haplotype reconstruction error. The\nproposed technique is shown to outperform existing methods when applied to\nsynthetic as well as real-world Fosmid-based HapMap NA12878 datasets.", "authors": ["Somsubhra Barik", "Haris Vikalo"], "category": "cs.LG", "comment": "28 pages, 3 pages, 3 Tables", "img": "/static/thumbs/1806.08647v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.08647v2", "num_discussion": 0, "originally_published_time": "6/13/2018", "pid": "1806.08647v2", "published_time": "6/26/2018", "rawpid": "1806.08647", "tags": ["cs.LG", "cs.IT", "math.IT", "q-bio.QM", "stat.ML"], "title": "Matrix Completion and Performance Guarantees for Single Individual\n  Haplotyping"}, {"abstract": "Natural language explanations of deep neural network decisions provide an\nintuitive way for a AI agent to articulate a reasoning process. Current textual\nexplanations learn to discuss class discriminative features in an image.\nHowever, it is also helpful to understand which attributes might change a\nclassification decision if present in an image (e.g., \"This is not a Scarlet\nTanager because it does not have black wings.\") We call such textual\nexplanations counterfactual explanations, and propose an intuitive method to\ngenerate counterfactual explanations by inspecting which evidence in an input\nis missing, but might contribute to a different classification decision if\npresent in the image. To demonstrate our method we consider a fine-grained\nimage classification task in which we take as input an image and a\ncounterfactual class and output text which explains why the image does not\nbelong to a counterfactual class. We then analyze our generated counterfactual\nexplanations both qualitatively and quantitatively using proposed automatic\nmetrics.", "authors": ["Lisa Anne Hendricks", "Ronghang Hu", "Trevor Darrell", "Zeynep Akata"], "category": "cs.CV", "comment": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockhol...", "img": "/static/thumbs/1806.09809v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09809v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09809v1", "published_time": "6/26/2018", "rawpid": "1806.09809", "tags": ["cs.CV"], "title": "Generating Counterfactual Explanations with Natural Language"}, {"abstract": "As an unsupervised dimensionality reduction method, principal component\nanalysis (PCA) has been widely considered as an efficient and effective\npreprocessing step for hyperspectral image (HSI) processing and analysis tasks.\nIt takes each band as a whole and globally extracts the most representative\nbands. However, different homogeneous regions correspond to different objects,\nwhose spectral features are diverse. It is obviously inappropriate to carry out\ndimensionality reduction through a unified projection for an entire HSI. In\nthis paper, a simple but very effective superpixelwise PCA approach, called\nSuperPCA, is proposed to learn the intrinsic low-dimensional features of HSIs.\nIn contrast to classical PCA models, SuperPCA has four main properties. (1)\nUnlike the traditional PCA method based on a whole image, SuperPCA takes into\naccount the diversity in different homogeneous regions, that is, different\nregions should have different projections. (2) Most of the conventional feature\nextraction models cannot directly use the spatial information of HSIs, while\nSuperPCA is able to incorporate the spatial context information into the\nunsupervised dimensionality reduction by superpixel segmentation. (3) Since the\nregions obtained by superpixel segmentation have homogeneity, SuperPCA can\nextract potential low-dimensional features even under noise. (4) Although\nSuperPCA is an unsupervised method, it can achieve competitive performance when\ncompared with supervised approaches. The resulting features are discriminative,\ncompact, and noise resistant, leading to improved HSI classification\nperformance. Experiments on three public datasets demonstrate that the SuperPCA\nmodel significantly outperforms the conventional PCA based dimensionality\nreduction baselines for HSI classification. The Matlab source code is available\nat https://github.com/junjun-jiang/SuperPCA.", "authors": ["Junjun Jiang", "Jiayi Ma", "Chen Chen", "Zhongyuan Wang", "Zhihua Cai", "Lizhe Wang"], "category": "cs.CV", "comment": "Accepted by IEEE TGRS", "img": "/static/thumbs/1806.09807v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09807v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09807v1", "published_time": "6/26/2018", "rawpid": "1806.09807", "tags": ["cs.CV"], "title": "SuperPCA: A Superpixelwise PCA Approach for Unsupervised Feature\n  Extraction of Hyperspectral Imagery"}, {"abstract": "The emerging technique of deep learning has been widely applied in many\ndifferent areas. However, when adopted in a certain specific domain, this\ntechnique should be combined with domain knowledge to improve efficiency and\naccuracy. In particular, when analyzing the applications of deep learning in\nsentiment analysis, we found that the current approaches are suffering from the\nfollowing drawbacks: (i) the existing works have not paid much attention to the\nimportance of different types of sentiment terms, which is an important concept\nin this area; and (ii) the loss function currently employed does not well\nreflect the degree of error of sentiment misclassification. To overcome such\nproblem, we propose to combine domain knowledge with deep learning. Our\nproposal includes using sentiment scores, learnt by regression, to augment\ntraining data; and introducing penalty matrix for enhancing the loss function\nof cross entropy. When experimented, we achieved a significant improvement in\nclassification results.", "authors": ["Khuong Vo", "Dang Pham", "Mao Nguyen", "Trung Mai", "Tho Quan"], "category": "cs.CL", "comment": "Accepted to MIWAI 2017", "img": "/static/thumbs/1806.08760v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.08760v2", "num_discussion": 0, "originally_published_time": "6/22/2018", "pid": "1806.08760v2", "published_time": "6/26/2018", "rawpid": "1806.08760", "tags": ["cs.CL", "cs.LG", "cs.NE"], "title": "Combination of Domain Knowledge and Deep Learning for Sentiment Analysis"}, {"abstract": "This paper addresses the problem of multi-agent inverse reinforcement\nlearning (MIRL) in a two-player general-sum stochastic game framework. Five\nvariants of MIRL are considered: uCS-MIRL, advE-MIRL, cooE-MIRL, uCE-MIRL, and\nuNE-MIRL, each distinguished by its solution concept. Problem uCS-MIRL is a\ncooperative game in which the agents employ cooperative strategies that aim to\nmaximize the total game value. In problem uCE-MIRL, agents are assumed to\nfollow strategies that constitute a correlated equilibrium while maximizing\ntotal game value. Problem uNE-MIRL is similar to uCE-MIRL in total game value\nmaximization, but it is assumed that the agents are playing a Nash equilibrium.\nProblems advE-MIRL and cooE-MIRL assume agents are playing an adversarial\nequilibrium and a coordination equilibrium, respectively. We propose novel\napproaches to address these five problems under the assumption that the game\nobserver either knows or is able to accurate estimate the policies and solution\nconcepts for players. For uCS-MIRL, we first develop a characteristic set of\nsolutions ensuring that the observed bi-policy is a uCS and then apply a\nBayesian inverse learning method. For uCE-MIRL, we develop a linear programming\nproblem subject to constraints that define necessary and sufficient conditions\nfor the observed policies to be correlated equilibria. The objective is to\nchoose a solution that not only minimizes the total game value difference\nbetween the observed bi-policy and a local uCS, but also maximizes the scale of\nthe solution. We apply a similar treatment to the problem of uNE-MIRL. The\nremaining two problems can be solved efficiently by taking advantage of\nsolution uniqueness and setting up a convex optimization problem. Results are\nvalidated on various benchmark grid-world games.", "authors": ["Xiaomin Lin", "Stephen C. Adams", "Peter A. Beling"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09795v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09795v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09795v1", "published_time": "6/26/2018", "rawpid": "1806.09795", "tags": ["cs.LG", "cs.GT", "stat.ML"], "title": "Multi-agent Inverse Reinforcement Learning for General-sum Stochastic\n  Games"}, {"abstract": "With the considerable development of customer-to-customer (C2C) e-commerce in\nthe recent years, there is a big demand for an effective recommendation system\nthat suggests suitable websites for users to sell their items with some\nspecified needs. Nonetheless, e-commerce recommendation systems are mostly\ndesigned for business-to-customer (B2C) websites, where the systems offer the\nconsumers the products that they might like to buy. Almost none of the related\nresearch works focus on choosing selling sites for target items. In this paper,\nwe introduce an approach that recommends the selling websites based upon the\nitem\u0027s description, category, and desired selling price. This approach employs\nNoSQL data-based machine learning techniques for building and training topic\nmodels and classification models. The trained models can then be used to rank\nthe websites dynamically with respect to the user needs. The experimental\nresults with real-world datasets from Vietnam C2C websites will demonstrate the\neffectiveness of our proposed method.", "authors": ["Khanh Dang", "Khuong Vo", "Josef K\u00fcng"], "category": "cs.IR", "comment": "Accepted to DEXA 2017", "img": "/static/thumbs/1806.09793v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09793v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09793v1", "published_time": "6/26/2018", "rawpid": "1806.09793", "tags": ["cs.IR", "cs.DB", "cs.LG"], "title": "A NoSQL Data-based Personalized Recommendation System for C2C e-Commerce"}, {"abstract": "Recent studies in sequence-to-sequence learning demonstrate that RNN\nencoder-decoder structure can successfully generate Chinese poetry. However,\nexisting methods can only generate poetry with a given first line or user\u0027s\nintent theme. In this paper, we proposed a three-stage multi-modal Chinese\npoetry generation approach. Given a picture, the first line, the title and the\nother lines of the poem are successively generated in three stages. According\nto the characteristics of Chinese poems, we propose a hierarchy-attention\nseq2seq model which can effectively capture character, phrase, and sentence\ninformation between contexts and improve the symmetry delivered in poems. In\naddition, the Latent Dirichlet allocation (LDA) model is utilized for title\ngeneration and improve the relevance of the whole poem and the title. Compared\nwith strong baseline, the experimental results demonstrate the effectiveness of\nour approach, using machine evaluations as well as human judgments.", "authors": ["Dayiheng Liu", "Quan Guo", "Wubo Li", "Jiancheng Lv"], "category": "cs.CL", "comment": "Accepted at the International Joint Conference on Neural Networks,\n  IJCNN, 2018", "img": "/static/thumbs/1806.09792v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09792v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09792v1", "published_time": "6/26/2018", "rawpid": "1806.09792", "tags": ["cs.CL"], "title": "A Multi-Modal Chinese Poetry Generation Model"}, {"abstract": "The interpretation of defect models heavily relies on software metrics that\nare used to construct them. However, such software metrics are often correlated\nto defect models. Prior work often uses feature selection techniques to remove\ncorrelated metrics in order to improve the performance of defect models. Yet,\nthe interpretation of defect models may be misleading if feature selection\ntechniques produce subsets of inconsistent and correlated metrics. In this\npaper, we investigate the consistency and correlation of the subsets of metrics\nthat are produced by nine commonly-used feature selection techniques. Through a\ncase study of 13 publicly-available defect datasets, we find that feature\nselection techniques produce inconsistent subsets of metrics and do not\nmitigate correlated metrics, suggesting that feature selection techniques\nshould not be used and correlation analyses must be applied when the goal is\nmodel interpretation. Since correlation analyses often involve manual selection\nof metrics by a domain expert, we introduce AutoSpearman, an automated metric\nselection approach based on correlation analyses. Our evaluation indicates that\nAutoSpearman yields the highest consistency of subsets of metrics among\ntraining samples and mitigates correlated metrics, while impacting model\nperformance by 1-2%pts. Thus, to automatically mitigate correlated metrics when\ninterpreting defect models, we recommend future studies use AutoSpearman in\nlieu of commonly-used feature selection techniques.", "authors": ["Jirayus Jiarpakdee", "Chakkrit Tantithamthavorn", "Christoph Treude"], "category": "cs.SE", "comment": "Accepted for publication at the International Conference on Software\n  Maintenance and Evolution (IC...", "img": "/static/thumbs/1806.09791v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09791v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09791v1", "published_time": "6/26/2018", "rawpid": "1806.09791", "tags": ["cs.SE", "cs.LG"], "title": "AutoSpearman: Automatically Mitigating Correlated Metrics for\n  Interpreting Defect Models"}, {"abstract": "The ability to detect small objects and the speed of the object detector are\nvery important for the application of autonomous driving, and in this paper, we\npropose an effective yet efficient one-stage detector, which gained the second\nplace in the Road Object Detection competition of CVPR2018 workshop - Workshop\nof Autonomous Driving(WAD). The proposed detector inherits the architecture of\nSSD and introduces a novel Comprehensive Feature Enhancement(CFE) module into\nit. Experimental results on this competition dataset as well as the MSCOCO\ndataset demonstrate that the proposed detector (named CFENet) performs much\nbetter than the original SSD and the state-of-the-art method RefineDet\nespecially for small objects, while keeping high efficiency close to the\noriginal SSD. Specifically, the single scale version of the proposed detector\ncan run at the speed of 21 fps, while the multi-scale version with larger input\nsize achieves the mAP 29.69, ranking second on the leaderboard", "authors": ["Qijie Zhao", "Tao Sheng", "Yongtao Wang", "Feng Ni", "Ling Cai"], "category": "cs.CV", "comment": "5 pages, 4 figures, CVPR2018, Workshop of Autonomous Driving (WAD)", "img": "/static/thumbs/1806.09790v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09790v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09790v1", "published_time": "6/26/2018", "rawpid": "1806.09790", "tags": ["cs.CV"], "title": "CFENet: An Accurate and Efficient Single-Shot Object Detector for\n  Autonomous Driving"}, {"abstract": "Traditional Evolutionary Robotics (ER) employs evolutionary techniques to\nsearch for a single monolithic controller which can aid a robot to learn a\ndesired task. These techniques suffer from bootstrap and deception issues when\nthe tasks are complex for a single controller to learn. Behaviour-decomposition\ntechniques have been used to divide a task into multiple subtasks and evolve\nseparate subcontrollers for each subtask. However, these subcontrollers and the\nassociated subcontroller arbitrator(s) are all evolved off-line. A distributed,\nfully embodied and evolutionary version of such approaches will greatly aid\nonline learning and help reduce the reality gap. In this paper, we propose an\nimmunology-inspired embodied action-evolution cum selection algorithm that can\ncater to distributed ER. This algorithm evolves different subcontrollers for\ndifferent portions of the search space in a distributed manner just as\nantibodies are evolved and primed for different antigens in the antigenic\nspace. Experimentation on a collective of real robots embodied with the\nalgorithm showed that a repertoire of antibody-like subcontrollers was created,\nevolved and shared on-the-fly to cope up with different environmental\nconditions. In addition, instead of the conventionally used approach of\nbroadcasting for sharing, we present an Intelligent Packet Migration scheme\nthat reduces energy consumption.", "authors": ["Tushar Semwal", "Divya D Kulkarni", "Shivashankar B. Nair"], "category": "cs.NE", "comment": "8 pages, 5 figures, GECCO 18, Kyoto, Japan", "img": "/static/thumbs/1806.09789v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09789v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09789v1", "published_time": "6/26/2018", "rawpid": "1806.09789", "tags": ["cs.NE"], "title": "On an Immuno-inspired Distributed, Embodied Action-Evolution cum\n  Selection Algorithm"}, {"abstract": "Pathogenic social media accounts such as terrorist supporters exploit\ncommunities of supporters for conducting attacks on social media. Early\ndetection of PSM accounts is crucial as they are likely to be key users in\nmaking a harmful message \"viral\". This paper overviews my recent doctoral work\non utilizing causal inference to identify PSM accounts within a short time\nframe around their activity. The proposed scheme (1) assigns time-decay\ncausality scores to users, (2) applies a community detection-based algorithm to\ngroup of users sharing similar causality scores and finally (3) deploys a\nclassification algorithm to classify accounts. Unlike existing techniques that\nrequire network structure, cascade path, or content, our scheme relies solely\non action log of users.", "authors": ["Hamidreza Alvari"], "category": "cs.SI", "comment": "Doctoral Consortium - 2018 International Conference on Social\n  Computing, Behavioral-Cultural Model...", "img": "/static/thumbs/1806.09787v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09787v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09787v1", "published_time": "6/26/2018", "rawpid": "1806.09787", "tags": ["cs.SI", "cs.AI"], "title": "Causal Inference for Early Detection of Pathogenic Social Media Accounts"}, {"abstract": "We propose a simplification of the Theory-of-Mind Network architecture, which\nfocuses on modeling complex, deterministic machines as a proxy for modeling\nnondeterministic, conscious entities. We then validate this architecture in the\ncontext of understanding engines, which, we argue, meet the required internal\nand external complexity to yield meaningful abstractions.", "authors": ["Rooz Mahdavian", "Richard Diehl Martinez"], "category": "cs.AI", "comment": "", "img": "/static/thumbs/1806.09785v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09785v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09785v1", "published_time": "6/26/2018", "rawpid": "1806.09785", "tags": ["cs.AI"], "title": "Theory of Machine Networks: A Case Study"}, {"abstract": "Symmetric nonnegative matrix factorization has found abundant applications in\nvarious domains by providing a symmetric low-rank decomposition of nonnegative\nmatrices. In this paper we propose a Frank-Wolfe (FW) solver to optimize the\nsymmetric nonnegative matrix factorization problem under a simplicial\nconstraint, which has recently been proposed for probabilistic clustering.\nCompared with existing solutions, this algorithm is simple to implement, and\nhas no hyperparameters to be tuned. Building on the recent advances of FW\nalgorithms in nonconvex optimization, we prove an $O(1/\\varepsilon^2)$\nconvergence rate to $\\varepsilon$-approximate KKT points, via a tight bound\n$\\Theta(n^2)$ on the curvature constant, which matches the best known result in\nunconstrained nonconvex setting using gradient methods. Numerical results\ndemonstrate the effectiveness of our algorithm. As a side contribution, we\nconstruct a simple nonsmooth convex problem where the FW algorithm fails to\nconverge to the optimum. This result raises an interesting question about\nnecessary conditions of the success of the FW algorithm on convex problems.", "authors": ["Han Zhao", "Geoff Gordon"], "category": "cs.LG", "comment": "In Proceedings of the Thirty-Fourth Conference on Uncertainty in\n  Artificial Intelligence, 2018", "img": "/static/thumbs/1706.06348v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.06348v3", "num_discussion": 0, "originally_published_time": "6/20/2017", "pid": "1706.06348v3", "published_time": "6/26/2018", "rawpid": "1706.06348", "tags": ["cs.LG", "math.OC", "stat.ML"], "title": "Frank-Wolfe Optimization for Symmetric-NMF under Simplicial Constraint"}, {"abstract": "Dropout has been one of standard approaches to train deep neural networks,\nand it is known to regularize large models to avoid overfitting. The effect of\ndropout has been explained by avoiding co-adaptation. In this paper, however,\nwe propose a new explanation of why dropout works and propose a new technique\nto design better activation functions. First, we show that dropout is an\noptimization technique to push the input towards the saturation area of\nnonlinear activation function by accelerating gradient information flowing even\nin the saturation area in backpropagation. Based on this explanation, we\npropose a new technique for activation functions, gradient acceleration in\nactivation function (GAAF), that accelerates gradients to flow even in the\nsaturation area. Then, input to the activation function can climb onto the\nsaturation area which makes the network more robust because the model converges\non a flat region. Experiment results support our explanation of dropout and\nconfirm that the proposed GAAF technique improves performances with expected\nproperties.", "authors": ["Sangchul Hahn", "Heeyoul Choi"], "category": "cs.LG", "comment": "10 pages", "img": "/static/thumbs/1806.09783v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09783v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09783v1", "published_time": "6/26/2018", "rawpid": "1806.09783", "tags": ["cs.LG", "stat.ML"], "title": "Gradient Acceleration in Activation Functions"}, {"abstract": "Pseudo-marginal Metropolis-Hastings (pmMH) is a versatile algorithm for\nsampling from target distributions which are not easy to evaluate point-wise.\nHowever, pmMH requires good proposal distributions to sample efficiently from\nthe target, which can be problematic to construct in practice. This is\nespecially a problem for high-dimensional targets when the standard random-walk\nproposal is inefficient.\n  We extend pmMH to allow for constructing the proposal based on information\nfrom multiple past iterations. As a consequence, quasi-Newton (qN) methods can\nbe employed to form proposals which utilize gradient information to guide the\nMarkov chain to areas of high probability and to construct approximations of\nthe local curvature to scale step sizes. The proposed method is demonstrated on\nseveral problems which indicate that qN proposals can perform better than other\ncommon Hessian-based proposals.", "authors": ["Johan Dahlin", "Adrian Wills", "Brett Ninness"], "category": "stat.CO", "comment": "41 pages and 11 figures. Submitted to journal", "img": "/static/thumbs/1806.09780v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09780v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09780v1", "published_time": "6/26/2018", "rawpid": "1806.09780", "tags": ["stat.CO", "stat.ML"], "title": "Correlated pseudo-marginal Metropolis-Hastings using quasi-Newton\n  proposals"}, {"abstract": "Algorithmic approaches endow deep learning systems with implicit bias that\nhelps them generalize even in over-parametrized settings. In this paper, we\nfocus on understanding such a bias induced in learning through dropout, a\npopular technique to avoid overfitting in deep learning. For single\nhidden-layer linear neural networks, we show that dropout tends to make the\nnorm of incoming/outgoing weight vectors of all the hidden nodes equal. In\naddition, we provide a complete characterization of the optimization landscape\ninduced by dropout.", "authors": ["Poorya Mianjy", "Raman Arora", "Rene Vidal"], "category": "cs.LG", "comment": "17 pages, 3 figures, In Proceedings of the Thirty-fifth International\n  Conference on Machine Learni...", "img": "/static/thumbs/1806.09777v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09777v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09777v1", "published_time": "6/26/2018", "rawpid": "1806.09777", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "On the Implicit Bias of Dropout"}, {"abstract": "Human activity recognition aims to recognize the activities of daily living\nby utilizing the sensors on different body parts. However, when the labeled\ndata from a certain body position (i.e. target domain) is missing, how to\nleverage the data from other positions (i.e. source domain) to help learn the\nactivity labels of this position? When there are several source domains\navailable, it is often difficult to select the most similar source domain to\nthe target domain. With the selected source domain, we need to perform accurate\nknowledge transfer between domains. Existing methods only learn the global\ndistance between domains while ignoring the local property. In this paper, we\npropose a \\textit{Stratified Transfer Learning} (STL) framework to perform both\nsource domain selection and knowledge transfer. STL is based on our proposed\n\\textit{Stratified} distance to capture the local property of domains. STL\nconsists of two components: Stratified Domain Selection (STL-SDS) can select\nthe most similar source domain to the target domain; Stratified Activity\nTransfer (STL-SAT) is able to perform accurate knowledge transfer. Extensive\nexperiments on three public activity recognition datasets demonstrate the\nsuperiority of STL. Furthermore, we extensively investigate the performance of\ntransfer learning across different degrees of similarities and activity levels\nbetween domains. We also discuss the potential applications of STL in other\nfields of pervasive computing for future research.", "authors": ["Yiqiang Chen", "Jindong Wang", "Meiyu Huang", "Han Yu"], "category": "cs.CV", "comment": "An extension of our PerCom 18 paper arXiv:1801.00820; submit to PMC\n  journal (Pervasive and Mobile ...", "img": "/static/thumbs/1806.09776v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09776v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09776v1", "published_time": "6/26/2018", "rawpid": "1806.09776", "tags": ["cs.CV"], "title": "Cross-position Activity Recognition with Stratified Transfer Learning"}, {"abstract": "Deck building is a crucial component in playing Collectible Card Games\n(CCGs). The goal of deck building is to choose a fixed-sized subset of cards\nfrom a large card pool, so that they work well together in-game against\nspecific opponents. Existing methods either lack flexibility to adapt to\ndifferent opponents or require large computational resources, still making them\nunsuitable for any real-time or large-scale application. We propose a new deck\nrecommendation system, named Q-DeckRec, which learns a deck search policy\nduring a training phase and uses it to solve deck building problem instances.\nOur experimental results demonstrate Q-DeckRec requires less computational\nresources to build winning-effective decks after a training phase compared to\nseveral baseline methods.", "authors": ["Zhengxing Chen", "Chris Amato", "Truong-Huy Nguyen", "Seth Cooper", "Yizhou Sun", "Magy Seif El-Nasr"], "category": "cs.AI", "comment": "CIG 2018", "img": "/static/thumbs/1806.09771v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09771v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09771v1", "published_time": "6/26/2018", "rawpid": "1806.09771", "tags": ["cs.AI"], "title": "Q-DeckRec: A Fast Deck Recommendation System for Collectible Card Games"}, {"abstract": "Synthetic Aperture Radar (SAR) images are often contaminated by a\nmultiplicative noise known as speckle. Speckle makes the processing and\ninterpretation of SAR images difficult. We propose a deep learning-based\napproach called, Image Despeckling Convolutional Neural Network (ID-CNN), for\nautomatically removing speckle from the input noisy images. In particular,\nID-CNN uses a set of convolutional layers along with batch normalization and\nrectified linear unit (ReLU) activation function and a component-wise division\nresidual layer to estimate speckle and it is trained in an end-to-end fashion\nusing a combination of Euclidean loss and Total Variation (TV) loss. Extensive\nexperiments on synthetic and real SAR images show that the proposed method\nachieves significant improvements over the state-of-the-art speckle reduction\nmethods.", "authors": ["Puyang Wang", "He Zhang", "Vishal M. Patel"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1706.00552v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1706.00552v2", "num_discussion": 0, "originally_published_time": "6/2/2017", "pid": "1706.00552v2", "published_time": "6/26/2018", "rawpid": "1706.00552", "tags": ["cs.CV"], "title": "SAR Image Despeckling Using a Convolutional Neural Network"}, {"abstract": "In order to fully function in human environments, robot perception will need\nto account for the uncertainty caused by translucent materials. Translucency\nposes several open challenges in the form of transparent objects (e.g.,\ndrinking glasses), refractive media (e.g., water), and diffuse partial\nocclusions (e.g., objects behind stained glass panels). This paper presents\nPlenoptic Monte Carlo Localization (PMCL) as a method for localizing object\nposes in the presence of translucency using plenoptic (light-field)\nobservations. We propose a new depth descriptor, the Depth Likelihood Volume\n(DLV), and its use within a Monte Carlo object localization algorithm. We\npresent results of localizing and manipulating objects with translucent\nmaterials and objects occluded by layers of translucency. Our PMCL\nimplementation uses observations from a Lytro first generation light field\ncamera to allow a Michigan Progress Fetch robot to perform grasping.", "authors": ["Zheming Zhou", "Zhiqiang Sui", "Odest Chadwicke Jenkins"], "category": "cs.RO", "comment": "", "img": "/static/thumbs/1806.09769v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09769v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09769v1", "published_time": "6/26/2018", "rawpid": "1806.09769", "tags": ["cs.RO", "cs.AI"], "title": "Plenoptic Monte Carlo Object Localization for Robot Grasping under\n  Layered Translucency"}, {"abstract": "We propose scalable methods to execute counting queries in machine learning\napplications. To achieve memory and computational efficiency, we abstract\ncounting queries and their context such that the counts can be aggregated as a\nstream. We demonstrate performance and scalability of the resulting approach on\nrandom queries, and through extensive experimentation using Bayesian networks\nlearning and association rule mining. Our methods significantly outperform\ncommonly used ADtrees and hash tables, and are practical alternatives for\nprocessing large-scale data.", "authors": ["Subhadeep Karan", "Matthew Eichhorn", "Blake Hurlburt", "Grant Iraci", "Jaroslaw Zola"], "category": "stat.ML", "comment": "", "img": "/static/thumbs/1804.04640v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.04640v2", "num_discussion": 0, "originally_published_time": "4/12/2018", "pid": "1804.04640v2", "published_time": "6/26/2018", "rawpid": "1804.04640", "tags": ["stat.ML", "cs.LG"], "title": "Fast Counting in Machine Learning Applications"}, {"abstract": "Various imaging artifacts, low signal-to-noise ratio, and bone surfaces\nappearing several millimeters in thickness have hindered the success of\nultrasound (US) guided computer assisted orthopedic surgery procedures. In this\nwork, a multi-feature guided convolutional neural network (CNN) architecture is\nproposed for simultaneous enhancement, segmentation, and classification of bone\nsurfaces from US data. The proposed CNN consists of two main parts: a\npre-enhancing net, that takes the concatenation of B-mode US scan and three\nfiltered image features for the enhancement of bone surfaces, and a modified\nU-net with a classification layer. The proposed method was validated on 650 in\nvivo US scans collected using two US machines, by scanning knee, femur, distal\nradius and tibia bones. Validation, against expert annotation, achieved\nstatistically significant improvements in segmentation of bone surfaces\ncompared to state-of-the-art.", "authors": ["Puyang Wang", "Vishal M. Patel", "Ilker Hacihaliloglu"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.09766v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09766v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09766v1", "published_time": "6/26/2018", "rawpid": "1806.09766", "tags": ["cs.CV"], "title": "Simultaneous Segmentation and Classification of Bone Surfaces from\n  Ultrasound Using a Multi-feature Guided CNN"}, {"abstract": "The broad set of deep generative models (DGMs) has achieved remarkable\nadvances. However, it is often difficult to incorporate rich structured domain\nknowledge with the end-to-end DGMs. Posterior regularization (PR) offers a\nprincipled framework to impose structured constraints on probabilistic models,\nbut has limited applicability to the diverse DGMs that can lack a Bayesian\nformulation or even explicit density evaluation. PR also requires constraints\nto be fully specified {\\it a priori}, which is impractical or suboptimal for\ncomplex knowledge with learnable uncertain parts. In this paper, we establish\nmathematical correspondence between PR and reinforcement learning (RL), and,\nbased on the connection, expand PR to learn constraints as the extrinsic reward\nin RL. The resulting algorithm is model-agnostic to apply to any DGMs, and is\nflexible to adapt arbitrary constraints with the model jointly. Experiments on\nhuman image generation and templated sentence generation show models with\nlearned knowledge constraints by our algorithm greatly improve over base\ngenerative models.", "authors": ["Zhiting Hu", "Zichao Yang", "Ruslan Salakhutdinov", "Xiaodan Liang", "Lianhui Qin", "Haoye Dong", "Eric Xing"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09764v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09764v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09764v1", "published_time": "6/26/2018", "rawpid": "1806.09764", "tags": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "title": "Deep Generative Models with Learnable Knowledge Constraints"}, {"abstract": "This paper examines a novel gradient boosting framework for regression. We\nregularize gradient boosted trees by introducing subsampling and employ a\nmodified shrinkage algorithm so that at every boosting stage the estimate is\ngiven by an average of trees. The resulting algorithm, titled Boulevard, is\nshown to converge as the number of trees grows. We also demonstrate a central\nlimit theorem for this limit, allowing a characterization of uncertainty for\npredictions. A simulation study and real world examples provide support for\nboth the predictive accuracy of the model and its limiting behavior.", "authors": ["Yichen Zhou", "Giles Hooker"], "category": "stat.ME", "comment": "", "img": "/static/thumbs/1806.09762v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09762v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09762v1", "published_time": "6/26/2018", "rawpid": "1806.09762", "tags": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "title": "Boulevard: Regularized Stochastic Gradient Boosted Trees and Their\n  Limiting Distribution"}, {"abstract": "We introduce several new black-box reductions that significantly improve the\ndesign of adaptive and parameter-free online learning algorithms by simplifying\nanalysis, improving regret guarantees, and sometimes even improving runtime. We\nreduce parameter-free online learning to online exp-concave optimization, we\nreduce optimization in a Banach space to one-dimensional optimization, and we\nreduce optimization over a constrained domain to unconstrained optimization.\nAll of our reductions run as fast as online gradient descent. We use our new\ntechniques to improve upon the previously best regret bounds for parameter-free\nlearning, and do so for arbitrary norms.", "authors": ["Ashok Cutkosky", "Francesco Orabona"], "category": "cs.LG", "comment": "Appears in Conference on Learning Theory 2018", "img": "/static/thumbs/1802.06293v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1802.06293v2", "num_discussion": 0, "originally_published_time": "2/17/2018", "pid": "1802.06293v2", "published_time": "6/26/2018", "rawpid": "1802.06293", "tags": ["cs.LG", "math.OC", "stat.ML"], "title": "Black-Box Reductions for Parameter-free Online Learning in Banach Spaces"}, {"abstract": "Unsupervised transfer of object recognition models from synthetic to real\ndata is an important problem with many potential applications. The challenge is\nhow to \"adapt\" a model trained on simulated images so that it performs well on\nreal-world data without any additional supervision. Unfortunately, current\nbenchmarks for this problem are limited in size and task diversity. In this\npaper, we present a new large-scale benchmark called Syn2Real, which consists\nof a synthetic domain rendered from 3D object models and two real-image domains\ncontaining the same object categories. We define three related tasks on this\nbenchmark: closed-set object classification, open-set object classification,\nand object detection. Our evaluation of multiple state-of-the-art methods\nreveals a large gap in adaptation performance between the easier closed-set\nclassification task and the more difficult open-set and detection tasks. We\nconclude that developing adaptation methods that work well across all three\ntasks presents a significant future challenge for syn2real domain transfer.", "authors": ["Xingchao Peng", "Ben Usman", "Kuniaki Saito", "Neela Kaushik", "Judy Hoffman", "Kate Saenko"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.09755v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09755v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09755v1", "published_time": "6/26/2018", "rawpid": "1806.09755", "tags": ["cs.CV"], "title": "Syn2Real: A New Benchmark forSynthetic-to-Real Visual Domain Adaptation"}, {"abstract": "We propose a generic numerical measure of inconsistency of a database with\nrespect to integrity constraints that is based on a repair semantics. A\nparticular measure is investigated, with mechanisms for computing it via\nanswer-set programs.", "authors": ["Leopoldo Bertossi"], "category": "cs.DB", "comment": "Submission as short paper; to appear in Proc. Scalable Uncertainty\n  Management, SUM 2018", "img": "/static/thumbs/1804.08834v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1804.08834v2", "num_discussion": 0, "originally_published_time": "4/24/2018", "pid": "1804.08834v2", "published_time": "6/26/2018", "rawpid": "1804.08834", "tags": ["cs.DB", "cs.AI", "cs.LO"], "title": "Measuring and Computing Database Inconsistency via Repairs"}, {"abstract": "This work addresses challenges arising from extracting entities from textual\ndata, including the high cost of data annotation, model accuracy, selecting\nappropriate evaluation criteria, and the overall quality of annotation. We\npresent a framework that integrates Entity Set Expansion (ESE) and Active\nLearning (AL) to reduce the annotation cost of sparse data and provide an\nonline evaluation method as feedback. This incremental and interactive learning\nframework allows for rapid annotation and subsequent extraction of sparse data\nwhile maintaining high accuracy.\n  We evaluate our framework on three publicly available datasets and show that\nit drastically reduces the cost of sparse entity annotation by an average of\n85% and 45% to reach 0.9 and 1.0 F-Scores respectively. Moreover, the method\nexhibited robust performance across all datasets.", "authors": ["Hussein S. Al-Olimat", "Steven Gustafson", "Jason Mackay", "Krishnaprasad Thirunarayan", "Amit Sheth"], "category": "cs.CL", "comment": "", "img": "/static/thumbs/1806.09751v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09751v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09751v1", "published_time": "6/26/2018", "rawpid": "1806.09751", "tags": ["cs.CL"], "title": "A Practical Incremental Learning Framework For Sparse Entity Extraction"}, {"abstract": "It is a fundamental, but still elusive question whether the schemes based on\nquantum mechanics, in particular on quantum entanglement, can be used for\nclassical information processing and machine learning. Even partial answer to\nthis question would bring important insights to both fields of machine learning\nand quantum mechanics. In this work, we implement simple numerical experiments,\nrelated to pattern/images classification, in which we represent the classifiers\nby many-qubit quantum states written in the matrix product states (MPS).\nClassical machine learning algorithm is applied to these quantum states to\nlearn the classical data. We explicitly show how quantum entanglement (i.e.,\nsingle-site and bipartite entanglement) can emerge in such represented images.\nEntanglement characterizes here the importance of data, and such information\nare practically used to guide the architecture of MPS, and improve the\nefficiency. The number of needed qubits can be reduced to less than 1/10 of the\noriginal number, which is within the access of the state-of-the-art quantum\ncomputers. We expect such numerical experiments could open new paths in\ncharactering classical machine learning algorithms, and at the same time shed\nlights on the generic quantum simulations/computations of machine learning\ntasks.", "authors": ["Yuhan Liu", "Xiao Zhang", "Maciej Lewenstein", "Shi-Ju Ran"], "category": "stat.ML", "comment": "10 pages, 5 figures", "img": "/static/thumbs/1803.09111v3.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1803.09111v3", "num_discussion": 0, "originally_published_time": "3/24/2018", "pid": "1803.09111v3", "published_time": "6/26/2018", "rawpid": "1803.09111", "tags": ["stat.ML", "cs.LG", "quant-ph"], "title": "Entanglement-guided architectures of machine learning by quantum tensor\n  network"}, {"abstract": "In coronary CT angiography, a series of CT images are taken at different\nlevels of radiation dose during the examination. Although this reduces the\ntotal radiation dose, the image quality during the low-dose phases is\nsignificantly degraded. To address this problem, here we propose a novel\nsemi-supervised learning technique that can remove the noises of the CT images\nobtained in the low-dose phases by learning from the CT images in the routine\ndose phases. Although a supervised learning approach is not possible due to the\ndifferences in the underlying heart structure in two phases, the images in the\ntwo phases are closely related so that we propose a cycle-consistent\nadversarial denoising network to learn the non-degenerate mapping between the\nlow and high dose cardiac phases. Experimental results showed that the proposed\nmethod effectively reduces the noise in the low-dose CT image while the\npreserving detailed texture and edge information. Moreover, thanks to the\ncyclic consistency and identity loss, the proposed network does not create any\nartificial features that are not present in the input images. Visual grading\nand quality evaluation also confirm that the proposed method provides\nsignificant improvement in diagnostic quality.", "authors": ["Eunhee Kang", "Hyun Jung Koo", "Dong Hyun Yang", "Joon Bum Seo", "Jong Chul Ye"], "category": "cs.CV", "comment": "", "img": "/static/thumbs/1806.09748v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09748v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09748v1", "published_time": "6/26/2018", "rawpid": "1806.09748", "tags": ["cs.CV", "cs.AI", "cs.LG", "stat.ML"], "title": "Cycle Consistent Adversarial Denoising Network for Multiphase Coronary\n  CT Angiography"}, {"abstract": "This paper presents details of our winning solutions to the task IV of NIPS\n2017 Competition Track entitled Classifying Clinically Actionable Genetic\nMutations. The machine learning task aims to classify genetic mutations based\non text evidence from clinical literature with promising performance. We\ndevelop a novel multi-view machine learning framework with ensemble\nclassification models to solve the problem. During the Challenge, feature\ncombinations derived from three views including document view, entity text\nview, and entity name view, which complements each other, are comprehensively\nexplored. As the final solution, we submitted an ensemble of nine basic\ngradient boosting models which shows the best performance in the evaluation.\nThe approach scores 0.5506 and 0.6694 in terms of logarithmic loss on a fixed\nsplit in stage-1 testing phase and 5-fold cross validation respectively, which\nalso makes us ranked as a top-1 team out of more than 1,300 solutions in NIPS\n2017 Competition Track IV.", "authors": ["Xi Zhang", "Dandi Chen", "Yongjun Zhu", "Chao Che", "Chang Su", "Sendong Zhao", "Xu Min", "Fei Wang"], "category": "cs.LG", "comment": "", "img": "/static/thumbs/1806.09737v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09737v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09737v1", "published_time": "6/26/2018", "rawpid": "1806.09737", "tags": ["cs.LG", "stat.ML"], "title": "The NIPS\u002717 Competition: A Multi-View Ensemble Classification Model for\n  Clinically Actionable Genetic Mutations"}, {"abstract": "The online environment has provided a great opportunity for insurance\npolicyholders to share their complaints with respect to different services.\nThese complaints can reveal valuable information for insurance companies who\nseek to improve their services; however, analyzing a huge number of online\ncomplaints is a complicated task for human and must involve computational\nmethods to create an efficient process. This research proposes a computational\napproach to characterize the major topics of a large number of online\ncomplaints. Our approach is based on using the topic modeling approach to\ndisclose the latent semantic of complaints. The proposed approach deployed on\nthousands of GEICO negative reviews. Analyzing 1,371 GEICO complaints indicates\nthat there are 30 major complains in four categories: (1) customer service, (2)\ninsurance coverage, paperwork, policy, and reports, (3) legal issues, and (4)\ncosts, estimates, and payments. This research approach can be used in other\napplications to explore a large number of reviews.", "authors": ["Amir Karami", "Noelle M. Pendergraft"], "category": "stat.AP", "comment": "", "img": "/static/thumbs/1806.09736v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09736v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09736v1", "published_time": "6/26/2018", "rawpid": "1806.09736", "tags": ["stat.AP", "cs.CL", "cs.IR", "stat.ML"], "title": "Computational Analysis of Insurance Complaints: GEICO Case Study"}, {"abstract": "Typefaces are an essential resource employed by graphic designers. The\nincreasing demand for innovative type design work increases the need for good\ntechnological means to assist the designer in the creation of a typeface. We\npresent an evolutionary computation approach for the generation of type\nstencils to draw coherent glyphs for different characters. The proposed system\nemploys a Genetic Algorithm to evolve populations of type stencils. The\nevaluation of each candidate stencil uses a hill climbing algorithm to search\nthe best configurations to draw the target glyphs. We study the interplay\nbetween legibility, coherence and expressiveness, and show how our framework\ncan be used in practice.", "authors": ["Tiago Martins", "Jo\u00e3o Correia", "Ernesto Costa", "Penousal Machado"], "category": "cs.NE", "comment": "EvoMUSART 2018 Best paper", "img": "/static/thumbs/1806.09731v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09731v1", "num_discussion": 0, "originally_published_time": "6/26/2018", "pid": "1806.09731v1", "published_time": "6/26/2018", "rawpid": "1806.09731", "tags": ["cs.NE", "cs.AI", "cs.GR"], "title": "Evotype: Towards the Evolution of Type Stencils"}, {"abstract": "One important assumption underlying common classification models is the\nstationarity of the data. However, in real-world streaming applications, the\ndata concept indicated by the joint distribution of feature and label is not\nstationary but drifting over time. Concept drift detection aims to detect such\ndrifts and adapt the model so as to mitigate any deterioration in the model\u0027s\npredictive performance. Unfortunately, most existing concept drift detection\nmethods rely on a strong and over-optimistic condition that the true labels are\navailable immediately for all already classified instances. In this paper, a\nnovel Hierarchical Hypothesis Testing framework with Request-and-Reverify\nstrategy is developed to detect concept drifts by requesting labels only when\nnecessary. Two methods, namely Hierarchical Hypothesis Testing with\nClassification Uncertainty (HHT-CU) and Hierarchical Hypothesis Testing with\nAttribute-wise \"Goodness-of-fit\" (HHT-AG), are proposed respectively under the\nnovel framework. In experiments with benchmark datasets, our methods\ndemonstrate overwhelming advantages over state-of-the-art unsupervised drift\ndetectors. More importantly, our methods even outperform DDM (the widely used\nsupervised drift detector) when we use significantly fewer labels.", "authors": ["Shujian Yu", "Xiaoyang Wang", "Jose C. Principe"], "category": "cs.LG", "comment": "Published as a conference paper at IJCAI 2018", "img": "/static/thumbs/1806.10131v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10131v1", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.10131v1", "published_time": "6/25/2018", "rawpid": "1806.10131", "tags": ["cs.LG", "cs.AI", "stat.ML"], "title": "Request-and-Reverify: Hierarchical Hypothesis Testing for Concept Drift\n  Detection with Expensive Labels"}, {"abstract": "Given $n$ samples from a population of individuals belonging to different\ntypes with unknown proportions, how do we estimate the probability of\ndiscovering a new type at the $(n+1)$-th draw? This is a classical problem in\nstatistics, commonly referred to as the missing mass estimation problem. Recent\nresults by Ohannessian and Dahleh \\citet{Oha12} and Mossel and Ohannessian\n\\citet{Mos15} showed: i) the impossibility of estimating (learning) the missing\nmass without imposing further structural assumptions on the type proportions;\nii) the consistency of the Good-Turing estimator for the missing mass under the\nassumption that the tail of the type proportions decays to zero as a regularly\nvarying function with parameter $\\alpha\\in(0,1)$. In this paper we rely on\ntools from Bayesian nonparametrics to provide an alternative, and simpler,\nproof of the impossibility of a distribution-free estimation of the missing\nmass. Up to our knowledge, the use of Bayesian ideas to study large sample\nasymptotics for the missing mass is new, and it could be of independent\ninterest. Still relying on Bayesian nonparametric tools, we then show that\nunder regularly varying type proportions the convergence rate of the\nGood-Turing estimator is the best rate that any estimator can achieve, up to a\nslowly varying function, and that minimax rate must be at least\n$n^{-\\alpha/2}$. We conclude with a discussion of our results, and by\nconjecturing that the Good-Turing estimator is an rate optimal minimax\nestimator under regularly varying type proportions.", "authors": ["Fadhel Ayed", "Marco Battiston", "Federico Camerlenghi", "Stefano Favaro"], "category": "math.ST", "comment": "", "img": "/static/thumbs/1806.09712v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09712v1", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.09712v1", "published_time": "6/25/2018", "rawpid": "1806.09712", "tags": ["math.ST", "stat.ML", "stat.TH"], "title": "On consistent estimation of the missing mass"}, {"abstract": "As artificial intelligence is increasingly affecting all parts of society and\nlife, there is growing recognition that human interpretability of machine\nlearning models is important. It is often argued that accuracy or other similar\ngeneralization performance metrics must be sacrificed in order to gain\ninterpretability. Such arguments, however, fail to acknowledge that the overall\ndecision-making system is composed of two entities: the learned model and a\nhuman who fuses together model outputs with his or her own information. As\nsuch, the relevant performance criteria should be for the entire system, not\njust for the machine learning component. In this work, we characterize the\nperformance of such two-node tandem data fusion systems using the theory of\ndistributed detection. In doing so, we work in the population setting and model\ninterpretable learned models as multi-level quantizers. We prove that under our\nabstraction, the overall system of a human with an interpretable classifier\noutperforms one with a black box classifier.", "authors": ["Kush R. Varshney", "Prashant Khanduri", "Pranay Sharma", "Shan Zhang", "Pramod K. Varshney"], "category": "stat.ML", "comment": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockhol...", "img": "/static/thumbs/1806.09710v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09710v1", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.09710v1", "published_time": "6/25/2018", "rawpid": "1806.09710", "tags": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "title": "Why Interpretability in Machine Learning? An Answer Using Distributed\n  Detection and Data Fusion Theory"}, {"abstract": "A robust and informative local shape descriptor plays an important role in\nmesh registration. In this regard, spectral descriptors that are based on the\nspectrum of the Laplace-Beltrami operator have gained a spotlight among the\nresearchers for the last decade due to their desirable properties, such as\nisometry invariance. Despite such, however, spectral descriptors often fail to\ngive a correct similarity measure for non-isometric cases where the metric\ndistortion between the models is large. Hence, they are in general not suitable\nfor the registration problems, except for the special cases when the models are\nnear-isometry. In this paper, we investigate a way to develop shape descriptors\nfor non-isometric registration tasks by embedding the spectral shape\ndescriptors into a different metric space where the Euclidean distance between\nthe elements directly indicates the geometric dissimilarity. We design and\ntrain a Siamese deep neural network to find such an embedding, where the\nembedded descriptors are promoted to rearrange based on the geometric\nsimilarity. We found our approach can significantly enhance the performance of\nthe conventional spectral descriptors for the non-isometric registration tasks,\nand outperforms recent state-of-the-art method reported in literature.", "authors": ["Zhiyu Sun", "Yusen He", "Andrey Gritsenko", "Amaury Lendasse", "Stephen Baek"], "category": "cs.GR", "comment": "Submitted to Computer-Aided Design", "img": "/static/thumbs/1710.06368v2.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1710.06368v2", "num_discussion": 0, "originally_published_time": "10/17/2017", "pid": "1710.06368v2", "published_time": "6/25/2018", "rawpid": "1710.06368", "tags": ["cs.GR", "cs.CV"], "title": "Deep Spectral Descriptors: Learning the point-wise correspondence metric\n  via Siamese deep neural networks"}, {"abstract": "Given independent samples generated from the joint distribution\n$p(\\mathbf{x},\\mathbf{y},\\mathbf{z})$, we study the problem of Conditional\nIndependence (CI-Testing), i.e., whether the joint equals the CI distribution\n$p^{CI}(\\mathbf{x},\\mathbf{y},\\mathbf{z})= p(\\mathbf{z})\np(\\mathbf{y}|\\mathbf{z})p(\\mathbf{x}|\\mathbf{z})$ or not. We cast this problem\nunder the purview of the proposed, provable meta-algorithm, \"Mimic and\nClassify\", which is realized in two-steps: (a) Mimic the CI distribution close\nenough to recover the support, and (b) Classify to distinguish the joint and\nthe CI distribution. Thus, as long as we have a good generative model and a\ngood classifier, we potentially have a sound CI Tester. With this modular\nparadigm, CI Testing becomes amiable to be handled by state-of-the-art, both\ngenerative and classification methods from the modern advances in Deep\nLearning, which in general can handle issues related to curse of dimensionality\nand operation in small sample regime. We show intensive numerical experiments\non synthetic and real datasets where new mimic methods such conditional GANs,\nRegression with Neural Nets, outperform the current best CI Testing performance\nin the literature. Our theoretical results provide analysis on the estimation\nof null distribution as well as allow for general measures, i.e., when either\nsome of the random variables are discrete and some are continuous or when one\nor more of them are discrete-continuous mixtures.", "authors": ["Rajat Sen", "Karthikeyan Shanmugam", "Himanshu Asnani", "Arman Rahimzamani", "Sreeram Kannan"], "category": "stat.ML", "comment": "16 pages, 2 figures", "img": "/static/thumbs/1806.09708v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.09708v1", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.09708v1", "published_time": "6/25/2018", "rawpid": "1806.09708", "tags": ["stat.ML", "cs.LG"], "title": "Mimic and Classify : A meta-algorithm for Conditional Independence\n  Testing"}, {"abstract": "We provide a proof of the the Front-Door adjustment formula using the\ndo-calculus.", "authors": ["Mohammad Ali Javidian", "Marco Valtorta"], "category": "cs.AI", "comment": "Six figures and an ancillary document consisting of 53 slides", "img": "/static/thumbs/1806.10449v1.pdf.jpg", "in_library": 0, "link": "http://arxiv.org/abs/1806.10449v1", "num_discussion": 0, "originally_published_time": "6/25/2018", "pid": "1806.10449v1", "published_time": "6/25/2018", "rawpid": "1806.10449", "tags": ["cs.AI"], "title": "A Proof of the Front-Door Adjustment Formula"}];
var pid_to_users = {};
var msg = "Showing most recent Arxiv papers:";
var render_format = "recent";
var username = "";
var numresults = "50076";
var show_prompt = "no";

var urlq = ''; // global will be read in to QueryString when load is done

// when page loads...
$(document).ready(function(){

	urlq = QueryString.q;

  // display message, if any
  if(msg !== '') { d3.select("#rtable").append('div').classed('msg', true).html(msg); }

  // add papers to #rtable
	var done = addPapers(10, false);
  if(done) { $("#loadmorebtn").hide(); }

  // set up inifinite scrolling for adding more papers
  $(window).on('scroll', function(){
    var scrollTop = $(document).scrollTop();
    var windowHeight = $(window).height();
    var bodyHeight = $(document).height() - windowHeight;
    var scrollPercentage = (scrollTop / bodyHeight);
    if(scrollPercentage > 0.9) {
      var done = addPapers(5, true);
      if(done) { $("#loadmorebtn").hide(); }
    }
  });

  // just in case scrolling is broken somehow, provide a button handler explicit
  $("#loadmorebtn").on('click', function(){
    var done = addPapers(5, true);
    if(done) { $("#loadmorebtn").hide(); }
  });

  if(papers.length === 0) { $("#loadmorebtn").hide(); }

	if(!(typeof urlq == 'undefined')) {
		d3.select("#qfield").attr('value', urlq.replace(/\+/g, " "));
	}

  var vf = QueryString.vfilter; if(typeof vf === 'undefined') { vf = 'all'; }
  var tf = QueryString.timefilter; if(typeof tf === 'undefined') { tf = 'week'; }
  var link_endpoint = '/';
  if(render_format === 'recent') { link_endpoint = ''; }
  if(render_format === 'top') { link_endpoint = 'top'; }
  if(render_format === 'recommend') { link_endpoint = 'recommend'; }
  if(render_format === 'friends') { link_endpoint = 'friends'; }
  if(render_format === 'toptwtr') { link_endpoint = 'toptwtr'; }
  if(render_format === 'discussions') { link_endpoint = 'discussions'; }

  var time_ranges = ['day', '3days', 'week', 'month', 'year', 'alltime'];
  var time_txt = {'day':'Last day', '3days': 'Last 3 days', 'week': 'Last week', 'month': 'Last month', 'year': 'Last year', 'alltime': 'All time'}
  var time_range = tf;

  // set up time filtering options
  if(render_format === 'recommend' || render_format === 'top' || render_format === 'recent' || render_format === 'friends') {
    // insert version filtering options for these views
    var elt = d3.select('#recommend-time-choice');
    var vflink = vf === 'all' ? '1' : 'all'; // toggle only showing v1 or not
    if(render_format === 'recent') {
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'&vfilter='+vflink); // leave out timefilter from this page
    } else {
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range+'&vfilter='+vflink);
    }
    var delt = aelt.append('div').classed('vchoice', true).html('Only show v1');
    if(vf === '1') { delt.classed('vchoice-selected', true); }
  }

  // time choices for recommend/top
  if(render_format === 'recommend' || render_format === 'top' || render_format === 'friends') {
    // insert time filtering options for these two views
    var elt = d3.select('#recommend-time-choice');
    elt.append('div').classed('fdivider', true).html('|');
    for(var i=0;i<time_ranges.length;i++) {
      var time_range = time_ranges[i];
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range+'&vfilter='+vf);
      var delt = aelt.append('div').classed('timechoice', true).html(time_txt[time_range]);
      if(tf == time_range) { delt.classed('timechoice-selected', true); } // also render as chosen
    }
  }

  // time choices for top tweets
  if(render_format === 'toptwtr') {
    var tf = QueryString.timefilter; if(typeof tf === 'undefined') { tf = 'day'; } // default here is day
    var time_ranges = ['day', 'week', 'month'];
    var elt = d3.select('#recommend-time-choice');
    for(var i=0;i<time_ranges.length;i++) {
      var time_range = time_ranges[i];
      var aelt = elt.append('a').attr('href', '/'+link_endpoint+'?'+'timefilter='+time_range);
      var delt = aelt.append('div').classed('timechoice', true).html(time_txt[time_range]);
      if(tf == time_range) { delt.classed('timechoice-selected', true); } // also render as chosen
    }
  }

  var xb = $("#xbanner");
  if(xb.length !== 0) {
    xb.click(function(){ $("#banner").slideUp('fast'); })
  }

  // in top tab: color current choice
  if( render_format === 'recent') { d3.select('#tabrecent').classed('tab-selected', true); }
  if( render_format === 'top') { d3.select('#tabtop').classed('tab-selected', true); }
  if( render_format === 'toptwtr') { d3.select('#tabtwtr').classed('tab-selected', true); }
  if( render_format === 'friends') { d3.select('#tabfriends').classed('tab-selected', true); }
  if( render_format === 'discussions') { d3.select('#tabdiscussions').classed('tab-selected', true); }
  if( render_format === 'recommend') { d3.select('#tabrec').classed('tab-selected', true); }
  if( render_format === 'library') { d3.select('#tablib').classed('tab-selected', true); }

  $("#goaway").on('click', function(){
    $("#prompt").slideUp('fast');
    $.post("/goaway", {}).done(function(data){ });
  });
});

</script>
</head>

<body>
<a href="https://github.com/karpathy/arxiv-sanity-preserver"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

<div id ="titdiv">

  <!-- User account information on top right -->
  <div id="userinfo">
    
    <form action="/login" method="post">
      User:
      <input type="text" name="username" class="input-no-border">
      Pass:
      <input type="password" name="password" class="input-no-border">
      <input type="submit" value="Login or Create" class="btn-fancy">
    </form>
    
  </div>

  <!-- Site information/banner on top left -->
	<a href="/">
	<div id="tittxt">
		<h1>Arxiv Sanity Preserver</h1>
		Built in spare time by <a href="https://twitter.com/karpathy">@karpathy</a> to accelerate research.<br>
		Serving last 50076 papers from cs.[CV|CL|LG|AI|NE]/stat.ML
	</div>
	</a>
</div>

<div id="flashesdiv">

    

</div>


<div id="banner">
  <div style="float:right;cursor:pointer;" id="xbanner">X</div>
  New to arxiv-sanity? Check out the <a href="https://youtu.be/S2GY3gh6qC8" target="_blank">introduction video</a>.
</div>


<div id="sbox">
  <form action="/search" method="get">
  	<input name="q" type="text" id="qfield">
  </form>
  <div id="search_hint"></div>
</div>



<div id="pagebar">
  <div class="pagelink" id="tabrecent"><a href="/">most recent</a></div>
  <div class="pagelink" id="tabtop"><a href="/top">top recent</a></div>
  <div class="pagelink" id="tabtwtr"><a href="/toptwtr">top hype</a></div>
  <div class="pagelink" id="tabfriends"><a href="/friends">friends</a></div>
  <div class="pagelink" id="tabdiscussions"><a href="/discussions">discussions</a></div>
  <div class="pagelink" id="tabrec"><a href="/recommend">recommended</a></div>
  <div class="pagelink" id="tablib"><a href="/library">library</a></div>
</div>

<!-- this div will be rendered into dynamcially at init with JS -->
<div id="recommend-time-choice" class="centerdiv"></div>

<div id="maindiv">

<div id="rtable"></div>

<div id="loadmore">
  <button id="loadmorebtn">Load more</button>
</div>

</div>

<br><br><br><br><br><br>
</body>

</html>